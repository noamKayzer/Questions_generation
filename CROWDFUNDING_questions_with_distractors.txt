--------------------------------------------------
TEXT: Crowdfunding platforms allow entrepreneurs to publish projects and raise funds for realizing them. Hence, the question of what influences projects’ fundraising success is very important. Previous studies examined various factors such as project goals and project duration that may influence the outcomes of fundraising campaigns. We present a novel model for predicting the success of crowdfunding projects in meeting their funding goals. Our model focuses on semantic features only, whose performance is comparable to that of previous models. In an additional model we developed, we examine both project metadata and project semantics, delivering a comprehensive study of factors influencing crowdFS. Further, we analyze a large dataset of crowdfunding project data, larger than reported in the art. Finally, we show that when combining semantics and metadata, we arrive at F1 score accuracy of 96.2%. We compare our model’s accuracy to the accuracy of previous research models by applying their methods on our dataset, and demonstrate higher accuracy of our model. In addition to our scientific contribution, we provide practical recommendations that may increase project Funding Success chances.

section 1 - (1) What do we present? --- A novel model for predicting the success of crowdfunding projects in meeting their funding goals.
 ['A mixed methods survey approach was used for surveying two distinct populations within a UK research setting involving students from four different universities studying economics', 'A study based on empirical research using survey and questionnaires collected responses from a total sample representing two major public-access television cable company websites', 'A review focused exclusively on fund and donation decisions to promote or inhibit research for non-government organisations based largely upon qualitative methodologies but including', 'A comparative study on different aspects regarding successful financing campaigns and what distinguishes our sample from others who have been researched by means machine learning algorithms', 'A comparative review using semantic classification from both technical as well social networks for an exhaustive understanding with different features, like keywords presence vs absent']
section 1 - (2) What do crowdfunding platforms allow entrepreneurs to do? --- Crowdfunding platforms allow entrepreneurs to publish projects and raise funds for realizing them
 ['Crowdfunding platforms allow entrepreneurs to use these products more broadly, while giving new types like customizable apps which may increase market adoption at a fraction or even cheaper', 'Crowdfunding platforms allow entrepreneurs to fund new products, services or marketing strategies without investable capital investment with a low-interest rate loan program called microborrowing', 'Crowdfunding platforms allow entrepreneurs to set their mind at rest and let things happen on demand, rather than being locked away forever within virtual forays dedicated purely through', 'Crowdfunding platforms allow entrepreneurs to take on complex, challenging financing challenges such as dealing with customer uncertainty and getting back customers for money from unknown entities using online methods', 'Crowdfunding platforms allow entrepreneurs to create and maintain a fundraising environment based on crowd input as well beautify these by adding their user community feedback back']
section 1 - (3) Is the proposed model more accurate than previous models? --- The paper presents a novel model for crowdfunding project Funding Success (FS) that combines both semantic features and project metadata. The model is based on a large dataset of crowdfunding project data. The proposed model is more accurate than previous models.
 ['The paper addresses how knowledge from different levels are incorporated together, easing our reasoning task as people need to focus just a few keywords', 'The results showed that there was a linear relationship befocr both quantitative and qualitative information gathered, suggesting some evidence is indeed shown', 'The use semantic has had a big positive influence on many different application fields including medicine to treat diabetes type II which was successfully improved by', 'The purpose is, first to study these three proposals with two distinct corpora using supervised and unsupervised classification procedures for a set number or features', 'The research methodology, findings were analyzed at length regarding different criteria associated to successful funding campaigns with various levels and sources used by investors for']
section 1 - (4)NP-BASED- What is one factor that may influence the outcome of fundraising campaigns? --- project goals and project duration
 ['project- and crowdfunders alike see this semantic challenge, trying to find out what elements must be emphasized when building online products aimed', 'project management, social networks technologies as well and finally project goals or targets could also have a substantial impact on final results through their relation', 'project evaluation for research into economic impact on patients A comparative study based an open source methodology. Analysis, description and categorization from three perspectives', 'project_ID project details date time price text description link1 Link2 URL2 Link3 Source code https-webpageserver', 'project2) how long will you remain on top position from day start until failure to make money within time limit set by client if']
section 1 - (5)NP-BASED- What do the authors analyze? --- a large dataset of crowdfunding project data
 ['a) Textual analyses using content and readability indexes to investigate whether there are text features which might relate semantic complexity associated either with specific', 'a13296 A CrowdCup approach to project design has emerged from experience during real-word crowdsourcing challenges and', 'a b s t r a C h I N D e M A P S U Performer Status, Type(s) Employ', 'a very relevant and significant task but, perhaps unknowingly overlooked topic that should take great care from scientists when developing any kind financial', 'a novel social psychological perspective, as indicated from multiple data available over an extended period and perspectives']
section 1 - (6)NP-BASED- What other aspect of crowdfunding did the authors examine? --- project metadata and project semantics
 ['project design, market segmentation) and could have found different results because this was unknown at publication time.. We hope researchers make it part', 'project and campaign metadata, website traffic volume prior funders made a prediction as to successful or unprofitable project based on certain variables', 'project design parameters are related to project duration and can be improved, such as how well a specific part addresses customer needs Social media', 'project descriptions for a variety project topics on both platforms are displayed below this summary section to demonstrate our focus only one or few aspects and', 'project description description project name description fundraising company country region type size date start up down time investment funding year duration amount per cent']
--------------------------------------------------
TEXT: In recent years, crowdfunding has emerged as a popular financing mechanism that allows various types of projects to get funded. Three main parties are involved in crowdfunding: entrepreneurs (and their projects), individuals or groups who support the project, and online platforms, i.e., crowdfunding websites. The average success rate of funded crowdfunding projects in Kickstarter is 37.5% [4] In this paper, we refer to a project as a Funding Success if it achieved its funding goal (i.e.  In contrast to prior studies, we take a more comprehensive approach to studying and predicting FS. We use unique features (for example, the use of buzzwords) and perform extensive research on the semantics of the projects’ text. Our main research objective is to find characteristics, with a focus on semantic characteristics, which affect the success of a project in meeting its funding goal via crowdfunding. This approach leverages known results and improves upon them to provide high-quality FS prediction.  Achieving these research objectives should provide new insights into the relationship between crowdfunding project’s data and their FS. This should provide entrepreneurs with additional and desirable ways to improve their chances of reaching their funding goals. The accuracy of the semantic-model (in terms of F-score and correctly classified instances) is comparable to the accuracy of state-of-the-art models which are based on metadata features such as the number of updates, number of images, etc.  The accuracy of the combined-model is higher than the accuracy derived in previous studies that use other models [11–14] Fourth, we show that buzzwords and Linguistic Inquiry and Word Count are among the highly correlate features with the project’s success in fund raising. Fifth, to the best of our knowledge, our research relies on the largest dataset used to date for developing models that predict FS of crowdfunding projects. In addition to the scientific contributions listed above, we provide a set of recommendations that may increase project FS chances.  The Methodology section focuses on the research methodology applied, including the acquisition of our dataset, preprocessing, feature extraction and selection. The Results section presents the empirical evaluation of our research model and discusses the results. It further compares our models to models in earlier studies.

section 2 - (1) What do we show about buzzwords and LIWC? --- Buzzwords and Linguistic Inquiry and Word Count (LIWC) are among the highly correlates features with project’s success in fund raising.
 ['Buzzwords and Linguistic Inquiry and Word Count (LIWC) are widely accepted by academics due mainly to being intuitive tools used when writing science papers describing emotional feelings that readers share, this tool', 'Buzzwords and Linguistic Inquiry and Word Count (LIWC) are linguistic computational techniques commonly being used together to provide us with a detailed knowledge from different disciplines that relate human language structure directly or indirectly', 'Buzzwords and Linguistic Inquiry and Word Count (LIWC) are increasingly becoming common ways to look at language within research on human cognition, however little data concerning use or relevance by lay people has', 'Buzzwords and Linguistic Inquiry and Word Count (LIWC) are frequently used to explain project results but it could take time for a user from starting research by getting knowledge with that particular dataset out', 'Buzzwords and Linguistic Inquiry and Word Count (LIWC) are not just good predictors for whether to launch campaigns or win a lot on crowdfunded websites like ekonomicos, but']
section 2 - (2)NP-BASED- What does the VC community facilitate? --- project funding and launching
 ['project descriptions that could be easily translated into machine readable representations suitable for processing using Artificial Intelligence techniques like text parsing tools with a deep', 'projector has created new opportunities for individuals, firms and NGOs by providing an avenue through various forms as a solution when no other', 'project-specific information and data analysis is missing from a large majority if all studies we considered here.. We identified only two previous research', 'project funding via open source online project documentation, such as Stack Overflow and Code Conjectures that provide examples demonstrating how one can', 'project managers) is considered highly challenging for any venture capital fund manager attempting such deals that include no cash, nothing or little return because']
section 2 - (3)NP-BASED- What does the semantic model predict? --- the success of crowdfunding projects in meeting their funding goals
 ['the authors argue that when faced only with a description, such descriptions will most probably have problems relating words or keywords correctly to each other', 'the relation is stronger than what could also, if you wanted to answer them with only regression modeling techniques then it looks like that too', 'the future research direction with respect to this work and what it reveals on various platforms like social or cybercraft communities are discussed briefly', 'the case study about 18 German universities shows and discusses, which data analytics techniques help to identify good project candidates or how many', 'the more funding, i see that we get back a better value at an early time than later ones and then start to go even']
section 2 - (4)NP-BASED- What do the authors focus on extraction and analysis of? --- semantic aspects of project posts
 ['semantic components to gain insights, for a deeper understanding why different communities engage or drop out from similar tasks with comparable fund amounts over time', 'semantic data that may facilitate a deep characterization from which can be developed innovative research questions regarding fundraising processes to improve sustainability models or', 'semantic networks such as Wordnet) should be able to contribute for increasing transparency during research work done through text-miners technologies that', 'semantic-focused crowdsourcing, which is still under research', 'semantic data or to improve project management, such as a better way that could predict outcomes through prediction models from user behavior collected at an']
section 2 - (5)NP-BASED- What do authors use to build a model of Funding Success (FS)? --- semantic features extracted from the text
 ['semantic modelling and big data technology', 'semantic_type is set as True and no new results are added after analyzing paper title, keywords list etcetera Semantic enrichment was', 'semantic_proposal refers that proposals made from funder-defined rules for their contents would be expected more support and thus achieve its', 'semantic and not syntactic analyses, but only when possible semantic measures are chosen as input variables together wth traditional bibliometric metrics like average', 'semantic features extracted through deep neural architecture have made them effective, since they allow more interpretable feature extraction than traditional regression methods for Funding Success (FS) problem']
section 2 - (6)NP-BASED- What do crowdfunding models rely on for prediction? --- metadata features and topic analysis
 ['metadata or image caption datasets is very limited as most open access websites require sub-committee review to confirm whether their project will meet', 'metadata vs semantic knowledge and metadata-enriched crowd datasets with NLP annotations help build a broader corpus from which better data science can be built', 'metadata are very heterogeneous among companies and even within specific businesses since they often come with their own unique set-up, policies etc..', 'metadata, word embedding or sentiment lexicon as features to predict funding results based from text messages posted within them are analyzed by researchers such', 'metadata or what other features are taken into account when evaluating a given project) to determine predictive capabilities through cross-fold testing procedure']
--------------------------------------------------
--------------------------------------------------
--------------------------------------------------
TEXT: We used the Linguistic Inquiry and Word Count software tool to extract features from the text. LIWC analysis measures the appearance of dictionary words in a specific text. The measure is a numeric value in the range [0..1]. It reflects the degree to which the text being analyzed is related to the theme of the dictionary. The output of LIWC is VD = SD/NT, which is the value of the feature that corresponds to D. Previous studies on crowdfunding used LIWC to analyze the textual description part of projects.  The number and diversity of features in our study are much larger than previously published, and our dataset is significantly greater as well. As a result, we arrive at much higher model accuracy.

section 5 - (1) What did we use to extract features from the text? --- Linguistic Inquiry and Word Count (LIWC) software tool
 ['word usage analysis', 'textual data', 'dictionary words', 'the topic–keyword distribution']
section 5 - (2) What does LIWC analysis measure? --- Previous studies on crowdfunding used Linguistic Inquiry and Word Count (LIWC) to analyze the textual description part of projects. LIWC analysis measures the appearance of dictionary words in a specific text.
 ['Previous research indicates that certain personality aspects play an important predictive impact among funding organizations, including high openness on one hand but also ext', 'Previous research that examined language use before funding had limited scope, being either general analyses with a few data points for which meaning could still', 'Previous studies using crowd science tools such as CrowdPile to collect textual data focused on measuring how effective, sustainable financing sources like', 'Previous attempts using linguistic factors such as sentiment, empathy were shown with insufficient explanatory evidence or inconclusive correlation results at different time frames within individual', 'Previous studies had reported low accuracy rates with NLP tools due to noisy text or complex, ambiguous terms as these results could easily be affected']
--------------------------------------------------
TEXT: Latent Dirichlet Allocation is a widely used topic modeling method. LDA algorithm considers each document as a collection of topics, where each word in the document belongs to one or some of these topics. Previous studies on crowdfunding used LDA to perform topic analysis on the text of project updates. We used the Gensim Python package LDA implementation (from GitHub.com) to execute LDA. The latter is known to run faster than other implementations and generates better topic segregation [16].  The three main inputs to the LDA topic model are the dictionary, the corpus, and the number of topics. Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] To avoid overfitting, we chose the one that derived the highest coherence value and the smallest number of. topics. There were 30 topics that derived. the highest. coherence values for the All_D dataset, 15 for the Tech_D and 15 for Market_D datasets.

section 6 - (1) How many topics were in the All_D dataset? --- The All_D dataset had 30 topics. The Tech_D had 15 topics. and the Market_D was 15 topics for the All_d dataset. The total number of topics was 30. The final answer: 30.
 ['The All_D dataset had no pre-assigned semantic label, but there was already such a task called Named Entity Distilization proposed by Noth', 'The All_D dataset had around one million different sentences as well, however this number represents two-thirds instead outstands to half since all titles did', 'The All_D dataset had been created for studying trends about various aspects such as trend modeling on twidata, topic modelling and their use to improve predictions', 'The All_D dataset had about double what percentage total crowd funding for all countries that was recorded, meaning we did not get sufficient amounts through an entire year', 'The All_D dataset had an almost similar mean average degree with GIFT49k as well which made one wonder what could have resulted if you did']
section 6 - (2) What did we do to avoid overfitting? --- To avoid overfitting, we chose the one that. derived the highest coherence value and the smallest number of topics. Then we chose one that derived. the highest. coherance value and smallest. number of. topic for the All_D dataset.
 ['To avoid possible effects due mainly or principally those caused by social context, data related at project scope and content have been removed because their presence', 'To avoid bias related for our approach by considering features that capture semantic relations between documents, such as entity name embeddings extracted from textual data sources', 'To avoid fitting all this information inside AI models, data scientist have used machine learning tools such as decision trees and Random Forest based regression algorithm', 'To avoid issues caused by limited number training samples, a two level approach was applied based on deep reinforcement and generative adversarial networks for text description', 'To avoid unnecessary over-parameterization, model evaluation relies exclusively on validation accuracy while only using training samples from a subset out among our labeled']
section 6 - (3) What did previous studies on crowdfunding use LDA to perform? --- topic analysis of text of project updates
 ['topic modelling instead is important for better understanding why and when a new company does well, compared with competitors who started competing at similar levels', 'topic analysis over user comments for detecting possible factors determining whether an event, topic or a company got selected as funding sources during several phases', 'topic modeling rather than Latent Dirichlet Allocation (LDA) or its extension for hierarchical multi-word terms model Hierarchical Probabilistic Topic Models with Collation and Discourse,', 'topic prediction is useful not only for understanding why these types are being considered and selected by their developers, but also how much more important', 'topic segmentation based text mining using Google Search Trends as feature representation and then classify them from a semantic category or tag space, instead classifying']
section 6 - (4) Which datasets had the highest coherence values? --- All_D dataset All_d dataset Tech_d and Market_d
 ['All_Dashboard and GitHub-BloomingCurves contain more comments than other collections, with around eight times or almost three folds', 'All_Dets vs NoCrowd Dataset Summary Information about all crowdsourced content detected on Google, Amazon web service or Yahoo for', 'All_Datas are composed by two parts which means that they represent both content and metadata related data together through one single schema, but their', 'All_Datasets, All3SetsForCorrectFollowers Dataset used a unique set(setnameID and Follower ID', 'All_Datasets, Wikipedia only as data sources and different classifiers are evaluated to see out what can improve these models on their semantic relevance towards']
section 6 - (5) What datasets did we use to test the LDA topic model? --- The three main inputs to the Latent Dirichlet Allocation (LDA) topic model are the dictionary, the corpus, and the number of topics. Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] To avoid overfitting, we chose the one that derived the highest coherency value and the smallest number of. topics for the All_D dataset, 15 for the Tech_D and 15 for Market_D.
 ['The second aim, however seems related and somewhat independent from any first step goal for this project that you have been thinking about with these', 'The research is inspired from this book chapter by Nascimento, Sampaio do Vallee and Lozano on CrowdF', 'The study was written up and approved for publication on September n, after it had passed an open discussion through email exchanges at CERN amongst', 'The question on a possible choice for Latent Dirichlet Allocation (LDA) parameters that was left unfinished at this step turned out not correct and should have been', 'The data that is currently being used for training machine learning-algorithms was downloaded automatically from public crowdsourcing platforms based on search engines and']
section 6 - (6)NP-BASED- What did previous studies use Latent Dirichlet Allocation (LDA) to analyze? --- text of project updates
 ['text of web-pages that have been analyzed by these algorithms was found for our investigation paper and not a random or even skewed collection from', 'text of comments and project websites for finding out whether those resources carry much information when it is combined from text data with images provided by contributors', 'text of online and physical messages for this approach has not previously addressed with a systematic investigation that is currently unavailable', 'text of articles on topic, like for us here or with sentiment tags such as positive and negative polarity is not that meaningful due a lot', 'text of funding campaigns with our aim towards developing a methodical analysis for project selection by selecting words and topics according an appropriate Latent Dirichlet Allocation (LDA) model,']
--------------------------------------------------
TEXT: We incorporated metadata features known to affect Funding Success. The metadata features we used were extracted from projects’ posts via Python web scraping. The set we used for our analysis included the number of photos, the. number of videos, the number. of updates, the. number of previously created projects by.

section 7 - (1) How were the metadata features extracted from projects? --- Python web scraping.
 ['Python based tool, called Semantic Text Normalization Language is used for normalization and translation among different language which include Dutch or Standard English to support', 'Python-powered code snippets can capture most semantic data available for research, making them a powerful tool with far reaching utility within', 'Python was selected and installed using pypython-2016a as an operating package for analysis steps to extract important data into', 'Python package to obtain and compare different datasets containing social network structure attributes, semantic properties along with their characteristics information was created for use by', 'Python, R scripts available upon request']
--------------------------------------------------
--------------------------------------------------
TEXT: We used the following metrics to measure the performance of our models. Recall is the ratio of correctly predicted positive records to the all records in actual class. F-score (also denoted F1) is the weighted harmonic mean of a model’s precision and recall.

section 9 - (1) What does the f-score measure? --- Model’s precision and recall are the same. F-score is the weighted harmonic mean of a model’s accuracy and recall. The final answer: accuracy.
 []
--------------------------------------------------
TEXT: We used a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects. We obtained these data from the Kaggle website for 2018. We used Beautifulsup (a Python web scraping package) to gain additional metadata features, such as, description content, number of updates, etc. For each record in the dataset, we obtained the values of five metadata features and about 120 semantic features, including buzzwords, Linguistic Inquiry and Word Count outputs, feelings words, explanation words, and Latent Dirichlet Allocation outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets.  To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the following analysis goals: First, it facilitates improvement in the LDA topic coherence score. Second, it allows us to determine whether a category affects the features that are highly correlated with Funding Success. Third, to study the correlation between buzzwords and FS, it is preferable for datasets to be separated into specific subdomains.  For each dataset, the original features space was reduced into three Principal Components The sum of the explained variance ratio of these three PCs is 78% of the total variance. To identify the most Significant Set of Features that has the highest impact on FS, we use the CFS (correlation-based feature selection) algorithm. The Principal Component Analysis plots in Fig 1 present the distribution of the All_D, Market_D and Tech_D datasets. Dots in blue represent unsuccessfully funded projects and red represent successfully funded projects.  The models’ design, derivation, and operational tests were conducted using the following Python packages: scikit-learn, scikits-feature and LightGBM. We employed a 10-fold cross-validation test to evaluate the prediction performance. Fig 2 includes a flowchart of the methodology. To validate the results of our study, we compared our model’s accuracy to previous research models by applying their methods on our dataset. To this end, we have developed the combined-model, whose novelty lies in the combination of semantic and meta-data features.

section 10 - (1) What did we develop? --- A combined Model for Funding Success (FS) in Kickstarter and Indiegogo projects.
 ['A literature synthesis to address RQ-2 and provide concrete evidence for research methods employed is conducted according  4) how many researchers use', 'A case example from one funder project is used as a vehicle for exploring what could potentially work if semantic techniques developed by software engineering', 'A preliminary view on what went and how to get into them from previous contributions as related bibliometry papers, which may shed light at', 'A qualitative exploration on developing a social networking framework and designing our own tools to support them, including their analysis by leveraging big data processing', 'A review paper about our experience regarding development and financing activities is given at beginning which illustrates that for large part financial issues remain beyond us']
section 10 - (2) What are the three datasets used to study the relationship between features and project categories? --- All_D, Market_D and Tech_D datasets
 ['All_D, Foursquare-based Semantic Distance Index for Facebook Communities', 'All_D, Samsung Databank from Google Trends database is considered which only records search queries related either on sports or politics terms within', 'All_D, is a big dataset which contains images annotated for semantic segmentation using FCN-VGG Model by training on PASCAL VOC database', 'All_D, BGP438291and EcoliK-PCBA) show similar tendencies that higher diversity makes good funding', 'All_D, MobiHealth2189CrowdFourDSV065-JULHPCMCSNQ']
section 10 - (3) What features were combined to create the combined model? --- A large dataset of Kickstarter and Indiegogo projects was used to train the model to predict Funding Success (FS). We used a combination of semantic and meta-data features to select and evaluate the most Significant Set of Features (MSSF). The model was tested on a 10-fold cross-validation test. The combined model was developed by combining the following features: buzzwords, sentimental words, feelings words, explanation words and Latent Dirichlet Allocation (LDA) topics.
 ['A B S E RV AT I V OF THIS ARTIC LE A RO Y P O STO PR IL IO D DATA,', 'A key point has not yet fully been understood as researchers attempt this new phenomenon and we could try something different than simply using traditional variables', 'A large set, covering over two and a half million public domain files on social networks was collected by crawling GitHub from its last', 'A novel combination analysis that measures all possible semantic elements from multiple models and then evaluates them by a classifier has been developed within this paper', 'A large dataset for evaluating factors affecting online social-media campaign growth was used, with a particular focus on characteristics associated both psychological constructs']
section 10 - (4) What does the division of the datasets do? --- The dataset used in this paper is a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects for 2018. We obtained these data from the Kaggle website for 2018. For each record in the dataset, we obtained the values of five metadata and about 120 semantic features, including buzzwords, Linguistic Inquiry and Word Count (LIWC) outputs, feelings words, explanation words, and Latent Dirichlet Allocation (LDA) outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets. To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the analysis goals: First,
 ['The aim being to assess what exactly is driving these correlations at this early state before analyzing them further by looking into data analysis as they', 'The purpose for applying data visualization tools is, inter alia what you know from literature about an object and how it relates to other', 'The dataset we have obtained is too large and diversified but nevertheless useful on one hand to build a model based mainly with semantic attributes,', 'The present paper investigates what factors could affect fund donors and their motivation towards participating on a given social media channel for different project types at', 'The goal is to develop machine translation tools for languages and dialects by improving human participation through annotation on multilingual web corpus that contain parallel']
section 10 - (5)NP-BASED- What did the authors filter out? --- projects with fewer than 10 lines of description
 ['projects with no content could therefore potentially have generated much revenue, so what had other factors to play a significant and even major r(7', 'projects with missing information or an absence during development was not addressed, especially since it could influence whether a funding opportunity exists for such cases)', 'projects with more successful results compared to similar size ones from another field was excluded due potential biases during literature research related for example, project sizes', 'projects with low or very few words are mostly failed, those that present more text may produce higher results as they represent real-life situations', 'projects with no value as much more effective that any project involving a business person on behalf off an external client-in other word to fund']
section 10 - (6)NP-BASED- What did the authors use Beautifulsup to gain? --- additional metadata features
 ['additional results not mentioned In table II, which includes three other sets-up and two testcases listed at p=0 by J', 'additional bibliographical details do not support an independent academic review or research synthesis and it was a study design article that relied only partially upon', 'additional support on this subject please cite me, efora is a full list at jesonresearch14523']
--------------------------------------------------
--------------------------------------------------
TEXT: In this section, we provide details of the data setup, the usage of the Latent Dirichlet Allocation algorithm, the feature correlation analysis, and the feature selection process. In what follows we describe the way in which we found the features that are most influential for Funding Success. The CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.  The semantic features buzzwords and Linguistic Inquiry and Word Count are among the features that have a higher correlation in all datasets. An important, unique conclusion of our study is that the features correlated to FS are dependent on the project category. Among the top 10 features, about 70% of the features are the same across datasets. For example, the features feelings_num and buzz_num appear in the three top 10 lists. In contrast, the parameter WC is unique in the R_Tech _D top 10 list and the parameter number is distinctive.

section 12 - (1) Buzzwords and Linguistic Inquiry have a higher correlation in what? --- all datasets
 ['a much smaller and very specific dataset', 'these data', 'each feature']
section 12 - (2) What does the CFS algorithm evaluate? --- CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.
 ['CFS algorithm as a new semantic method used for fundraising is discussed at different levels here and how has it made itself available within financial', 'CFS algorithm is used at Facebook, it takes into account all parameters to rank results for new candidates according our values on specific issues related and', 'CFS algorithm selects only those semantic properties that are significantly and positively correlated with our outcome variable, a high enough value out from other possible values', 'CFS algorithm evaluates many indicators based mostly on crowd-sourcing experience and personal intuition, so we should find other methods capable to detect hidden', 'CFS algorithm evaluates five factors, three from project-siccosis point to time and two relating them semantically as shown on table II']
section 12 - (3) What features are most influential for Funding Success? --- This paper describes the data setup, the usage of Latent Dirichlet Allocation (LDA) algorithm, the feature correlation analysis, and the feature selection process. We find that the following feature are most influential for Funding Success (FS): buzzwords Linguistic Inquiry Word Count Word %
 ['This descriptive exploratory, non-systematical study is set within an academic and industrial realworld environment involving companies that had completed a', 'This paper analyzes if certain project semantic, iOS device capability or network availability affect User Generated Content Creation Performance Index and how much financial', 'This question represents only one facet about understanding what makes a successful campaign go wrong, and this should hopefully inspire researchers not too long', 'This paper aims to reveal some semantic relations within social media discourse by applying an unsupervised clustering approach on a corpus consisting entirely or partially from', 'This paper analyzes factors that potentially can help understanding Funding Success (FS), to increase their quality and effectiveness when using crowd financing mechanisms based on donation models']
--------------------------------------------------
TEXT: For the development of the Semantic-Model, semantic features were used as input. We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN, and more) on All_D. Table 2 presents the accuracies metrics of the combined-model: Combined model.  The semantic-model we have developed is comparable in accuracy with the state of the art (metadata) models, exhibiting an accuracy level of 91.2%. The LightGBM algorithm exhibited a high accuracy level for all three datasets. In particular, the accuracy of the prediction model is greater than 94% for all datasets.

section 13 - (1) What did the LightGBM algorithm do for all three datasets? --- LightGBM algorithm exhibited a high accuracy level for all three datasets. In particular the accuracy of the prediction model is greater than 94% for all datasets in this study.
 ['LightGBM algorithm proved especially valuable to identify meaningful semantic features on data from crowd donation sites while minimizing unnecessary feature engineering that increases project cost-over', 'LightGBM algorithm showed that adding new categories and creating categorical splits as well had improved performance from original models, however there is no evidence demonstrating this', 'LightGBM algorithm used random forest based ensemble with several important factors, like gender and country to predict whether an individual will have a sustainable dream about', 'LightGBM algorithm worked best using textual content, so we had some unexpected data results here also.. In order to check if TextBERT really performed', 'LightGBM algorithm had two distinct modes, which can both perform better at this case than using any machine learning classifier or ensemble learner based on them']
section 13 - (2) On what dataset was the proposed model evaluated? --- The proposed models were evaluated on the following datasets: All_D.
 ['The proposed work includes an original and deep study concerning one single, challenging financial problem to address a large portion which has never been previously investigated', 'The proposed project classification system will have to consider a broader concept and be applied without any particular datasets but data collection through Internet would need considerable', 'The proposed article reports a thorough analysis carried out on different crowdsourcing and AI research sources by focusing their focus entirely to CrowdMind Open', 'The proposed technique presented results very similar if you will compare two datasets instead on one set, with values close to precision and recall between them', 'The proposed semantic algorithm takes input on two aspects when designing its architecture which include data type, and format with their different formats such as images']
section 13 - (3) What machine learning algorithms were used? --- For the development of the Semantic-Model, semantic features were used as input. We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN, and more) on All_D.
 ['For the project selection stage we are not analyzing whether they achieved good results from an economic point-of view but, what has already been', 'For the first experiment, as can be perceived from figure2(a) to Figure5_Synthetic Experiments for Real CrowdFund', 'For the second question on topic B, which one could you recommend among multiple options like k-NN algorithm that we have chosen above with', 'For the case with a limited number or categories, we need another solution to handle multicategories for training our data models which use several classification', 'For the first experiment with a semantic vector representing an image on Wikipedia it was discovered that, although some correlation existed between textual description and label']
section 13 - (4) What were semantic features used for? --- To develop the Semantic-Model, semantic features were used as input.
 ['To be fair I can only acknowledge that many companies use crowdsourcing services with varying degree without being certain about reasons behind it and if', 'To study what aspects influenced users and researchers to build, develop their applications etc that are helpful during this stage we looked specifically at Crow', 'To understand what characteristics are being measured with each question, it would help if you provided these descriptions from other sources where your analysis did', 'To gain a deeper understanding what exactly works and underwears, we analyze data coming from several case studies by exploring possible correlations existing', 'To provide a framework we suggest two kinds, syntactic elements as well semantical ones- that determine usefulness and value added which is defined']
section 13 - (5) What data set was the Semantic-Model developed on? --- 91.2% of the data was used for experiments. The Semantic-Model was developed on the data set All_D.
 ['91.2% of the data was obtained during three and only two years from March when one campaign became open, February with its official report to launch all funds gathered', '91.2% of the data was from Rede Globo, an independent global search engine owned and distributed by Amazon ECECON Ltd with a total amount close', '91.2% of the data was extracted for this project and collected during its execution with real patients who participated directly online) are needed to prove, through a statistical', '91.2% of the data was correctly identified as not applicable during pretraining and validation, i is that they contained only textual descriptions such has an abstract description or', '91.2% of the data was acquired and analysed with a semantic approach that involved expert knowledge about technology for analysing social media as we could only be able observe these']
--------------------------------------------------
TEXT: The study aims to examine whether the set of features we use for prediction and the dataset on which learning was applied deliver a better model by means of F-score accuracy. We trained the Latent Dirichlet Allocation-Model and the Metadata-Model with the algorithms that were used in the studies above, and with additional algorithms, including SVM, J48, Random forest, LightGBM, SDG, and DNN. This training was performed on All_D with 10-fold cross-validation.  F-score is used for consistency with the earlier studies to which we compare. Figure shows that the model we developed has the highest accuracy. The accuracy of the Semantic-Model is similar to that of the LDA-Model and the Metadata-Model.

section 14 - (1) What additional algorithms were used in addition to the ones used in the studies above? --- LSVM, J48, Random forest, LightGBM, SDG, and DNN
 ['LSVM, ANN are two example approaches which have received attention and may potentially improve over simple keyword co-clustering results that focus on word similarity', 'LSVM, ANN as deep networks are already considered and have proven quite helpful for some applications so you can assume that it should be applicable here', 'LSVM, AdaBoost Machine Learning and Decision Tough-Rare Sets are two novel classifiers that we have explored based on their performance across', 'LSVM, kmeans etc could be considered and are discussed below', 'LSVM, logistic regression are more or less often included among models created so far using features described for particular fund categories separately i c h v']
section 14 - (2) What does the figure show? --- This training is performed on all D datasets with 10-fold cross-validation. The model we developed has the highest accuracy.
 ['This article attempts at a deeper level than any similar recent literature on fundraising for social innovation which has attempted only qualitative, comparative', 'This article analyzes data regarding Facebook-based online forums and how this has driven or curtailed large financial investments using different variables which', 'This work tries to better understand what it says with respect that question about how much is involved, where exactly are we from a given', 'This study is done by researchers from Université Montanégaute, Toulouse) with funding provided through Swiss Research Foundation', 'This is a very interesting paper and I found several errors throughout as we know they were introduced by us when trying to analyze data using']
section 14 - (3) On what dataset was training performed? --- All_D with 10-fold cross-validation
 ['All_D with the highest impact, on the one-year funding total and shareability indicator during evaluation stage compared to its nonreplicating model', 'All_D with full metadata to enable researchers and project creators access through different tools without depending purely on one source that has been validated internally for', 'All_D with Semantika for project prediction and model assessment, 15837 labeled examples only containing categorical variables used to learn', 'All_D with no preprocessing, all models using default hyperparameters were trained for overfit control by only looking to model selection instead than optimization', 'All_D with semantic labels All features based on raw audio signal Only images Incorrect prediction is observed because data labeling problem are not addressed']
section 14 - (4)NP-BASED- What is the major effector of such differences? --- the set of features
 ['the authors have no contribution to report or disclaim anything that they are involved from either institution at large and as members thereof, other', 'the most common language with funding campaigns or, less commonly reported by donors are either Italian and English terms used for these categories can have', 'the most crucial factor influencing their longevity was perceived social distance with stalwarts, friends and peers among noncouponsor', 'the study presents evidence demonstrating that semantic content, i...', 'the impact from an economic side on different project objectives are compared using econometrics for three countries across four years, where it can clearly']
--------------------------------------------------
TEXT: The study is the first that investigates the relationship between Funding Success and buzzwords. The buzzwords feature is among the features that are highly correlated to FS compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model’s performance could be achieved via novel feature selection algorithms.

section 15 - (1) What feature is highly correlated to FS? --- Buzzwords feature
 ['The semantic features buzzwords feature', 'the topic–keyword distribution feature', 'terms feature', 'semantics feature']
section 15 - (2) What could be considered in future research? --- Model based on semantic features only. Model focusing on both project-specific aspects and semantics of project descriptions. Future research could further improve accuracy by considering the characteristics of images, video content and the semantics.
 ['Model-fitting methodology using generalized estimating equations for multivariate and censored data analyses with an application to a large fundraising study on Google', 'Model based predictions can guide investment decisions, which might save researchers time by reducing a large trial and error loop between candidate developers before getting', 'Model selection results support Hypothesis H6 with positive coefficient, thus a larger difference is expected to result more than smaller value change between post', 'Modelos de análise por meia das umidades socias-cultural as bases e atenciones baseadas em', 'Model validation based upon an artificial semantic network with three types connections and the randomisation approach is performed using simulation, to assess that if']
section 15 - (3)NP-BASED- What did the authors focus on? --- project-specific aspects and semantics of project descriptions
 ['project-specific project information was not found online or publicly available but could include any kind such data, which you consider relevant to evaluate whether fund', 'project-specific information like target funding rate, location etc should help researchers improve decision making or identify which specific factors are relevant to predict a successful', 'project-specific variables such as duration were less frequently mentioned compared to a large number from our dataset, this was not taken under consideration with regard', 'project-specific semantic properties should also be related with a changeable impact such as timeframe chosen according their respective business goals and financial goal)', 'project-specific aspects, such as project description and content development activities were taken into account instead... A systematic review could be designed for this type']
