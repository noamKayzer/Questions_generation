{"_id":"2851","attribs":{"courseNumber":"","institution":"","lecturer":"","semester":"","subTopic":"","year":""},"fileAttributes":[{"authors":["Rayan Krishnan Pranav Rajpurkar Eric J. Topol"],"doi":"doi:10.1038/s41551-022-00914-1","journal":"Rayan Krishnan Pranav Rajpurkar Eric J. Topol","title":"Self-supervised learning in medicine and healthcare"}],"key_concepts":[{"data":{"0":{"tag":"NP","wiki":"In machine learning, a common task is the study and construction of algorithms that can learn from and make predictions on data. Such algorithms function by making data-driven predictions or decisions, through building a mathematical model from input data. These input data used to build the model are usually divided in multiple data sets. In particular, three data sets are commonly used in different stages of the creation of the model: training, validation and test sets.\nThe model is initially fit on a training data set, which is a set of examples used to fit the parameters (e.g. weights of connections between neurons in artificial neural networks) of the model. The model (e.g. a naive Bayes classifier) is trained on the training data set using a supervised learning method, for example using optimization methods such as gradient descent or stochastic gradient descent. In practice, the training data set often consists of pairs of an input vector (or scalar) and the corresponding output vector (or scalar), where the answer key is commonly denoted as the target (or label). The current model is run with the training data set and produces a result, which is then compared with the target, for each input vector in the training data set. Based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. The model fitting can include both variable selection and parameter estimation.\nSuccessively, the fitted model is used to predict the responses for the observations in a second data set called the validation data set. The validation data set provides an unbiased evaluation of a model fit on the training data set while tuning the model's hyperparameters (e.g. the number of hidden units\u2014layers and layer widths\u2014in a neural network). Validation datasets can be used for regularization by early stopping (stopping training when the error on the validation data set increases, as this is a sign of over-fitting to the training data set).\nThis simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when over-fitting has truly begun.Finally, the test data set is a data set used to provide an unbiased evaluation of a final model fit on the training data set. If the data in the test data set has never been used in training (for example in cross-validation), the test data set is also called a holdout data set. The term \"validation set\" is sometimes used instead of \"test set\" in some literature (e.g., if the original data set was partitioned into only two subsets, the test set might be referred to as the validation set).Deciding the sizes and strategies for data set division in training, test and validation sets is very dependent on the problem and data available."}},"key":"training data","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model. It is closely related to oversampling in data analysis."}},"key":"data augmentation","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Supervised learning (SL) is a machine learning paradigm for problems where the available data consists of labelled examples, meaning that each data point contains features (covariates) and an associated label. The goal of supervised learning algorithms is learning a function that maps feature vectors (inputs) to labels (output), based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way (see inductive bias). This statistical quality of an algorithm is measured through the so-called generalization error."}},"key":"supervised learning","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Health data is any data \"related to health conditions, reproductive outcomes, causes of death, and quality of life\" for an individual or population. Health data includes clinical metrics along with environmental, socioeconomic, and behavioral information pertinent to health and wellness. A plurality of health data are collected and used when individuals interact with health care systems. This data, collected by health care providers, typically includes a record of services received, conditions of those services, and clinical outcomes or information concerning those services. Historically, most health data has been sourced from this framework. The advent of eHealth and advances in health information technology, however, have expanded the collection and use of health data\u2014but have also engendered new security, privacy, and ethical concerns. The increasing collection and use of health data by patients is a major component of digital health."}},"key":"health data","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Data acquisition is the process of sampling signals that measure real-world physical conditions and converting the resulting samples into digital numeric values that can be manipulated by a computer. Data acquisition systems, abbreviated by the acronyms DAS, DAQ, or DAU, typically convert analog waveforms into digital values for processing. The components of data acquisition systems include:\n\nSensors, to convert physical parameters to electrical signals.\nSignal conditioning circuitry, to convert sensor signals into a form that can be converted to digital values.\nAnalog-to-digital converters, to convert conditioned sensor signals to digital values.\nData acquisition applications are usually controlled by software programs developed using various general purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc. Stand-alone data acquisition systems are often called data loggers.\nThere are also open-source software packages providing all the necessary tools to acquire data from different, typically specific, hardware equipment. These tools come from the scientific community where complex experiment requires fast, flexible, and adaptable software. Those packages are usually custom-fit but more general DAQ packages like the Maximum Integrated Data Acquisition System can be easily tailored and are used in several physics experiments."}},"key":"data acquisition","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"An image is a visual representation of something. It can be two-dimensional, three-dimensional, or somehow otherwise feed into the visual system to convey information. An image can be an artifact, such as a photograph or other two-dimensional picture, that resembles a subject. In the context of signal processing, an image is a distributed amplitude of color(s).In optics, the term \u201cimage\u201d may refer specifically to a 2D image.\nAn image does not have to use the entire visual system to be a visual representation. A popular example of this is of a greyscale image, which uses the visual system's sensitivity to brightness across all wavelengths, without taking into account different colors. A black and white visual representation of something is still an image, even though it does not make full use of the visual system's capabilities.\nImages are typically still, but in some cases can be moving or animated."}},"key":"images","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Self-supervised learning (SSL) refers to a machine learning paradigm, and corresponding methods, for processing unlabelled data to obtain useful representations that can help with downstream learning tasks. The most salient thing about SSL methods is that they do not need human-annotated labels, which means they are designed to take in datasets consisting entirely of unlabelled data samples. Then the typical SSL pipeline consists of learning supervisory signals (labels generated automatically) in a first stage, which are then used for some supervised learning task in the second and later stages. For this reason, SSL can be described as an intermediate form of unsupervised and supervised learning.\nThe typical SSL method is based on an artificial neural network or other model such as a decision list. The model learns in two steps. First, the task is solved based on an auxiliary or pretext classification task using pseudo-labels which help to initialize the model parameters. Second, the actual task is performed with supervised or unsupervised learning. Other auxiliary tasks involve pattern completion from masked input patterns (silent pauses in speech or image portions masked in black). Self-supervised learning has produced promising results in recent years and has found practical application in audio processing and is being used by Facebook and others for speech recognition. The primary appeal of SSL is that training can occur with data of lower quality, rather than improving ultimate outcomes. Self-supervised learning more closely imitates the way humans learn to classify objects."}},"key":"contrastive learning","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Machine learning (ML) is a field of inquiry devoted to understanding and building methods that 'learn', that is, methods that leverage data to improve performance on some set of tasks. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.A subset of machine learning is closely related to computational statistics, which focuses on making predictions using computers, but not all machine learning is statistical learning. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning. Some implementations of machine learning use data and neural networks in a way that mimics the working of a biological brain.  In its application across business problems, machine learning is also referred to as predictive analytics."}},"key":"machine learning","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Deep learning  (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks,  convolutional neural networks and Transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains.  Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.The adjective \"deep\" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, hence the \"structured\" part."}},"key":"deep learning","order":["0"],"using":true},{"data":{"0":{"tag":"NP","wiki":"Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks.  This area of research bears some relation to the long history of psychological literature on transfer of learning, although practical ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent."}},"key":"transfer learning","order":["0"],"using":true}],"level":1,"permission":"private","rank":{"by":1,"value":5},"sections":{"0":{"original":{"images":["https://api.leminda.com/summary/2851/img/10790.png","https://api.leminda.com/summary/2851/img/10791.png"],"state":0,"text":"Artificial intelligence (AI) has been driven by advancements in deep learning and in the creation of datasets. Algorithms for medical AI have been developed on medical tasks intended to diagnose, predict and recommend treatments across a variety of medical modalities and data types, such as electronic health records (EHRs), chest X-rays, electrocardiograms and protein sequences1. When building algorithms for medical AI, a central challenge is their reliance on the availability of annotated input data at scale, often in the hundreds of thousands, if not millions, of datapoints. Addressing this bottleneck would enable the development of accurate AI algorithms for a much broader range of tasks in health and disease, from diagnostics to monitoring to treatment decisions. In this Review, we highlight recently developed and promising sets of techniques in self-supervised learning, and their challenges and opportunities when used in medicine and healthcare. Deep learning is the dominant approach for developing medical AI. However, the success of its applications relies heavily on the availability of annotated datasets. Deep-learning models are typically trained using a supervised-learning paradigm, where the models learn to map an input (such as a chest X-ray image or a health record) to an output (for example, a diagnosis of pleural effusion, or the prediction of myocardial infarction). For the models to learn relevant patterns in the data, training them via supervised learning requires large datasets in which each input is annotated with its corresponding output. However, much more emphasis has been placed on building and testing models than on the heavy-lifting work of building annotated datasets. This is partly because, for most medical tasks, building the required large datasets would prove inordinately expensive2. Still, there has been insufficient commitment to expand the resources needed to create such annotated datasets. For common image types, such as chest X-ray images, images of skin lesions, retinal photographs and brain computed-tomography scans, the existing datasets have been repeatedly used. Medical datasets carefully annotated by experts are hard to create at scale. Non-medical deep-learning models have been incredibly successful when trained on ImageNet, which harnessed 49,000 Mechanical Turk workers (Amazon\u2019s Mechanical Turk is a crowdsourcing marketplace for outsourcing tasks that typically require human intelligence) and hundreds of academics and citizen scientists to label approximately 15 million images of 21,000 classes (such as \u2018broccoli\u2019 and \u2018hummingbird\u2019)3. However, the labelling of medical datasets requires experts and considerable time. Interpreting a medical image, such as a tissue slide or electrocardiography (ECG) data, typically demands even more time per image than the labelling of natural objects or other diagnostic data used in clinical practice. For instance, chest X-ray images in the CheXpert dataset4 were labelled at an estimated rate of 2\u20135 min per study, whereas image samples from ImageNet were labelled at an average rate of 50 images per minute3. In addition, methods for automated labelling\u2014which have enabled weakly supervised learning, a technique that leverages noisy or imprecise sources to alleviate the burden of obtaining hand-labelled datasets\u2014often require domain expertise and substantial development time. A related challenge is the vital need of datasets to be comprehensive and to fully represent the diversity of the data (in particular, of the relevant pathologies and patients). Because medical domains are difficult to label, one method to build more capable models is to train them on a large and general dataset such as ImageNet, and then re-train the models on the smaller and specific medical task. In many applications, such a process of transfer learning (from a general domain to a specific domain) has allowed models to perform better than those trained from scratch5. However, applying transfer learning to the training of models for medical AI has an inherent problem: the first training task is typically not medically relevant, so the characteristics that the model learns may not be valuable for the medical task. Self-supervised learning is a better method for the first phase of training, as the model then learns about the specific medical domain, even in the absence of explicit labels. Unlike labelled datasets, which are difficult to create, unlabelled medical data are plentiful. These include images, gene or protein sequences, electronic health records and pathology slides that have been collected from patients but not explicitly labelled with a diagnosis. Unlabelled datasets can be leveraged to build self-supervised models that learn complex structures in the data via new The development of medical applications of machine learning has required manual annotation of data, often by medical experts. Yet, the availability of large-scale unannotated data provides opportunities for the development of better machine-learning models. In this Review, we highlight self-supervised methods and models for use in medicine and healthcare, and discuss the advantages and limitations of their application to tasks involving electronic health records and datasets of medical images, bioelectrical signals, and sequences and structures of genes and proteins. We also discuss promising applications of self-supervised learning for the development of models leveraging multimodal datasets, and the challenges in collecting unbiased data for their training. Self-supervised learning may accelerate the development of medical artificial intelligence. supervised-learning tasks; for example, by occluding portions of the data and expecting the model to predict what has been hidden, or by providing two samples from the same patient and training the model to associate them strongly. After such preliminary training, these general models can be trained again on a much smaller set of labelled examples for the final medical task. In such a first phase of training, the models are trained on a preparation task, referred to as a \u2018pretext task\u2019. Because the data used for such pretext tasks are unlabelled, the trained model cannot yet solve the primary task. Instead, after being trained on a pretext task, the model, referred to as a \u2018featurizer\u2019, can take an input sample and output a vector of numbers that represent the important aspects of the input in a machine-readable form. This pretext training phase is valuable because the model can learn how to find useful features or attributes in the data, even before seeing any labelled data. In the second phase of training, the featurizer is trained on a dataset of explicit labels. This enables the model to incorporate its knowledge of the data to perform the relevant medical task. In what follows, we highlight specific examples of self-supervised pre-training tasks across medical domains and data types in its two major forms: contrastive learning and generative learning6,7. contrastive learning The primary objective of pre-training a model with contrastive learning is to make the model associate similar samples and dissociate dissimilar samples. The task for the model consists of predicting whether a pair of samples are positive pairs (hence, are closely related) or negative pairs (and thus unrelated). The data may already be naturally structured for this setup. For example, a face-detection dataset may have many photos of each subject\u2019s countenance. In this case, photographs of the same person would make positive pairs, and photographs of different people would constitute negative pairs. Ideally, the featurizer should take two images as input, and produce two corresponding vectors that are numerically similar to one another if the images are positive pairs (and numerically far from one another if the images are negative pairs)6\u20138. By receiving many pairs and predicting whether they are positive or negative, the model becomes a strong featurizer, increasingly recognizing relevant information in the images. When the model has achieved a sufficiently comprehensive \u2018understanding\u2019 of the properties of the data, it is then trained explicitly on the available set of labelled data, where the input is a particular face and the expected output is a name. Case studies. The most widely used strategy to generate training data for the contrastive-learning pretext task involves data-augmentation techniques. Data augmentation is the process by which minor changes to the data can be made to create new samples6,9. For example, images can be slightly cropped or rotated to create a distinct image that has the same content as the original image, or reflected to create a new corresponding image (Fig. 1). Because the subject and content of the image remain the same, altered pairs of the same original image are positive pairs, whereas altered versions of different original images are negative pairs. Depending on the data used, different augmentation techniques can be applied. For example, contrastive-learning augmentation techniques can also be applied to diagnose heart and lung diseases from digital stethoscope data10. This methodology has also shown its potential in work that has applied a version of contrastive learning to chest X-ray diagnosis9,11\u201313. In what follows, we highlight how this technique can be combined with other data variants. First, we describe applications for medical-image and sensing modalities, and then for sequence data or structured data, such as molecules and DNA sequences. When multiple scans or samples are taken from the same patient, a multiple-viewpoint method can be applied. These multiple views can be used directly as positive pairs for the contrastive-learning task. One study14 worked with chest X-ray data with both lateral and frontal scans and with dermatology data with photos from different perspectives (where only a single view was available, a data-augmentation step was used to generate image pairs; where two views existed, a minor data-augmentation approach was used on the distinct frames). Another study showed that data augmentation using multiple views of the same patient performed best for the generation of positive pairs for training diagnostic models based on chest X-ray images15. Self-supervised learning is particularly applicable for classification tasks based on histology slides, which are particularly challenging to annotate. In histology-based diagnosis, every sample contains a microscopy image of many cells, each of which may be cancerous. Each sample contains many cells, and the sample is considered cancerous if at least one cell in the image exhibits cancerous features. Traditionally, data have been labelled for this task by having an expert painstakingly annotate regions of pixels according to whether the regions contain cancerous or non-cancerous cells. Instead, unlabelled data can be used to create a self-supervised pre-training task by selecting sub-patches from the slide to use as positive pairs16\u201318. This relies on the patch of cells following the property that if one cell exhibits a label, all instances in the window share that same label. This methodology was developed further by using a self-supervised knowledge-distillation process to build an effective \u2018student\u2019 model that could classify lower-resolution images19. In addition to its applicability to spatially structured data, self-supervised learning can also be applied to data collected across time. For example, ECG data (if collected from multiple leads) are both spatially and temporally structured, and in conjunction with data-augmentation techniques have allowed models to generate spatiotemporal associations for the same underlying patient and disease20,21. In fact, physiologically rooted data-augmentation techniques can offer superior pre-training performance22. Because videos have both spatial and temporal variations (the contents of a single frame belong to the same space, and frames are collected across time), self-supervised learning has also been applied to natural videos and more recently to medical videos. For instance, a model for the interpretation of ultrasound videos was pre-trained in two phases23. In the first phase, video frames were shuffled, and the model was trained to predict the correct ordering of the frames to support the model\u2019s \u2018understanding\u2019 of temporality. In the second phase, a frame underwent a geometric transformation (such as rotation or translation), and the model was trained to predict the original frame. These techniques of data augmentation (also when using multiple views) can be applied to other data types and tasks, such as the discovery of small-molecule drugs24. The task of using molecular structure to predict molecular properties is constrained by the limited number and size of labelled datasets and by the large space of molecules and molecular structures. By assuming that molecules with a similar structure have similar properties, one can create a positive pair of structures by applying a data-augmentation technique that randomly removes some atoms in the structure to create a modified version of the original. Molecules can also be augmented by randomly removing some bonds, or by removing whole portions of atoms and bonds from parts of the molecule25. For protein structures, similar strategies have been used; specifically, predicting the spatial distance between acids in the protein as well as missing edges in the structure26. Notably, a graph neural network trained on 10 million unlabelled molecules was more interpretable than previous models, and generated clear representations of molecules by topographical structure and functional groups26. Self-supervised techniques have also been applied to DNAsequencing data27 to determine whether DNA fragments align, as well as differences in the number of mutations irrespective of alignment. To do this, self-supervised learning can be applied by training  Fig. 1 | contrastive learning. a, Example of a self-supervised pretext task, in which a fundus retinal image is rotated and the self-supervised learning model learns to predict the original image by evaluating the difference in rotation angle \u03b8. b, A pretext task in which a fundus retinal image is augmented via horizontal reflection. An encoder model is trained to produce similar embeddings (representations of discrete variables as continuous vectors) across the two images. c, Examples of positive data pairs used in contrastive learning. From top to bottom: two rotations of the same X-ray image; two spatial views of the same patient; two time points of an ECG trace; two chemical structures of a small molecule differing slightly in chemical bonding (red); two data modalities: X-ray image and a textual description of it. a model to predict a known number of mutations applied to a reference sequence; the model can then be used to predict the pairwise identity scores of sequences. generative learning In generative pre-training, defining labels allows for the application of supervised-learning techniques to self-supervised learning. For instance, Wikipedia does not contain any definitions for the words in the corpus, and hence does not have any labels for individual words. However, because sentences are structured as an ordered sequence of words, such structure can be used to frame a new supervised-learning task where words in a sentence are randomly blanked out (masked) and the model is expected to use the context of the surrounding words to predict the masked word (Fig. 2). The masked word can then be re-obtained from the original text (and, therefore, there is an explicit \u2018right answer\u2019 that the model can be trained to predict). In fact, this procedure of learning the meaning of words via contextual clues is one way that we all use to guess the meaning of new words. A model that can successfully predict the missing word must also \u2018understand\u2019 its meaning (and hence, it can effectively \u2018read\u2019), and this ability can be used to perform a specific task, such as identifying key topics in a piece of text. Case studies. Text-masking techniques can be easily extended to tasks in the medical domain, such as tasks involving EHRs or protein sequences (which can also be treated as text)26,28\u201332. Time-series data (such as electroencephalography scans) can be used to frame a pre-training problem for the prediction of the next period (such as the next waveform)33,34. In addition, images, which can be pre-trained via contrastive loss, can also be used for generative tasks35 by blocking out parts of the image and training the model to fill what was removed. Masked-word pre-training (guessing the hidden word via context words) has been extensively used after the development of transformers\u2014a state-of-the-art class of neural-network architectures for language tasks36. These models work by taking a sequence of tokens (individual words in sentences, for example), identifying the connections between each token, constructing a representation of the sequence and using the representation to produce an output sequence. Transformers have recently been applied to non-textual data, including images and protein structures. Notably, a transformer-based design was used to build models that can take arbitrary input data to learn representations of the data37\u201339. A model might do this by using one modality of input to filter or augment the information available in another data modality (this is known as \u2018cross attention\u2019). These multimodal featurizers can be used in downstream tasks that make use of more than one data modality as input. A direct application of generative self-supervised learning is the parsing of EHRs. Masked-word pretext tasks can be applied to EHRs because they contain textual information (background information of patients, such as gender, weight and height, as well as information recorded by doctors during patient visits). Models trained to make sense of EHRs can be used to predict the likelihood of patients developing diseases, which may enable more accurate early-disease detection28,30,31. For instance, a model adapted from the model known as BERT (for bidirectional encoder representations from transformers) to work with EHRs (the BEHRT model) was trained on a dataset of 1.6 million patients to predict disease likelihood for 301 pathologies28 (the more recent Med-BERT model expanded the training dataset to 28 million patients30). These models could be trained on such large datasets because they were structured as text sequences for self-supervised masked pre-training (the data did not need to be manually labelled). Generative language models can also be applied to protein sequences. Sequences are easy to collect, but it is difficult to label  Fig. 2 | generative pre-training. a, Example of pre-training with a masked-language model. The original text sequence has a random word masked, and the model is trained to restore the masked word. An encoder\u2013decoder model is used to generate a \u2018hidden\u2019 numerical representation (z) of the data. This can also be performed on medically relevant text and on other data types. b, The trained word-guessing model depicted in a can be used to solve particular medical tasks, such as disease detection from text. The blue, red and orange backgrounds denote inputs, vector representations (embeddings) and model predictions, respectively. c, Examples of data types for which generative self-supervised learning has been applied. From top to bottom: free text and structured text from EHRs; protein sequences and structures; bioelectric waveforms from the brain (from electroencephalography) and the heart (ECG traces). them for structure and function. Techniques for natural language processing have been applied directly as a pre-training task for protein data by framing them as supervised tasks for predicting the structure or functions of proteins with partially masked sequences40,41. During training, such models randomly mask parts of a hidden representation embedding and predict what was missing42. In addition to using generative techniques, a self-supervised contrastive-learning task can be constructed by creating positive protein fragments taken from the same protein sequence, as well as negative pairs from fragments from different sequences43. Such a pre-trained model can then be applied to other tasks, such as predicting a protein\u2019s secondary structure, stability or function. Benefits and limitations Self-supervised learning is primarily limited by the difficulty in finding and selecting useful pre-training tasks. There is no indication that applying a language-masking method will necessarily result in a high-performing model. For contrastive learning, the performance of the model is highly dependent on the data-augmentation technique used. Existing work is mostly empirical, relying on testing many different pretext tasks to identify which tasks are most useful. In some cases, it seems that having domain knowledge about the data and their structure may suggest augmentation techniques that are relevant for the particular data type15,44. After self-supervised training, some models have required fewer labelled examples to reach the same performance than models trained only through supervised learning (for instance, a self-supervised model for chest X-ray images used less than 10% of the labelled data to match the performance of a supervised model11). The implication is that new medical diagnosis tasks with limited labelled samples could be addressed using machine learning. This is particularly meaningful for rare pathologies, for which building datasets is naturally more difficult. Although applications of self-supervised learning to medical tasks are currently few, the models have in many cases met or exceeded the performance of their strongly supervised counterparts45,46. For example, using X-ray images and radiologist reports for pre-training, a self-supervised diagnosis model using only 1% of the labelled data met or exceeded the performance of baseline models. Similarly, a self-supervised model for the detection of diabetic retinopathy using only 25% of the labelled data performed similarly to other supervised models47. Self-supervised pre-trained models require fewer labelled examples for training due to faster convergence48. Improvements in accuracy with limited labelled data have been attributed to the ability of self-supervised models to first learn what features to consider as meaningful differences. In fact, self-supervised models can learn to segment images into particular objects without any labels (as exemplified by the Distillation with NO Labels model49 which, after training with paired image data without any segmentation labels, correctly identified pixels belonging to different object classes). Multiple-instance learning and multiple-viewpoint learning have produced models that are not misled by minor changes in the data14. In these training paradigms, images with different perspectives of the same object or pathology are considered similar (positive pairs), and thus the erroneous differences in perspective are not considered to be important features. For instance, if models consider two photos of different perspectives as positive pairs, they may associate important features with the subject of the photos rather than with their perspective. Strongly supervised models are liable to shortcut learning50 by associating erroneous distortions of facets of the image with the label. This is commonly seen in models that rely on image backgrounds more heavily to predict the subject51. Instead, self-supervised models trained using data augmentation can produce models that are less vulnerable to minor visual distortions. Hence, by using data-augmentation techniques (for images, rotation, cropping or brightness alterations, for example), the models can learn to avoid associations with these types of image variation. Although some supervised-learning methods may be robust to such distortions, they may not generalize that well to out-of-distribution tests. This lack of generalization has been effectively counteracted by more extensive augmentation, reinforcing the importance of data augmentation for the success of contrastive learning52 (in early work using mammograms for the detection of cancerous lesions, self-supervised methods have generalized better53). However, generalization depends on the task of interest and data-augmentation strategy. Forthcoming developments The uses of self-supervised learning for tasks in medical diagnosis thus far are suggestive of forthcoming progress. One main advantage of self-supervised techniques is that they can more easily make use of multimodal data. For example, the AI research and deployment company Open AI has combined text and image models into one model (named CLIP, for contrastive language-image pre-training)49 that can perform contrastive learning with the outputs of an image encoder and a text encoder. Another model (ConVIRT, for contrastive visual representation learning from text)11 can learn diagnostic labels for pairs of chest X-ray images and radiology reports. Contrastive learning can also be used to learn correlations between chest X-ray images and their reports, to generate text reports for new X-ray images (the CXR-RePaiR model)54. Another model leveraged the labelling of retinal fundus images with retinal-thickness values (obtained via optical coherence tomography) to build positive pairs for the pre-training of a model for the diagnosis of diabetic retinopathy52. After pre-training, the model relied only on the retinal images to classify them according to the severity of diabetic retinopathy. Pre-training with retinal-thickness data allowed the model to better \u2018understand\u2019 the most salient aspects in the retinal images; this improved its performance on the diagnostic task over that of a model trained solely with the retinal images. We expect that data from multiple medical tests or from patient information in EHRs will be increasingly used to create high-performance models that leverage self-supervised learning. Models trained with multimodal data may be created with two different goals. First, they may make use of multimodal data when they are deployed, which would make them more relevant in clinical settings. For example, if a patient\u2019s age, weight and blood pressure are recorded before performing an ECG exam, then the models can be trained to also make use of these data rather than be trained only on the ECG data. These two types of data are likely to contain different yet diagnostically useful information about the patient. Second, the models may be pre-trained with more extensive tests (not commonly performed at the time of diagnosis) to build featurizers that have a superior \u2018understanding\u2019 of the underlying disease. For example, the model that leveraged self-supervised learning for the diagnosis and classification of the severity of diabetic retinopathy used retinal-thickness measurements, which are not routinely collected in screening programs for the disease and thus were not available for the testing of the model. By using more expensive medical tests for pre-training, the self-supervised model learned relevant associations in the data (a more nuanced \u2018understanding\u2019 of how to interpret a fundus image; that is, a better representation of it) that may lead to performance improvements when using only the more limited tests available during model deployment. Featurizers can also use labelled data to perform other tasks in the medical domain. For instance, models can be trained to cluster patients into subgroups or to use specific types of patient. For example, by using contrastive learning to build a featurizer for chest X-ray images, a featurizer model was trained to identify patient groups that are most at risk of deterioration, even when labelled data are limited55. Another self-supervised method was trained on pathology slides to predict whether patients will show a response to a particular treatment56. The development of machine-learning models to predict the need for intervention and patient responses to treatments is relatively underexplored (with respect to the development of models for diagnostic tasks). Patient-specific models may aid the development of applications in personalized healthcare. Self-supervised learning may also allow for models that can interpret multimodal data across time. This includes multiple \u2018views\u2019 of a patient from different tests, as well as previous medical history and patient testimony. With the increased use of fitness trackers and the increasingly regular collection of health data, machine-learning models could help interpret extensive datasets that would be difficult for physicians to do on their own. Building models that rely on multimodal data will require compiling datasets that incorporate data from medical tests from many patients. Much of existing research in machine learning for healthcare revolves around improving diagnostic tasks in controlled settings (typically using retrospective datasets and comparing performance to those of individual experts), which is insufficient to demonstrate clinically relevant success for a model. Models relying on comprehensive multimodal data and self-supervised learning will probably lead to more reliable clinical implementations in real-world settings. It is essential to consider the consequences of overreliance on previously collected datasets. Models trained on biased data are vulnerable to become biased themselves57. This has been seen in the creation of large language models trained on open-text corpuses. For instance, models trained to translate from a language that lacks gender-specific pronouns into English showed bias for genders by occupation (for example, \u2018he is an engineer\u2019 and \u2018she is a nurse\u2019). In the medical domain, large language models have exhibited bias against females and minorities by recommending that pain medication not be prescribed58. In addition, gender-biased datasets yield models that perform better on the majority class59. To avoid perpetuating biases found in historical data, new data will need to be collected and scrutinized to meet high standards for quality. The need for the continuous collection of new data suggests that new systems will need to be built to support data acquisition for self-supervised models. Labelling services (such as Amazon Mechanical Turk) have become popular for procuring labelled large datasets, but to produce high-quality unlabelled datasets, new procedures and services will need to be developed. To create models ready for deployment, a priority is to ensure that the models are trained on unbiased data that match the data distribution of the deployment setting. To support this, new data-collection procedures that are not biased against certain patient subgroups can be implemented at the hospitals where the model will be deployed. In some cases, it may be more effective to create independent models by patient subgroup. Moreover, workflows that facilitate the labelling of data by medical experts as the patient is studied and tested, rather than after the data are collected, could be developed. Furthermore, labels could also be given to self-supervised groupings of the data. For instance, after clustering on self-supervised representations, medical experts could characterize key visual features shared between examples belonging to the same cluster and that are different from examples in other clusters60. These ideas would enable scalable methods for the building of large and heterogenous sets of high-quality unbiased data. Overall, by using large unlabelled datasets to pre-train machine-learning models, self-supervised learning improves the performance of downstream tasks. This is particularly relevant for training models to perform medical-diagnosis tasks for which large labelled datasets are difficult to procure. For contrastive-learning and generative-learning pretext tasks, data-specific augmentation strategies and techniques are needed. We postulate that, in many unexplored areas of medicine, self-supervised learning leveraging multimodal data will enable the creation of high-performing models that better \u2018understand\u2019 the underlying physiology.","title":"Self-supervised learning in medicine and healthcare"},"summary":{"images":["https://api.leminda.com/summary/2851/img/10790.png","https://api.leminda.com/summary/2851/img/10791.png"],"text":" Algorithms for medical AI have been developed on medical tasks intended to diagnose, predict and recommend treatments. The success of these applications relies heavily on the availability of annotated datasets. Addressing this bottleneck would enable the development of accurate AI algorithms for a much broader range of tasks in health and disease, from diagnostics to monitoring to treatment decisions. In this Review, we highlight recently developed and promising sets of techniques in self-supervised learning, and their challenges and opportunities when used in healthcare.  Medical datasets carefully annotated by experts are hard to create at scale. This is partly because, for most medical tasks, building the required large datasets would prove inordinately expensive. Still, there has been insufficient commitment to expand the resources needed to create such annotated datasets. For common image types, such as chest X-ray images, images of skin lesions, retinal photographs and brain computed-tomography scans, the existing datasets have been repeatedly used. Non-medical deep-learning models have been incredibly successful when trained on ImageNet.  The development of medical applications of machine learning has required manual annotation of data, often by medical experts. Unlike labelled datasets, which are difficult to create, unlabelled medical data are plentiful. Unlabelled datasets can be leveraged to build self-supervised models that learn complex structures in the data via new tools. The development is a better method for the first phase of training, as the model then learns about the specific medical domain, even in the absence of explicit labels.  We highlight self-supervised methods and models for use in medicine and healthcare. We discuss the advantages and limitations of their application to tasks involving electronic health records and datasets of medical images, bioelectrical signals, and sequences and structures of genes and proteins. We also discuss the challenges in collecting unbiased data for their training. We discuss promising applications for the development of models leveraging multimodal datasets, and the challenges of collecting unbiased. data to train models on a large set of labelled examples for the final medical task.  The primary objective of pre-training a model with contrastive learning is to make the model associate similar samples and dissociate dissimilar samples. The task for the model consists of predicting whether a pair of samples are positive pairs (hence, are closely related) or negative pairs (and thus unrelated) The data may already be naturally structured for this setup. When the model has achieved a sufficiently comprehensive \u2018understanding\u2019 of the properties of the data, it is then trained explicitly on the available set of labelled data.  Contrastive-learning augmentation techniques can also be applied to diagnose heart and lung diseases from digital stethoscope data. This methodology has also shown its potential in work that has applied a version of contrastive learning to chest X-ray diagnosis9,11\u201313. In what follows, we highlight how this technique can be combined with other data variants. We describe applications for medical-image and sensing modalities, then for sequence data or structured data, such as molecules and DNA sequences, and then for structured data.  Each sample contains many cells, and the sample is considered cancerous if at least one cell in the image exhibits cancerous features. Traditionally, data have been labelled for this task by having an expert painstakingly annotate regions of pixels according to whether the regions contain cancerous or non-cancerous cells. Instead, unlabelled data can be used to create a self-supervised pre-training task by selecting sub-patches from the slide to use as positive pairs. This relies on the property that if one cell exhibits a label, all instances in the window share that same label.  Self-supervised learning has also been applied to natural videos and more recently to medical videos. These techniques of data augmentation (also when using multiple views) can be applied to other data types and tasks, such as the discovery of small-molecule drugs24. For example, a model for the interpretation of ultrasound videos was pre-trained in two phases23. In the first phase, video frames were shuffled, and the model was trained to predict the correct ordering of the frames to support the model\u2019s \u2018understanding\u2019 of temporality.  Self-supervised techniques have also been applied to DNAsequencing data27 to determine whether DNA fragments align, as well as differences in the number of mutations irrespective of alignment. To do this can be applied by training an encoder model to produce similar embeddings (representations of discrete variables as continuous vectors) across the two images. In generative pre-training, defining labels allows for the application of supervised-learning techniques to self-Supervised learning. For instance, Wikipedia does not contain any definitions for the words in the corpus and hence does not have any labels for individual words.  A model that can successfully predict the missing word must also \u2018understand\u2019 its meaning (and hence, it can effectively \u2018read\u2019) Text-masking techniques can be easily extended to tasks in the medical domain, such as tasks involving EHRs or protein sequences. Time-series data (such as electroencephalography scans) can be used to frame a pre-training problem for the prediction of the next period. In addition, images, which can be pre-trained via contrastive loss, can also be used for generative tasks.  Masked-word pre-training (guessing the hidden word via context words) has been extensively used after the development of transformers\u2014a state-of-the-art class of neural-network architectures for language tasks. Transformers have recently been applied to non-textual data, including images and protein structures, including protein structures. A direct application of generative self-supervised learning is the parsing of EHRs.  Generative language models can also be applied to protein sequences and bioelectric waveforms from the brain (from electroencephalography) and the heart (ECG traces) can be used to solve particular medical tasks, such as disease detection from text.  Self-supervised learning is limited by the difficulty in finding and selecting useful pre-training tasks. The performance of the model is highly dependent on the data-augmentation technique used. The implication is that new medical diagnosis tasks with limited labelled samples could be addressed using machine learning. After training, some models have required fewer labelled examples to reach the same performance than models trained only through supervised learning. There is no indication that applying a language-masking method will necessarily result in a high-performing model.  This is particularly meaningful for rare pathologies, for which building datasets is naturally more difficult. Although applications of self-supervised learning to medical tasks are currently few, the models have in many cases met or exceeded the performance of their strongly supervised counterparts45,46,46. Self-Supervised pre-trained models require fewer labelled examples for training due to faster convergence48. Improvements in accuracy with limited labelled data have been attributed to the ability of models to first learn what features to consider as meaningful differences.  Strongly supervised models are liable to shortcut learning by associating erroneous distortions of facets of the image with the label. Self-supervised models trained using data augmentation can produce models that are less vulnerable to minor visual distortions. By using data-augmentation techniques, the models learn to avoid associations with these types of image variation. In early work using mammograms for the detection of cancerous lesions in mammograms have generalized better. The uses of self supervised learning for tasks in medical diagnosis thus far are suggestive of forthcoming progress.  We expect that data from multiple medical tests or from patient information in EHRs will be increasingly used to create high-performance models that leverage self-supervised learning. Contrastive learning can also be used to learn correlations between chest X-ray images and their reports. Another model leveraged the labelling of retinal fundus images with retinal-thickness values (obtained via optical coherence tomography) to build positive pairs for a model for the diagnosis of diabetic retinopathy.  Second, the models may be pre-trained with more extensive tests (not commonly performed at the time of diagnosis) to build featurizers that have a superior \u2018understanding\u2019 of the underlying disease. For example, the model that leveraged self-supervised learning for the diagnosis and classification of the severity of diabetic retinopathy used retinal-thickness measurements, which are not routinely collected in screening programs for the disease. Featurizers can also use labelled data to perform other tasks in the medical domain. For instance, models can be trained to cluster patients into subgroups or to use specific types of patient.  Machine-learning models could help interpret extensive datasets that would be difficult for physicians to do on their own. Building models that rely on multimodal data will require compiling datasets that incorporate data from medical tests from many patients. Models relying on comprehensive data and self-supervised learning will probably lead to more reliable clinical implementations in real-world settings. To avoid perpetuating biases found in historical data, new data will need to be collected and scrutinized to meet high standards for quality. Models trained on biased data are vulnerable to become biased themselves57.  New systems will need to be built to support data acquisition for self-supervised models. Labelling services (such as Amazon Mechanical Turk) have become popular for procuring labelled large datasets. To create models ready for deployment, a priority is to ensure that the models are trained on unbiased data that match the data distribution of the deployment setting. This is particularly relevant for training models to perform medical-diagnosis tasks for which large labelled datasets are difficult to procure. For contrastive-learning and generative-learning tasks, data-specific augmentation strategies and techniques are needed.  Self-supervised learning leveraging multimodal data will enable the creation of high-performing models that better \u2018understand\u2019 the underlying physiology.","title":"Self-supervised learning in medicine and healthcare"}}},"source":[""],"stats":{"length":{"original":4836,"summary":1554},"quality":{},"readability":{"original":16.0,"summary":15.0},"time":{"reading_time_original_text":14,"reading_time_saved":10,"reading_time_summary_text":5,"reduction_percentage":66}},"text_id":"63ac9c6cdcefcbf7cc133fb9","title":"Self-supervised learning in medicine and healthcare","topic":"Medical science","ts":1672256666,"user":"6316144a32fa3e3614c02e2f","userRecord":{"family_name":"\u05e7\u05d9\u05d9\u05d6\u05e8","given_name":"\u05e0\u05e2\u05dd \u05d3\u05d5\u05d3","name":"\u05e0\u05e2\u05dd \u05d3\u05d5\u05d3 \u05e7\u05d9\u05d9\u05d6\u05e8"}}
