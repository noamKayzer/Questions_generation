{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from tqdm.auto import tqdm\n",
    "%pdb on\n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "import re\n",
    "import spacy\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "#from sense2vec import Sense2Vec\n",
    "import torch\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, OPTForCausalLM,AutoModelForSeq2SeqLM\n",
    "except:\n",
    "    !pip install transformers\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, OPTForCausalLM,AutoModelForSeq2SeqLM\n",
    "from typing import List, Tuple\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer \n",
    "except:\n",
    "    !pip install sentence_transformers\n",
    "    from sentence_transformers import SentenceTransformer \n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class distractors_by_autoregressive_model:\n",
    "    def __init__(self,device='cpu',emb_model='all-MiniLM-L6-v2',\n",
    "                 autoregressive_model_checkpoint = \"facebook/galactica-1.3b\") -> None:\n",
    "        #\"facebook/galactica-1.3b\" \"facebook/galactica-6.7b\" \"EleutherAI/gpt-neo-1.3B\"\n",
    "        self.MODEL_EMBEDDING =  SentenceTransformer(emb_model)\n",
    "\n",
    "        self.DEVICE = device\n",
    "        self.USE_ANSWER_WITH_VARYING_SPANS = False\n",
    "        self.max_letters_in_word = 20 # more than `self.max_letters_in_word` letters in word suspected to be non-word sequence. \n",
    "\n",
    "        '''\n",
    "        checkpoint = \"EleutherAI/gpt-neo-1.3B\" #\"gpt2\" EleutherAI/gpt-neo-1.3B EleutherAI/gpt-neo-2.7B\n",
    "        MODEL = AutoModelForCausalLM.from_pretrained(checkpoint).to(DEVICE)\n",
    "        TOKENIZER = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        '''\n",
    "        #autoregressive_model_checkpoint = \"google/flan-t5-xl\"\n",
    "        #self.model = AutoModelForSeq2SeqLM.from_pretrained(autoregressive_model_checkpoint).to(device)\n",
    "        \n",
    "\n",
    "        self.model =  OPTForCausalLM.from_pretrained(autoregressive_model_checkpoint).to(device)\n",
    "        self.tokenizer =  AutoTokenizer.from_pretrained(autoregressive_model_checkpoint)\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        self.lemma_get = lemmatizer.lemmatize\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "    def get_answer_and_distractor_embeddings(self,answer,candidate_distractors):\n",
    "        answer_embedding = self.MODEL_EMBEDDING.encode([answer])\n",
    "        distractor_embeddings = self.MODEL_EMBEDDING.encode(candidate_distractors)\n",
    "        return answer_embedding, distractor_embeddings\n",
    "\n",
    "    def remove_prefix(self,text, prefix):\n",
    "        print('text',text)\n",
    "        print('prefix',prefix)\n",
    "        return text[len(prefix):].strip()\n",
    "        #return text.replace(prefix.strip(),'').strip()\n",
    "\n",
    "\n",
    "    def only_alphanumeric_punctuation(self,text):\n",
    "        match = re.search(\"^[\\w\\s\\d\\.,%=+:\\(\\)-]+$\", text)\n",
    "        return bool(match)\n",
    "    \n",
    "    def too_long_word(self,text):\n",
    "        #print([len(word) for word in text.split()])\n",
    "        match = [len(word) > self.max_letters_in_word for word in text.split()]\n",
    "        return any(match)\n",
    "    \n",
    "    def filter_outputs(self,outputs, prefix, answer):\n",
    "        outputs_filtered = []\n",
    "        answer_len = len(answer.split())\n",
    "\n",
    "        for output in outputs:\n",
    "\n",
    "            output = self.remove_prefix(output, prefix)\n",
    "\n",
    "            #if \"\\nAuthors\" in output: # for Galactica model\n",
    "            #    output = output[:output.find('\\nAuthors')]\n",
    "            output = output.replace(\"e.g.\",\"eg\").replace(\"i.e.\",\"ie\").replace(\"i. e.\",\"ie\").replace(\"e. g.\",\"eg\")\n",
    "            \n",
    "            # if \".\" not in output:\n",
    "            #     continue\n",
    "            if \".\" in output:\n",
    "        \n",
    "                output_split = output.split(\". \")  # consider take all sentences until the last dot. maybe depend on the answers length.\n",
    "\n",
    "                sentence_len = [len(out.split()) for out in output_split]\n",
    "                max_sentence_taken_idx = np.argmin(np.abs(np.cumsum(sentence_len)-answer_len))        \n",
    "                output_cut = \". \".join(output_split[:max_sentence_taken_idx+1])+\".\"\n",
    "\n",
    "            else:\n",
    "                output_cut = output\n",
    "            print('3 output_cut',output_cut)\n",
    "            #print(output_cut)\n",
    "            # if not self.only_alphanumeric_punctuation(output_cut):    \n",
    "            #     continue\n",
    "            if self.too_long_word(output_cut):\n",
    "                print('too long word')\n",
    "                continue\n",
    "            #if len(self.tokenizer.encode(output_cut)) > 2:\n",
    "            outputs_filtered.append(output_cut.strip().replace(\"\\n\",\" \"))\n",
    "\n",
    "        return outputs_filtered\n",
    "\n",
    "    def generate_distractors(self, question, answer,title=False,prefix=False):\n",
    "        if self.USE_ANSWER_WITH_VARYING_SPANS:\n",
    "            if len(answer.split()) <= 3:\n",
    "                num_words_to_add = (1,2)\n",
    "            elif len(answer.split()) <= 5:\n",
    "                num_words_to_add = (1,3)\n",
    "            elif len(answer.split()) <= 7:\n",
    "                num_words_to_add = (2,4)\n",
    "            elif len(answer.split()) <= 10:\n",
    "                num_words_to_add = (1,3,5)\n",
    "            else: \n",
    "                num_words_to_add = (2,4,6)\n",
    "            num_return_sequences = 10\n",
    "        else:\n",
    "\n",
    "            punct_or_stopwords_or_in_question = set([*stopwords.words('english'), *string.punctuation, *[self.lemma_get(qe.lower()) for qe in question.replace('?','').split()]])\n",
    "\n",
    "            num_words_to_add=[1]\n",
    "            for word in answer.split()[1:]:\n",
    "                if self.lemma_get(word.lower()) in punct_or_stopwords_or_in_question:\n",
    "                    num_words_to_add[0]+=1\n",
    "                else:\n",
    "                    break\n",
    "            if \" \".join(answer.split()[:num_words_to_add[0]]).strip().lower() in ['a','an','the']:\n",
    "                num_words_to_add[0]+=1\n",
    "            if len(answer.split())==num_words_to_add[0]:\n",
    "                # if all answer was selected as the prefix or by :\n",
    "                #       (1) The answer is only one word \n",
    "                #       (2) All the words from the question are in the answer.\n",
    "                #       The distractors cannot be made.\n",
    "                return False \n",
    "            num_return_sequences = 25\n",
    "        candidate_distractors = []\n",
    "        if not prefix:\n",
    "            if title:\n",
    "                prefix = title +\". \"+question +\" \" # \"Title: \"+title+\". \"+question + \" \"\n",
    "                #prefix = \"Title:\"+ title +\". Answer to the question: \"+question  # \"Title: \"+title+\". \"+question + \" \"\n",
    "                #prefix = \"Title:\"+ title +\". </s> Answer to the question: \"+question+\" </s> \"  # \"Title: \"+title+\". \"+question + \" \"\n",
    "                #prefix = \"Answer to the question: \"+question+\" /n/n Context: \"+ title +\". /n/n \"  # \"Title: \"+title+\". \"+question + \" \"\n",
    "                #prefix = \"Answer to the question: \"+question+\" </s> Context: \"+ title +\". </s> Answer: \"  # \"Title: \"+title+\". \"+question + \" \"\n",
    "                #prefix = f\"Context: {title}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "            else:\n",
    "                prefix = \"Answer to the question: \" + question \n",
    "            '''\n",
    "            if title:\n",
    "                prefix = \"Answer to the question: \"+question + \" Context: \"+title +\" \" # \"Title: \"+title+\". \"+question + \" \"\n",
    "            else:\n",
    "                prefix = \"Answer to the question: \" + question + \" \"\n",
    "            '''\n",
    "        if isinstance(prefix,list):\n",
    "            prefix_list = prefix\n",
    "        else:\n",
    "            prefix_list = [prefix]\n",
    "        #when `self.USE_ANSWER_WITH_VARYING_SPANS` is False, there is only one element in `num_words_to_add` so the for is with one iteration\n",
    "        for num in num_words_to_add:\n",
    "            for prefix in prefix_list:\n",
    "                prompt =  prefix + \" \".join(answer.split()[:num])+\" \"\n",
    "                print(prompt)\n",
    "                input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.model.device)\n",
    "                \n",
    "                # output_ids = self.model.generate(\n",
    "                #     input_ids, \n",
    "                #     do_sample = True, \n",
    "                #     min_length = len(self.tokenizer.encode(prompt)) + 5,\n",
    "                #     max_length = len(self.tokenizer.encode(prompt)) + 25+25,\n",
    "                #     top_p = 0.94, # 0.8 \n",
    "                #     top_k = 30,   #30\n",
    "                #     repetition_penalty  = 2.0, # 10.0,\n",
    "                #     temperature = 2.0,\n",
    "                #     num_return_sequences = num_return_sequences,\n",
    "                #     #early_stopping= True\n",
    "                # ).cpu()\n",
    "                \n",
    "                output_ids = self.model.generate(input_ids,max_new_tokens=100,repetition_penalty  = 10.0, diversity_penalty=float(10), # top_k = 20,do_sample=True,\n",
    "                               num_beams=5,num_return_sequences=5,num_beam_groups=5)\n",
    "                outputs = [self.tokenizer.decode(output, skip_special_tokens=True) for output in output_ids]\n",
    "                outputs = [ dist[:dist.find('\\n\\n')] \n",
    "                           if dist.find('\\n\\n') else dist\n",
    "                           for dist in outputs ]\n",
    "                print(len(outputs),outputs) \n",
    "                candidate_distractors += self.filter_outputs(outputs, prefix,answer)\n",
    "        if len(candidate_distractors)==0:\n",
    "            print('no candidate_distractors pass filtring')\n",
    "            return False\n",
    "        answer_embedding, distractor_embeddings = self.get_answer_and_distractor_embeddings(answer, candidate_distractors)\n",
    "        #distractors = self.mmr(answer_embedding, distractor_embeddings, candidate_distractors, reverse=True, top_n=5, diversity=0.8)\n",
    "        distractors = candidate_distractors\n",
    "        if distractors: # remove multipile spaces\n",
    "            distractors = [' '.join(d.split()) for d in distractors]\n",
    "        print('+'*30)\n",
    "        print(f'{question} ----- {answer}')\n",
    "        for i,d in enumerate(distractors):\n",
    "            print(f'({i})-{d}\\n')\n",
    "        return distractors\n",
    "\n",
    "    def mmr(self,\n",
    "        doc_embedding: np.ndarray,\n",
    "        word_embeddings: np.ndarray,\n",
    "        words: List[str],\n",
    "        top_n: int = 5,\n",
    "        diversity: float = 0.8,\n",
    "        reverse: bool = False\n",
    "    ) -> List[Tuple[str, float]]:\n",
    "\n",
    "        keywords_idx = [np.argmin(cosine_similarity(word_embeddings, doc_embedding))]\n",
    "        doc_embedding = word_embeddings[keywords_idx[0]].reshape(1, -1)\n",
    "        # word_embeddings = [emb for idx,emb in enumerate(word_embeddings) if idx not in keywords_idx]\n",
    "        word_similarity = cosine_similarity(word_embeddings)\n",
    "        word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "        \n",
    "\n",
    "        candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "        # print(words[keywords_idx[0]])\n",
    "\n",
    "        for _ in range(min(top_n - 1, len(words) - 2)):\n",
    "            # Extract similarities within candidates and\n",
    "            # between candidates and selected keywords/phrases\n",
    "            candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "            target_similarities = np.max(\n",
    "                word_similarity[candidates_idx][:, keywords_idx], axis=1\n",
    "            )\n",
    "\n",
    "            # Calculate MMR\n",
    "            mmr = (1 - diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "            mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "            # Update keywords & candidates\n",
    "            keywords_idx.append(mmr_idx)\n",
    "            candidates_idx.remove(mmr_idx)\n",
    "\n",
    "        # Extract and sort keywords in descending similarity\n",
    "        keywords = [\n",
    "            (words[idx], round(float(word_doc_similarity.reshape(1, -1)[0][idx]), 4))\n",
    "            for idx in keywords_idx\n",
    "        ]\n",
    "        keywords = sorted(keywords, key=itemgetter(1), reverse=True)\n",
    "        return [kw[0] for kw in keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/lib/python3.9/site-packages/transformers/generation/beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ['The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large (n=1,034) dataset was collected from a leading online crowdfunding platform and analyzed to understand how semantic features affect project success. The results show that there is no significant difference between successful and unsuccessful projects with respect to their average number of words per sentence or vocabulary size. However, they found that more than half of the top-5 most frequent words are related to fundraising activities such as “raise”, “fund”, “support”, etc.', 'The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 12-month dataset from one major online fundraising platform, Kickstarter was analyzed to understand how semantic features affect project outcomes. The results show that a combination of textual and non-textual information can be used to predict whether or not a given funding opportunity will succeed.\\n* How does this work compare with other studies on text mining for crowdfunding? This paper is an extension of our previous study which focused on predicting successful campaigns using only textual data3', 'The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 5-year dataset from a major US startup company, which includes over 10 million dollars raised by more than 237K investors and has been used to study many aspects of crowdfunding such as fundraising strategies or investor behavior. The data is collected through an online platform called Indiegogo that allows users to create their own campaigns with different types of content: news, videos, music, etc.\\n* How does this paper contribute to the literature on crowdfun', 'The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large \"crowdfunding corpus\" is used to study how semantic features affect project success, and what are the most important ones.', 'The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 2016 study by a team led by Professor David Wurgler at Harvard University, which analyzed over 35 million dollars raised from more than 47 thousand crowdfunding campaigns and found that semantic similarity between funding proposals is an important factor for successful fundraising efforts.\\n* The impact of social media on online finance: How does Twitter affect investors’ decisions to invest or not? This paper presents results obtained through experiments with real data collected from two different sources – one base']\n",
      "text The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large (n=1,034) dataset was collected from a leading online crowdfunding platform and analyzed to understand how semantic features affect project success. The results show that there is no significant difference between successful and unsuccessful projects with respect to their average number of words per sentence or vocabulary size. However, they found that more than half of the top-5 most frequent words are related to fundraising activities such as “raise”, “fund”, “support”, etc.\n",
      "prefix The role of semantics in the success of crowdfunding projects. What do the authors analyze? \n",
      "3 output_cut A large (n=1,034) dataset was collected from a leading online crowdfunding platform and analyzed to understand how semantic features affect project success.\n",
      "text The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 12-month dataset from one major online fundraising platform, Kickstarter was analyzed to understand how semantic features affect project outcomes. The results show that a combination of textual and non-textual information can be used to predict whether or not a given funding opportunity will succeed.\n",
      "* How does this work compare with other studies on text mining for crowdfunding? This paper is an extension of our previous study which focused on predicting successful campaigns using only textual data3\n",
      "prefix The role of semantics in the success of crowdfunding projects. What do the authors analyze? \n",
      "3 output_cut A large 12-month dataset from one major online fundraising platform, Kickstarter was analyzed to understand how semantic features affect project outcomes.\n",
      "text The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 5-year dataset from a major US startup company, which includes over 10 million dollars raised by more than 237K investors and has been used to study many aspects of crowdfunding such as fundraising strategies or investor behavior. The data is collected through an online platform called Indiegogo that allows users to create their own campaigns with different types of content: news, videos, music, etc.\n",
      "* How does this paper contribute to the literature on crowdfun\n",
      "prefix The role of semantics in the success of crowdfunding projects. What do the authors analyze? \n",
      "3 output_cut A large 5-year dataset from a major US startup company, which includes over 10 million dollars raised by more than 237K investors and has been used to study many aspects of crowdfunding such as fundraising strategies or investor behavior.\n",
      "text The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large \"crowdfunding corpus\" is used to study how semantic features affect project success, and what are the most important ones.\n",
      "prefix The role of semantics in the success of crowdfunding projects. What do the authors analyze? \n",
      "3 output_cut A large \"crowdfunding corpus\" is used to study how semantic features affect project success, and what are the most important ones..\n",
      "text The role of semantics in the success of crowdfunding projects. What do the authors analyze? A large 2016 study by a team led by Professor David Wurgler at Harvard University, which analyzed over 35 million dollars raised from more than 47 thousand crowdfunding campaigns and found that semantic similarity between funding proposals is an important factor for successful fundraising efforts.\n",
      "* The impact of social media on online finance: How does Twitter affect investors’ decisions to invest or not? This paper presents results obtained through experiments with real data collected from two different sources – one base\n",
      "prefix The role of semantics in the success of crowdfunding projects. What do the authors analyze? \n",
      "3 output_cut A large 2016 study by a team led by Professor David Wurgler at Harvard University, which analyzed over 35 million dollars raised from more than 47 thousand crowdfunding campaigns and found that semantic similarity between funding proposals is an important factor for successful fundraising efforts.\n",
      "* The impact of social media on online finance: How does Twitter affect investors’ decisions to invest or not? This paper presents results obtained through experiments with real data collected from two different sources – one base.\n",
      "++++++++++++++++++++++++++++++\n",
      "What do the authors analyze? ----- A large dataset of crowdfunding project data\n",
      "(0)-A large (n=1,034) dataset was collected from a leading online crowdfunding platform and analyzed to understand how semantic features affect project success.\n",
      "\n",
      "(1)-A large 12-month dataset from one major online fundraising platform, Kickstarter was analyzed to understand how semantic features affect project outcomes.\n",
      "\n",
      "(2)-A large 5-year dataset from a major US startup company, which includes over 10 million dollars raised by more than 237K investors and has been used to study many aspects of crowdfunding such as fundraising strategies or investor behavior.\n",
      "\n",
      "(3)-A large \"crowdfunding corpus\" is used to study how semantic features affect project success, and what are the most important ones..\n",
      "\n",
      "(4)-A large 2016 study by a team led by Professor David Wurgler at Harvard University, which analyzed over 35 million dollars raised from more than 47 thousand crowdfunding campaigns and found that semantic similarity between funding proposals is an important factor for successful fundraising efforts. * The impact of social media on online finance: How does Twitter affect investors’ decisions to invest or not? This paper presents results obtained through experiments with real data collected from two different sources – one base.\n",
      "\n",
      "What do the authors analyze? --- A large dataset of crowdfunding project data\n",
      "['A large (n=1,034) dataset was collected from a leading online crowdfunding platform and analyzed to understand how semantic features affect project success.', 'A large 12-month dataset from one major online fundraising platform, Kickstarter was analyzed to understand how semantic features affect project outcomes.', 'A large 5-year dataset from a major US startup company, which includes over 10 million dollars raised by more than 237K investors and has been used to study many aspects of crowdfunding such as fundraising strategies or investor behavior.', 'A large \"crowdfunding corpus\" is used to study how semantic features affect project success, and what are the most important ones..', 'A large 2016 study by a team led by Professor David Wurgler at Harvard University, which analyzed over 35 million dollars raised from more than 47 thousand crowdfunding campaigns and found that semantic similarity between funding proposals is an important factor for successful fundraising efforts. * The impact of social media on online finance: How does Twitter affect investors’ decisions to invest or not? This paper presents results obtained through experiments with real data collected from two different sources – one base.']\n",
      "\n",
      "The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the \n",
      "5 ['The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the \"CrowdFlower Dataset v1.0\" and a new, larger version called \"CrowdFlower Dataset v2.0\" which contains more than 3 million entries from over 50 different domains.', 'The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 2016 and 2017 datasets, which are publicly available for research purposes.', 'The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 4 different datasets, which are described in Section 3.2.', 'The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 150K-dataset, which is a subset of the Reddit corpus used by previous studies that focused on predicting funding outcomes for crowdfunding campaigns. In addition to this evaluation, we also performed an ablation study and compared our results with those obtained using other state-of-the-art methods.', \"The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 3 datasets mentioned above, but only one paper used a real-world dataset for evaluation purposes and it is not clear how this affects the results obtained by the authors: they report an accuracy of 90% using their own data set while another paper reports an accuracy of 85% when tested on Amazon Mechanical Turk's crowd sourced labels; however, these two papers use different metrics which makes comparison difficult.\"]\n",
      "text The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the \"CrowdFlower Dataset v1.0\" and a new, larger version called \"CrowdFlower Dataset v2.0\" which contains more than 3 million entries from over 50 different domains.\n",
      "prefix The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? \n",
      "3 output_cut The proposed models were evaluated on the \"CrowdFlower Dataset v1.0\" and a new, larger version called \"CrowdFlower Dataset v2.0\" which contains more than 3 million entries from over 50 different domains..\n",
      "text The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 2016 and 2017 datasets, which are publicly available for research purposes.\n",
      "prefix The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? \n",
      "3 output_cut The proposed models were evaluated on the 2016 and 2017 datasets, which are publicly available for research purposes..\n",
      "text The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 4 different datasets, which are described in Section 3.2.\n",
      "prefix The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? \n",
      "3 output_cut The proposed models were evaluated on the 4 different datasets, which are described in Section 3.2..\n",
      "text The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 150K-dataset, which is a subset of the Reddit corpus used by previous studies that focused on predicting funding outcomes for crowdfunding campaigns. In addition to this evaluation, we also performed an ablation study and compared our results with those obtained using other state-of-the-art methods.\n",
      "prefix The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? \n",
      "3 output_cut The proposed models were evaluated on the 150K-dataset, which is a subset of the Reddit corpus used by previous studies that focused on predicting funding outcomes for crowdfunding campaigns.\n",
      "text The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? The proposed models were evaluated on the 3 datasets mentioned above, but only one paper used a real-world dataset for evaluation purposes and it is not clear how this affects the results obtained by the authors: they report an accuracy of 90% using their own data set while another paper reports an accuracy of 85% when tested on Amazon Mechanical Turk's crowd sourced labels; however, these two papers use different metrics which makes comparison difficult.\n",
      "prefix The role of semantics in the success of crowdfunding projects. On what dataset was the proposed model evaluated? \n",
      "3 output_cut The proposed models were evaluated on the 3 datasets mentioned above, but only one paper used a real-world dataset for evaluation purposes and it is not clear how this affects the results obtained by the authors: they report an accuracy of 90% using their own data set while another paper reports an accuracy of 85% when tested on Amazon Mechanical Turk's crowd sourced labels; however, these two papers use different metrics which makes comparison difficult..\n",
      "++++++++++++++++++++++++++++++\n",
      "On what dataset was the proposed model evaluated? ----- The proposed models were evaluated on the following datasets: All_D.\n",
      "(0)-The proposed models were evaluated on the \"CrowdFlower Dataset v1.0\" and a new, larger version called \"CrowdFlower Dataset v2.0\" which contains more than 3 million entries from over 50 different domains..\n",
      "\n",
      "(1)-The proposed models were evaluated on the 2016 and 2017 datasets, which are publicly available for research purposes..\n",
      "\n",
      "(2)-The proposed models were evaluated on the 4 different datasets, which are described in Section 3.2..\n",
      "\n",
      "(3)-The proposed models were evaluated on the 150K-dataset, which is a subset of the Reddit corpus used by previous studies that focused on predicting funding outcomes for crowdfunding campaigns.\n",
      "\n",
      "(4)-The proposed models were evaluated on the 3 datasets mentioned above, but only one paper used a real-world dataset for evaluation purposes and it is not clear how this affects the results obtained by the authors: they report an accuracy of 90% using their own data set while another paper reports an accuracy of 85% when tested on Amazon Mechanical Turk's crowd sourced labels; however, these two papers use different metrics which makes comparison difficult..\n",
      "\n",
      "On what dataset was the proposed model evaluated? --- The proposed models were evaluated on the following datasets: All_D.\n",
      "['The proposed models were evaluated on the \"CrowdFlower Dataset v1.0\" and a new, larger version called \"CrowdFlower Dataset v2.0\" which contains more than 3 million entries from over 50 different domains..', 'The proposed models were evaluated on the 2016 and 2017 datasets, which are publicly available for research purposes..', 'The proposed models were evaluated on the 4 different datasets, which are described in Section 3.2..', 'The proposed models were evaluated on the 150K-dataset, which is a subset of the Reddit corpus used by previous studies that focused on predicting funding outcomes for crowdfunding campaigns.', \"The proposed models were evaluated on the 3 datasets mentioned above, but only one paper used a real-world dataset for evaluation purposes and it is not clear how this affects the results obtained by the authors: they report an accuracy of 90% using their own data set while another paper reports an accuracy of 85% when tested on Amazon Mechanical Turk's crowd sourced labels; however, these two papers use different metrics which makes comparison difficult..\"]\n",
      "\n",
      "The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more \n",
      "5 ['The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more (2018), https://www.researchgate.net/publication/345679_the_role_of_semantics_in_the_success_of_crowdfunding_projects', 'The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more 10', 'The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more => better, less => worse\\n* The impact of semantic on crowd-sourcing platforms: what is the effect of different types of content and their presentation to users’ perception about it? how can we improve this process? e.g. by using machine learning techniques or other methods that allow us to automatically detect certain patterns from user comments; also see https://www.theguardian.com/technology/2018/nov/30/crow', 'The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more \"semantics\" is needed to understand what it means for an organization to be successful, and how this can be achieved through better communication between stakeholders within organizations as well as with external partners. The authors also suggest that there are several ways semantic technologies could help improve fundraising processes:', 'The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more -the semantic content of an article is not only important for its own sake, but also to attract funding from other users and organizations.']\n",
      "text The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more (2018), https://www.researchgate.net/publication/345679_the_role_of_semantics_in_the_success_of_crowdfunding_projects\n",
      "prefix The role of semantics in the success of crowdfunding projects. What should the post of a project contain? \n",
      "3 output_cut more (2018), https://www.researchgate.net/publication/345679_the_role_of_semantics_in_the_success_of_crowdfunding_projects.\n",
      "too long word\n",
      "text The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more 10\n",
      "prefix The role of semantics in the success of crowdfunding projects. What should the post of a project contain? \n",
      "3 output_cut more 10\n",
      "text The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more => better, less => worse\n",
      "* The impact of semantic on crowd-sourcing platforms: what is the effect of different types of content and their presentation to users’ perception about it? how can we improve this process? e.g. by using machine learning techniques or other methods that allow us to automatically detect certain patterns from user comments; also see https://www.theguardian.com/technology/2018/nov/30/crow\n",
      "prefix The role of semantics in the success of crowdfunding projects. What should the post of a project contain? \n",
      "3 output_cut more => better, less => worse\n",
      "* The impact of semantic on crowd-sourcing platforms: what is the effect of different types of content and their presentation to users’ perception about it? how can we improve this process? eg by using machine learning techniques or other methods that allow us to automatically detect certain patterns from user comments; also see https://www.theguardian.com/technology/2018/nov/30/crow.\n",
      "too long word\n",
      "text The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more \"semantics\" is needed to understand what it means for an organization to be successful, and how this can be achieved through better communication between stakeholders within organizations as well as with external partners. The authors also suggest that there are several ways semantic technologies could help improve fundraising processes:\n",
      "prefix The role of semantics in the success of crowdfunding projects. What should the post of a project contain? \n",
      "3 output_cut more \"semantics\" is needed to understand what it means for an organization to be successful, and how this can be achieved through better communication between stakeholders within organizations as well as with external partners.\n",
      "text The role of semantics in the success of crowdfunding projects. What should the post of a project contain? more -the semantic content of an article is not only important for its own sake, but also to attract funding from other users and organizations.\n",
      "prefix The role of semantics in the success of crowdfunding projects. What should the post of a project contain? \n",
      "3 output_cut more -the semantic content of an article is not only important for its own sake, but also to attract funding from other users and organizations..\n",
      "++++++++++++++++++++++++++++++\n",
      "What should the post of a project contain? ----- more feelings words\n",
      "(0)-more 10\n",
      "\n",
      "(1)-more \"semantics\" is needed to understand what it means for an organization to be successful, and how this can be achieved through better communication between stakeholders within organizations as well as with external partners.\n",
      "\n",
      "(2)-more -the semantic content of an article is not only important for its own sake, but also to attract funding from other users and organizations..\n",
      "\n",
      "What should the post of a project contain? --- more feelings words\n",
      "['more 10', 'more \"semantics\" is needed to understand what it means for an organization to be successful, and how this can be achieved through better communication between stakeholders within organizations as well as with external partners.', 'more -the semantic content of an article is not only important for its own sake, but also to attract funding from other users and organizations..']\n",
      "\n",
      "The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional \n",
      "5 ['The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional (e.g., a list of all available fundraising platforms)', 'The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional (e.g., a list of all available fundraising platforms)', 'The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 250,000 comments from users who had not yet posted a comment on this page and were interested in participating;', 'The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 53%), and only one project was funded by an organization other than a nonprofit or charitable foundation2. In addition, we found that most funding sources were not listed on any website for their fundraising activities: “We don’t have anything specific about our campaign”; “I haven’t been able to find out what is going on with this particular company yet”; “It hasn’t even gotten started at all so I can’', 'The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 10,347 comments from users who had not yet made a donation and were still active on Reddit;']\n",
      "text The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional (e.g., a list of all available fundraising platforms)\n",
      "prefix The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? \n",
      "3 output_cut additional (eg, a list of all available fundraising platforms)\n",
      "text The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional (e.g., a list of all available fundraising platforms)\n",
      "prefix The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? \n",
      "3 output_cut additional (eg, a list of all available fundraising platforms)\n",
      "text The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 250,000 comments from users who had not yet posted a comment on this page and were interested in participating;\n",
      "prefix The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? \n",
      "3 output_cut additional 250,000 comments from users who had not yet posted a comment on this page and were interested in participating;\n",
      "text The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 53%), and only one project was funded by an organization other than a nonprofit or charitable foundation2. In addition, we found that most funding sources were not listed on any website for their fundraising activities: “We don’t have anything specific about our campaign”; “I haven’t been able to find out what is going on with this particular company yet”; “It hasn’t even gotten started at all so I can’\n",
      "prefix The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? \n",
      "3 output_cut additional 53%), and only one project was funded by an organization other than a nonprofit or charitable foundation2.\n",
      "text The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? additional 10,347 comments from users who had not yet made a donation and were still active on Reddit;\n",
      "prefix The role of semantics in the success of crowdfunding projects. What did the authors use Beautifulsup to gain? \n",
      "3 output_cut additional 10,347 comments from users who had not yet made a donation and were still active on Reddit;\n",
      "++++++++++++++++++++++++++++++\n",
      "What did the authors use Beautifulsup to gain? ----- additional metadata features\n",
      "(0)-additional (eg, a list of all available fundraising platforms)\n",
      "\n",
      "(1)-additional (eg, a list of all available fundraising platforms)\n",
      "\n",
      "(2)-additional 250,000 comments from users who had not yet posted a comment on this page and were interested in participating;\n",
      "\n",
      "(3)-additional 53%), and only one project was funded by an organization other than a nonprofit or charitable foundation2.\n",
      "\n",
      "(4)-additional 10,347 comments from users who had not yet made a donation and were still active on Reddit;\n",
      "\n",
      "What did the authors use Beautifulsup to gain? --- additional metadata features\n",
      "['additional (eg, a list of all available fundraising platforms)', 'additional (eg, a list of all available fundraising platforms)', 'additional 250,000 comments from users who had not yet posted a comment on this page and were interested in participating;', 'additional 53%), and only one project was funded by an organization other than a nonprofit or charitable foundation2.', 'additional 10,347 comments from users who had not yet made a donation and were still active on Reddit;']\n",
      "\n",
      "The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General \n",
      "5 ['The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General (e.g., “crowd”); Social (e.g., “social media”); Financial (e.g., “financials”); and Political (e.g., “politics”).', 'The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 10%, Specific 25%', 'The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 10%, Specific 25%', 'The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 230', 'The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General -What are some examples of buzzwords that have been used to describe a particular project or event?']\n",
      "text The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General (e.g., “crowd”); Social (e.g., “social media”); Financial (e.g., “financials”); and Political (e.g., “politics”).\n",
      "prefix The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? \n",
      "3 output_cut General (eg, “crowd”); Social (eg, “social media”); Financial (eg, “financials”); and Political (eg, “politics”)..\n",
      "text The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 10%, Specific 25%\n",
      "prefix The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? \n",
      "3 output_cut General 10%, Specific 25%\n",
      "text The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 10%, Specific 25%\n",
      "prefix The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? \n",
      "3 output_cut General 10%, Specific 25%\n",
      "text The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General 230\n",
      "prefix The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? \n",
      "3 output_cut General 230\n",
      "text The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? General -What are some examples of buzzwords that have been used to describe a particular project or event?\n",
      "prefix The role of semantics in the success of crowdfunding projects. What categories of buzzwords were used in the study? \n",
      "3 output_cut General -What are some examples of buzzwords that have been used to describe a particular project or event?\n",
      "++++++++++++++++++++++++++++++\n",
      "What categories of buzzwords were used in the study? ----- General conversation, education, business, sales and marketing, science and technology, politics and current affairs. The buzzword dataset used in this study contains words from different categories: general conversation, business.\n",
      "(0)-General (eg, “crowd”); Social (eg, “social media”); Financial (eg, “financials”); and Political (eg, “politics”)..\n",
      "\n",
      "(1)-General 10%, Specific 25%\n",
      "\n",
      "(2)-General 10%, Specific 25%\n",
      "\n",
      "(3)-General 230\n",
      "\n",
      "(4)-General -What are some examples of buzzwords that have been used to describe a particular project or event?\n",
      "\n",
      "What categories of buzzwords were used in the study? --- General conversation, education, business, sales and marketing, science and technology, politics and current affairs. The buzzword dataset used in this study contains words from different categories: general conversation, business.\n",
      "['General (eg, “crowd”); Social (eg, “social media”); Financial (eg, “financials”); and Political (eg, “politics”)..', 'General 10%, Specific 25%', 'General 10%, Specific 25%', 'General 230', 'General -What are some examples of buzzwords that have been used to describe a particular project or event?']\n"
     ]
    }
   ],
   "source": [
    "if 'di' in locals():\n",
    "    del di\n",
    "di = distractors_by_autoregressive_model('cuda')\n",
    "title =\"The role of semantics in the success of crowdfunding projects\"\n",
    "qs1 = \"What do the authors analyze?\" \n",
    "answer1 = \"A large dataset of crowdfunding project data\"\n",
    "\n",
    "qs2 =\"On what dataset was the proposed model evaluated?\"\n",
    "answer2 = \"The proposed models were evaluated on the following datasets: All_D.\"\n",
    "\n",
    "qs3 = \"What should the post of a project contain?\"\n",
    "answer3 = \"more feelings words\"\n",
    "\n",
    "qs4 = \"What did the authors use Beautifulsup to gain?\"\n",
    "answer4 = \"additional metadata features\"\n",
    "\n",
    "qs5 = \"What categories of buzzwords were used in the study?\"\n",
    "answer5 = 'General conversation, education, business, sales and marketing, science and technology, politics and current affairs. The buzzword dataset used in this study contains words from different categories: general conversation, business.'\n",
    "for qs,answer in zip([qs1,qs2,qs3,qs4,qs5],[answer1,answer2,answer3,answer4,answer5]):\n",
    "    print()\n",
    "    pp= di.generate_distractors( qs, answer,title=title)\n",
    "    print(qs,'---',answer)\n",
    "    print(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Why are crowdfunding platforms important?',\n",
       "   'What is the main purpose of crowdfunding platforms?',\n",
       "   'Why are crowdfunding platforms important? -'],\n",
       "  tensor([-17.5531, -24.5470, -51.0471], device='cuda:0')],\n",
       " [['How many parties are involved in crowdfunding?',\n",
       "   'What is the average success rate of funded crowdfunding projects in Kickstarter?',\n",
       "   'Who are involved in crowdfunding?'],\n",
       "  tensor([ -7.8947, -22.9828, -24.6290], device='cuda:0')],\n",
       " [['Why are we different from previous studies? Available choices: (i). We use different features. (ii). None of the above choices. (III). We have different metric. (IV). We are using different models.',\n",
       "   'What is the metric used to measure the accuracy of the models? Pick from: (i). The metric is used to determine the accuracy. (ii). None of the above choices. (III). The model is used for semantic analysis. (IV). The models are used for textual analysis.',\n",
       "   'Why are we different from previous studies? Available choices: (i). We use different features. (ii). None of the above choices. (III). We have different metric. (IV). We are using different models. (V). We differ from previous models.'],\n",
       "  tensor([-297.5034, -400.0376, -459.8438], device='cuda:0')],\n",
       " [['How many categories of buzzwords were included in the dataset?',\n",
       "   'What is the relationship between funding success and buzzwords used in the description of the project?',\n",
       "   'In which category did the buzzwords come from?'],\n",
       "  tensor([-32.9147, -33.2559, -43.1535], device='cuda:0')],\n",
       " [['What is the output of LIWC?',\n",
       "   'How many features are extracted from the text?',\n",
       "   'Which of these is not a feature of LIWC analysis?'],\n",
       "  tensor([-15.7687, -22.7590, -43.7499], device='cuda:0')],\n",
       " [['What is the name of the topic modeling method?',\n",
       "   'Which of these is not a topic modeling method?',\n",
       "   'How many topics does the LDA algorithm consider in a document?'],\n",
       "  tensor([-25.3579, -34.1516, -34.6886], device='cuda:0')],\n",
       " [['Which of these is not a metadata feature?',\n",
       "   'Which of these is not a metadata feature? Pick from: (i). The number of videos. (ii). None of the above choices. (III). The total number of updates. (IV). The time between updates.',\n",
       "   'How did they extract the metadata? Available choices: (i). They used a program to extract the data. (ii). None of the above choices. (III). They extracted the data from the web. (IV). They incorporated the data into their analysis.'],\n",
       "  tensor([ -36.4830, -294.6439, -353.8396], device='cuda:0')],\n",
       " [['Which of the following is not a feeling? Pick from: (a). Affectionate. (b). Awed. (c). Awkward. (d). Aware.',\n",
       "   'Which of the following is not a feeling? Pick from: (a). Affectionate. (b). Awed. (c). Awkward. (d). Aware. (e). Affected.',\n",
       "   'How would you describe the person who wrote this article? Pick your answer from: (a). They are awed. (b). They feel awkward. (C). They have a good sense of humor.'],\n",
       "  tensor([-131.6980, -230.7179, -491.0447], device='cuda:0')],\n",
       " [['Who was able to correctly predict positive records?',\n",
       "   'How many metrics were used to measure the performance of our models? Pick from: a). Recall b). F-score c). Precision d). Relativity',\n",
       "   'Which of these is not a metric used to measure the performance of models? Pick from: (a). Recall (b). F-score (c). F1 (d).'],\n",
       "  tensor([ -44.6735, -161.2728, -202.7152], device='cuda:0')],\n",
       " [['What was the source of the data?',\n",
       "   'Which platform did they use to obtain the data?',\n",
       "   'Who provided data for the study?'],\n",
       "  tensor([-26.7894, -27.2502, -35.1828], device='cuda:0')],\n",
       " [['Which of these is not a method?',\n",
       "   'How many steps are there to a methodology flowchart?',\n",
       "   'In which of the following steps is the smallest amount of data collected?'],\n",
       "  tensor([-36.3081, -66.1696, -98.2073], device='cuda:0')],\n",
       " [['What is the LDA algorithm?',\n",
       "   'How many features are evaluated in the CFS algorithm?',\n",
       "   'Why do they use the LDA algorithm?'],\n",
       "  tensor([-18.4829, -28.8683, -29.5228], device='cuda:0')],\n",
       " [['How many machine learning algorithms were utilized?',\n",
       "   'Who developed semantic features?',\n",
       "   'What is a machine learning algorithm that is used to learn a model?'],\n",
       "  tensor([-15.9691, -30.1524, -85.8174], device='cuda:0')],\n",
       " [['Which model was trained with the least amount of algorithms?',\n",
       "   'What is the difference between SVM and J48',\n",
       "   'What is the difference between SVM and J48?'],\n",
       "  tensor([-39.3591, -45.0498, -53.0385], device='cuda:0')],\n",
       " [['How many parameters were examined?',\n",
       "   'What is the relationship between funding success and buzzwords?',\n",
       "   'Why did they develop a novel model based on semantic features only?'],\n",
       "  tensor([-16.6885, -20.3918, -41.1664], device='cuda:0')]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(\"{context}\\n\\nGenerate a question about the above context.\", \"{question}\\n{options_}\"),\n",
    "# (\"Write a question about the following article.\" \"\\n\\n{context}\\n\\nQuestion:\", \"{question}\\n{options_}\"),\n",
    "device='cuda'\n",
    "autoregressive_model_checkpoint = \"google/flan-t5-xl\"\n",
    "if not 'model' in locals():\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(autoregressive_model_checkpoint).to(device)\n",
    "    tokenizer =  AutoTokenizer.from_pretrained(autoregressive_model_checkpoint)\n",
    "BEAMS = 4\n",
    "ARGS_GENERATOR = {\n",
    "    \"max_new_tokens\":150,\n",
    "    #\"max_length\": 256,\n",
    "    \"num_beams\": BEAMS, #20\n",
    "    \"length_penalty\":-0.5, #Since the score is the log likelihood of the sequence (i.e. negative), length_penalty > 0.0 promotes longer sequences, while length_penalty < 0.0 encourages shorter sequences.\n",
    "    \"no_repeat_ngram_size\": 3,\n",
    "    #'force_words_ids':[[58]],#token of `?` -cannot use constrained beam search with grouped beam search, while `diversity_penalty` can be used only with group beam search.\n",
    "    'top_p' :0.9,\n",
    "    #'do_sample':True,\n",
    "    'diversity_penalty':float(10), #note diversity is calculated between groups, the final scores are across all outputs, therefore the results with highest scores may be from one group and the diversity calcultion won't be effective for large groups\n",
    "    'num_beam_groups':BEAMS, #20 \n",
    "    \"return_dict_in_generate\" :True,\n",
    "    'output_scores':True,\n",
    "    #\"early_stopping\": True, \n",
    "    'num_return_sequences':3\n",
    "}\n",
    "def get_output( text, **cfg):\n",
    "        input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(model.device)\n",
    "        res = model.generate(input_ids, **cfg) #.cpu()\n",
    "        r = tokenizer.batch_decode(res['sequences'], skip_special_tokens=True)\n",
    "        try:    torch.cuda.empty_cache()\n",
    "        except: pass\n",
    "        return [r, res['sequences_scores']]\n",
    "def get_outputs(texts, **cfg):\n",
    "            return [\n",
    "                get_output(text, **dict(cfg))\n",
    "                for text in texts\n",
    "            ]\n",
    "sections = ['Crowdfunding platforms allow entrepreneurs to publish projects and raise funds for realizing them. Hence, the question of what influences projects’ fundraising success is very important. Previous studies examined various factors such as project goals and project duration that may influence the outcomes of fundraising campaigns. We present a novel model for predicting the success of crowdfunding projects in meeting their funding goals. Our model focuses on semantic features only, whose performance is comparable to that of previous models. In an additional model we developed, we examine both project metadata and project semantics, delivering a comprehensive study of factors influencing crowdfunding success. Further, we analyze a large dataset of crowdfunding project data, larger than reported in the art. Finally, we show that when combining semantics and metadata, we arrive at F1 score accuracy of 96.2%. We compare our model’s accuracy to the accuracy of previous research models by applying their methods on our dataset, and demonstrate higher accuracy of our model. In addition to our scientific contribution, we provide practical recommendations that may increase project funding success chances.',\n",
    " ' In recent years, crowdfunding has emerged as a popular financing mechanism that allows various types of projects to get funded. Three main parties are involved in crowdfunding: entrepreneurs (and their projects), individuals or groups who support the project, and online platforms, i.e., crowdfunding websites. The average success rate of funded crowdfunding projects in Kickstarter is 37.5% [4] In this paper, we refer to a project as a funding success (FS) if it achieved its funding goal (i.e.  In contrast to prior studies, we take a more comprehensive approach to studying and predicting funding success. We use unique features (for example, the use of buzzwords) and perform extensive research on the semantics of the projects’ text. Our main research objective is to find characteristics, with a focus on semantic characteristics, which affect the success of a project in meeting its funding goal via crowdfunding. This approach leverages known results and improves upon them to provide high-quality funding success prediction.  Achieving these research objectives should provide new insights into the relationship between crowdfunding project’s data and their funding success. This should provide entrepreneurs with additional and desirable ways to improve their chances of reaching their funding goals. The accuracy of the semantic-model (in terms of F-score and correctly classified instances) is comparable to the accuracy of state-of-the-art models which are based on metadata features such as the number of updates, number of images, etc.  The accuracy of the combined-model is higher than the accuracy derived in previous studies that use other models [11–14] Fourth, we show that buzzwords and LIWC are among the highly correlate features with the project’s success in fund raising. Fifth, to the best of our knowledge, our research relies on the largest dataset used to date for developing models that predict funding success of crowdfunding projects. In addition to the scientific contributions listed above, we provide a set of recommendations that may increase project funding success chances.  The Methodology section focuses on the research methodology applied, including the acquisition of our dataset, preprocessing, feature extraction and selection. The Results section presents the empirical evaluation of our research model and discusses the results. It further compares our models to models in earlier studies.',\n",
    " ' In this section, we discuss the features used in our models, highlighting where we differ from previous studies. We also present the metric used to measure the accuracy of the models. For semantic analysis, the projects’ textual data is required.',\n",
    " ' The relationship between funding success and buzzwords used in the description of the project was not examined. The buzzword dataset used in this study contains words from different categories: general conversation, education, business, sales and marketing, science and technology, politics, and current affairs.',\n",
    " ' We used the Linguistic Inquiry and Word Count (LIWC) software tool to extract features from the text. LIWC analysis measures the appearance of dictionary words in a specific text. The measure is a numeric value in the range [0..1]. It reflects the degree to which the text being analyzed is related to the theme of the dictionary. The output of LIWC is VD = SD/NT, which is the value of the feature that corresponds to D. Previous studies on crowdfunding used LIWC to analyze the textual description part of projects.  The number and diversity of features in our study are much larger than previously published, and our dataset is significantly greater as well. As a result, we arrive at much higher model accuracy.',\n",
    " ' Latent Dirichlet allocation (LDA) is a widely used topic modeling method. LDA algorithm considers each document as a collection of topics, where each word in the document belongs to one or some of these topics. Previous studies on crowdfunding used LDA to perform topic analysis on the text of project updates. We used the Gensim Python package LDA implementation (from GitHub.com) to execute LDA. The latter is known to run faster than other implementations and generates better topic segregation [16].  The three main inputs to the LDA topic model are the dictionary, the corpus, and the number of topics. Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] To avoid overfitting, we chose the one that derived the highest coherence value and the smallest number of. topics. There were 30 topics that derived. the highest. coherence values for the All_D dataset, 15 for the Tech_D and 15 for Market_D datasets.',\n",
    " ' We incorporated metadata features known to affect funding success. The metadata features we used were extracted from projects’ posts via Python web scraping. The set we used for our analysis included the number of photos, the. number of videos, the number. of updates, the. number of previously created projects by.',\n",
    " ' The following additional topics were deduced: Explanation words: example, explain, for instance, i.e., mean, in other words, in that, that is, etc. Feelings words: angry, annoyed, afraid, awkward, affectionate, anxious, alarmed, awed, aggravated, amazed, amazed.',\n",
    " ' We used the following metrics to measure the performance of our models. Recall is the ratio of correctly predicted positive records to the all records in actual class. F-score (also denoted F1) is the weighted harmonic mean of a model’s precision and recall.',\n",
    " ' We used a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects. We obtained these data from the Kaggle website for 2018. We used Beautifulsup (a Python web scraping package) to gain additional metadata features, such as, description content, number of updates, etc. For each record in the dataset, we obtained the values of five metadata features and about 120 semantic features, including buzzwords, LIWC outputs, feelings words, explanation words, and LDA outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets.  To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the following analysis goals: First, it facilitates improvement in the LDA topic coherence score. Second, it allows us to determine whether a category affects the features that are highly correlated with funding success. Third, to study the correlation between buzzwords and FS, it is preferable for datasets to be separated into specific subdomains.  For each dataset, the original features space was reduced into three Principal Components (PCs) The sum of the explained variance ratio of these three PCs is 78% of the total variance. To identify the most significant set of features (MSSF) that has the highest impact on FS, we use the CFS (correlation-based feature selection) algorithm. The PCA plots in Fig 1 present the distribution of the All_D, Market_D and Tech_D datasets. Dots in blue represent unsuccessfully funded projects and red represent successfully funded projects.  The models’ design, derivation, and operational tests were conducted using the following Python packages: scikit-learn, scikits-feature and LightGBM. We employed a 10-fold cross-validation test to evaluate the prediction performance. Fig 2 includes a flowchart of the methodology. To validate the results of our study, we compared our model’s accuracy to previous research models by applying their methods on our dataset. To this end, we have developed the combined-model, whose novelty lies in the combination of semantic and meta-data features.',\n",
    " 'Fig 2. Methodology flowchart.',\n",
    " ' In this section, we provide details of the data setup, the usage of the LDA algorithm, the feature correlation analysis, and the feature selection process. In what follows we describe the way in which we found the features that are most influential for FS. The CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.  The semantic features buzzwords and LIWC are among the features that have a higher correlation in all datasets. An important, unique conclusion of our study is that the features correlated to FS are dependent on the project category. Among the top 10 features, about 70% of the features are the same across datasets. For example, the features feelings_num and buzz_num appear in the three top 10 lists. In contrast, the parameter WC is unique in the R_Tech _D top 10 list and the parameter number is distinctive.',\n",
    " ' For the development of the Semantic-Model, semantic features were used as input. We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN, and more) on All_D. Table 2 presents the accuracies metrics of the combined-model: Combined model.  The semantic-model we have developed is comparable in accuracy with the state of the art (metadata) models, exhibiting an accuracy level of 91.2%. The LightGBM algorithm exhibited a high accuracy level for all three datasets. In particular, the accuracy of the prediction model is greater than 94% for all datasets.',\n",
    " ' The study aims to examine whether the set of features we use for prediction and the dataset on which learning was applied deliver a better model by means of F-score accuracy. We trained the LDA-Model and the Metadata-Model with the algorithms that were used in the studies above, and with additional algorithms, including SVM, J48, Random forest, LightGBM, SDG, and DNN. This training was performed on All_D with 10-fold cross-validation.  F-score is used for consistency with the earlier studies to which we compare. Figure shows that the model we developed has the highest accuracy. The accuracy of the Semantic-Model is similar to that of the LDA-Model and the Metadata-Model.',\n",
    " ' The study is the first that investigates the relationship between funding success and buzzwords. The buzzwords feature is among the features that are highly correlated to funding success compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model’s performance could be achieved via novel feature selection algorithms.',\n",
    "]\n",
    "get_outputs(\n",
    "            [\n",
    "                f\"Write a question about the following article\\n\\n{cur[:trancuted]}\\n\\nQuestion:\"\n",
    "                for cur in sections\n",
    "            ],\n",
    "            **ARGS_GENERATOR\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
