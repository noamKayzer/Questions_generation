{"checks":{},"sections":{"0":{"computed":{"stats":{"readability":13.0,"readtime":1,"words":178},"text":"Crowdfunding platforms allow entrepreneurs to publish projects and raise funds for realizing them. Hence, the question of what influences projects\u2019 fundraising success is very important. Previous studies examined various factors such as project goals and project duration that may influence the outcomes of fundraising campaigns. We present a novel model for predicting the success of crowdfunding projects in meeting their funding goals. Our model focuses on semantic features only, whose performance is comparable to that of previous models. In an additional model we developed, we examine both project metadata and project semantics, delivering a comprehensive study of factors influencing crowdfunding success. Further, we analyze a large dataset of crowdfunding project data, larger than reported in the art. Finally, we show that when combining semantics and metadata, we arrive at F1 score accuracy of 96.2%. We compare our model\u2019s accuracy to the accuracy of previous research models by applying their methods on our dataset, and demonstrate higher accuracy of our model. In addition to our scientific contribution, we provide practical recommendations that may increase project funding success chances.","title":"Abstract"}},"1":{"computed":{"stats":{"readability":11.0,"readtime":2,"words":365},"text":" In recent years, crowdfunding has emerged as a popular financing mechanism that allows various types of projects to get funded. Three main parties are involved in crowdfunding: entrepreneurs (and their projects), individuals or groups who support the project, and online platforms, i.e., crowdfunding websites. The average success rate of funded crowdfunding projects in Kickstarter is 37.5% [4] In this paper, we refer to a project as a funding success (FS) if it achieved its funding goal (i.e.  In contrast to prior studies, we take a more comprehensive approach to studying and predicting funding success. We use unique features (for example, the use of buzzwords) and perform extensive research on the semantics of the projects\u2019 text. Our main research objective is to find characteristics, with a focus on semantic characteristics, which affect the success of a project in meeting its funding goal via crowdfunding. This approach leverages known results and improves upon them to provide high-quality funding success prediction.  Achieving these research objectives should provide new insights into the relationship between crowdfunding project\u2019s data and their funding success. This should provide entrepreneurs with additional and desirable ways to improve their chances of reaching their funding goals. The accuracy of the semantic-model (in terms of F-score and correctly classified instances) is comparable to the accuracy of state-of-the-art models which are based on metadata features such as the number of updates, number of images, etc.  The accuracy of the combined-model is higher than the accuracy derived in previous studies that use other models [11\u201314] Fourth, we show that buzzwords and LIWC are among the highly correlate features with the project\u2019s success in fund raising. Fifth, to the best of our knowledge, our research relies on the largest dataset used to date for developing models that predict funding success of crowdfunding projects. In addition to the scientific contributions listed above, we provide a set of recommendations that may increase project funding success chances.  The Methodology section focuses on the research methodology applied, including the acquisition of our dataset, preprocessing, feature extraction and selection. The Results section presents the empirical evaluation of our research model and discusses the results. It further compares our models to models in earlier studies.","title":"Introduction"}},"2":{"computed":{"images":["1-193x133","2-466x65"],"stats":{"readability":13.0,"readtime":2,"words":420},"text":" For semantic analysis, the projects\u2019 textual data is required. The analysis we performed on posts examined their use of buzzwords [15]. The relationship between funding success and buzzwords used in the description of the project was not examined. The buzzword dataset used in this study contains words from different categories: general conversation, education, business, sales and marketing, science and technology, politics, and current affairs. In our study, the buzzwords feature was the percentage contribution of the words in the buzzword datasets to each input text i.e., project\u2019s description.  LIWC analysis measures the appearance of dictionary words in a specific text. The measure is a numeric value in the range [0..1]. It reflects the degree to which the text being analyzed is related to the theme of the dictionary. Previous studies on crowdfunding used LIWC to analyze the textual description part of projects (though they did not look for buzzwords) and arrived at high model accuracies. The main difference between the present research and those studies is that the number and diversity of features in our study are much larger than previously published.  Latent Dirichlet allocation (LDA) is a widely used topic modeling algorithm. LDA algorithm considers each document as a collection of topics, where each word belongs to one or some of these topics. Previous studies on crowdfunding used LDA to perform topic analysis on the text of project updates. We used the Gensim Python package LDA implementation (from GitHub) to run faster than other implementations. To execute LDA, we performed some preprocessing.  Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] We ran the LDA on three datasets (of which details are in the Methodology section) and derived three corresponding sets of topics. The output was a set of topics and the percentage contribution of each topic to each input text. There were 30 topics that derived the highest coherence for the All_D dataset, 15 for the Tech_D datasets, and 15 for Market_D. The metadata features we used were extracted from projects\u2019 posts via Python web scraping.  We used the following metrics to measure the performance of our models. F-score (also denoted F1) is the weighted harmonic mean of a model\u2019s precision and recall. We explored additional topics that could have a high correlation to FS by reviewing those used by studies in the field of textual analysis. The following additional topics were deduced: Explanation words: example, explain, explanation words, and feelings words: angry, annoyed, afraid, awkward, awkward.","title":"Background"}},"3":{"computed":{"images":["3-760x732"],"stats":{"readability":14.0,"readtime":1,"words":326},"text":" We used a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects. We obtained these data from the Kaggle website for 2018. We used Beautifulsup (a Python web scraping package) to gain additional metadata features, such as, description content, number of updates, etc. For each record in the dataset, we obtained the values of five metadata features and about 120 semantic features, including buzzwords, LIWC outputs, feelings words, explanation words, and LDA outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets.  To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the following analysis goals: First, it facilitates improvement in the LDA topic coherence score. Second, it allows us to determine whether a category affects the features that are highly correlated with funding success. Third, to study the correlation between buzzwords and FS, it is preferable for datasets to be separated into specific subdomains.  For each dataset, the original features space was reduced into three Principal Components (PCs) The sum of the explained variance ratio of these three PCs is 78% of the total variance. To identify the most significant set of features (MSSF) that has the highest impact on FS, we use the CFS (correlation-based feature selection) algorithm. The PCA plots in Fig 1 present the distribution of the All_D, Market_D and Tech_D datasets. Dots in blue represent unsuccessfully funded projects and red represent successfully funded projects.  The models\u2019 design, derivation, and operational tests were conducted using the following Python packages: scikit-learn, scikits-feature and LightGBM. We employed a 10-fold cross-validation test to evaluate the prediction performance. Fig 2 includes a flowchart of the methodology. To validate the results of our study, we compared our model\u2019s accuracy to previous research models by applying their methods on our dataset. To this end, we have developed the combined-model, whose novelty lies in the combination of semantic and meta-data features.","title":"Methodology"}},"4":{"computed":{"images":["4-569x928","5-1136x293","6-1132x88"],"stats":{"readability":12.0,"readtime":1,"words":372},"text":" In this section, we provide details of the data setup, the usage of the LDA algorithm, the feature correlation analysis, and the feature selection process. In what follows we describe the way in which we found the features that are most influential for FS. The CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.  There are various semantic features that have a high correlation to FS among the features we checked based on the project\u2019s category. The semantic features buzzwords and LIWC have a higher correlation in all datasets. Among the top 10 features, about 70% of the features are the same across datasets. For example, the features feelings_num and buzz_num appear in the three top 10 lists. In contrast, the parameter WC is unique in the R_Tech _D top 10 list and the parameter number is distinctive in R_Market_D list.  We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN, and more) on All_D. We used the grid search algorithm to optimize the hyperparameters with which each algorithm was executed (for example, for SDG we optimized batch size, number of epochs, etc.) Table 2 presents the accuracy metrics of the Semantic-Model: Combined model. Table 2 shows the accuracy of the combined-model, which is comparable in accuracy with the state of the art (metadata) models, exhibiting an accuracy level of 91.2%.  By combining the semantic model with the metadata model, we have achieved an accuracy level of 96.2%. Additionally, as seen across Tables 3\u20135, the LightGBM algorithm exhibited a high accuracy level for all three datasets. In particular, the accuracy of the prediction model is greater than 94% for all datasets. Our study aims to examine whether the set of features we use for prediction and the dataset on which learning was applied deliver a better model by means of F-score accuracy.  We trained the LDA-Model and the Metadata-Model with the algorithms that were used in the studies above and with additional algorithms, including SVM, J48, Random forest, LightGBM, SDG, and DNN. This training was performed on All_D with 10-fold cross-validation. Fig 3 shows that the model we developed has the highest accuracy.","title":"Results"}},"5":{"computed":{"images":["7-1133x88","8-765x465"],"stats":{"readability":12.0,"readtime":1,"words":140},"text":" The buzzwords feature is among the features that are highly correlated to funding success compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms. In addition to the scientific contributions listed above, a set of recommendations that may increase project funding success chances can be proposed.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model\u2019s performance could be achieved via novel feature selection algorithms.","title":"Conclusion and future work"}}},"stats":{"computed":{"readability":14.0,"readtime":5,"words":1801}}}
