RQUGE:5.0024
 Q1:ROME is a tool for understanding mechanisms of what?
Q2:ROME is a tool for understanding mechanisms of what?
Best ans: knowledge stored
['A0: knowledge stored',
 'A1:  Rank-One Model Editing (ROME)is to serve as a tool for understanding mechanisms of knowledge storage.
  Knowledge storage is the process of organizing and storing information. Knowledge is organized into facts and stored in memory.
   Therefore, the final answer is information. knowledge.',
   
    'A2:  Rank-One Model Editing (ROME)is to serve as a tool for understanding mechanisms of knowledge storage.
     Knowledge storage is the process of organizing and storing information. 
     Knowledge is organized into facts and stored in memory. Therefore, the final answer is information.'
     , 'A3: The purpose of Rank-One Model Editing (ROME) is to serve as a tool for understanding mechanisms of knowledge storage. 
     Knowledge storage is the process of storing and retrieving information. Knowledge is stored in the form of facts.
      Therefore, the final answer is knowledge storage of facts and information.',
       'A4: knowledge', 'A5: knowledge stored', 'A6: learning', 'A7: memory']
       Text: The purpose of Rank-One Model Editing (ROME) is to serve as a tool for understanding mechanisms of knowledge storage. It only edits a single fact at a time, and in the MLP modules (ii (it) is not intended as a practical method for large-scale model training. ROME and Causal Tracing shed light on factual association within GPT, but we have not investigated other kinds of learned beliefs such as logical, spatial, or numerical knowledge.



RQUGE:4.9218
Q1:Using an autoregressive transformer model, which of these is not true?
Q2:What dominates the early site?
Best ans: B) MLP contributions dominate early site.
['A0: B', 'A1: c', 'A2: B) MLP contributions dominate early site.', 
'A3: MLP contributions dominate the early site.', 'A4: B)', 'A5: [a]', 'A6: B', 'A7: c']Text: Autoregressive transformer language model G : X → Y over vocabulary V maps a token sequence x = [x1,..., xT ] to a probability distribution y ⊂ R|V | that predicts next-token continuations of x. Within the transformer, the ith token is embedded as a series of hidden state vectors h(l) i, beginning with h(0) i = emb(xi) + pos(i) ∈ RH. The final output y = decode(h(L) T ) is read from the last hidden state.  Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.



RQUGE:4.5249
 Q1:What is the purpose of this paper?
Q2:What is the purpose of COUNTERFACT?
Best ans: To evaluate counterfactual edits in language models. To test generalization–specificity tradeoff. To compare the performance of different models.
['A0: To evaluate counterfactual edits in language models. To test generalization–specificity tradeoff. To compare the performance of different models.', 'A1: The goal of this paper was to evaluate the effectiveness of counterfactual edits in language models.', 'A2: A dataset for evaluation of counterfactual edits in language models.', 'A3: A dataset for evaluation of counterfactual edits in language models', 'A4: to measure generalization–specificity tradeoff', 'A5: evaluate counterfactual edits in language models.', 'A6: Evaluation of counterfactual edits in language models.', 'A7: evaluate counterfactual edits in language models']Text: Hase et al. (2021) observed that standard model-editing benchmarks underestimate difficulty by testing only proposals that the model previously scored as likely. We compile a set of more difficult false facts (s, r, oc) and report Paraphrase Scores (PS) and (PM) to measure efficacy of significant changes. To test generalization–specificity tradeoff, we report the harmonic mean of Efficacy Score (ES)  PS, Neighborhood Score (NS) as Score (S) We also wish to measure semantic consistency of G′’s generations.  COUNTERFACT is a challenging evaluation dataset for evaluating counterfactual edits in language models. It contains 21,919 records with a diverse set of subjects, relations, and linguistic variations. The goal is to differentiate robust storage of new facts from the superficial regurgitation of target words. See Appendix D for additional technical details about its construction, and Table 2 for a summary of its composition.



RQUGE:4.4356
 Q1:How does attention influence the late site of a transformer?
Q2:What is the importance of attention at the late site?
Best ans: c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.
['A0: In the transformer, each layer’s MLP is a two-layer neural network. Attention is important at the late site of a transformer because each MLP has a pair of layers.', 'A1: c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network. Each transformer language model G :', 'A2: c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.', 'A3: Attention is important at the late site of a transformer. Each layer’s MLP is a two-layer neural network.', 'A4: (a', 'A5: b).', 'A6: [C]', 'A7: b']Text: Autoregressive transformer language model G : X → Y over vocabulary V maps a token sequence x = [x1,..., xT ] to a probability distribution y ⊂ R|V | that predicts next-token continuations of x. Within the transformer, the ith token is embedded as a series of hidden state vectors h(l) i, beginning with h(0) i = emb(xi) + pos(i) ∈ RH. The final output y = decode(h(L) T ) is read from the last hidden state.  Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.



RQUGE:4.255
 Q1:Where does this method of factual association storage come from?
Q2:What model does this paper use?
Best ans: causal trace model of memory and learning
['A0: causal trace', 'A1: causal trace model', 'A2: causal trace model of memory', 'A3: causal trace model of memory and learning', 'A4: clinical trials and clinical trials', 'A5: clinical trials', 'A6: MLP modules', 'A7: the last token']Text: Based on causal traces, we posit a specific mechanism for storage of factual associations. Each midlayer MLP module accepts inputs that encode a subject, then produces outputs that recall memorized properties about that subject. Middle layer MLP outputs accumulate information, then the summed information is copied to the last token by attention at high layers. This hypothesis localizes factual association along three dimensions, placing in the MLP modules (ii (it) (i) in the MLP modules (iii and specifically at the processing of the subject’s last token.  (e) To write new value vector v∗ into the layer, (f) we calculate a rank-one update to cause ˆ W (l) projk∗ = v, while minimizing interference with other memories stored in the layer. could be equivalently stored in any one of the middle MLP layers.



RQUGE:4.1065
 Q1:What is the Causal Tracing method? How is it used? How does it work?
Q2:What does this paper introduce?
Best ans: This paper introduces paired interventions that allow explicit measurement of causal indirect effects. We use our Causal Tracing method to measure the causal structure of models.
['A0: paired interventions that allow explicit measurement of causal indirect effects', 'A1: This paper introduces paired interventions that allow explicit measurement of causal indirect effects. We use our Causal Tracing method to measure the causal structure of models.', 'A2: We use our Causal Tracing method to measure the causal structure of models.', 'A3: This paper introduces paired interventions that allow explicit measurement of causal indirect effects. We use our Causal Tracing method to measure the causal structure of models. A common strategy is to define an empty prompt, and let a masked LM complete in the MLP modules (ii (it) (Petroni et al., 2019, 2020). Later work showed that knowledge extraction can be improved by diversifying the prompts. We compare with all these methods, and find that our single-layer Rank-One Model Editing (ROME) parameter intervention has comparable capabilities.', 'A4: to measure the causal structure of models.', 'A5: paired interventions that allow explicit measurement of causal indirect effects of individual hidden state vectors.', 'A6: to measure the causal structure of models', 'A7: We use our Causal tracing method to measure the causal structure of models']Text: The question of what a model learns is a fundamental problem that has been approached from several directions. Causal effects have been used to probe important information within a network in a way that avoids misleading spurious correlations. The Causal Tracing method introduces paired interventions that allow explicit measurement of causal indirect effects of individual hidden state vectors. Another line of work aims to assess the knowledge within LMs by evaluating whether the model predicts pieces of knowledge. We use our Causal tracing method to measure the causal structure of models.  A common strategy is to define a fill-in-the-blank prompt, and let a masked LM complete in the MLP modules (ii (it) (Petroni et al., 2019, 2020). Later work showed that knowledge extraction can be improved by diversifying the prompts. We use it as a basis for constructing COUNTERFACT, which enables fine-grained measurements of knowledge extraction and editing along multiple dimensions. Different from prior work, we do not strive to extract the most knowledge from a model, but rather wish to understand mechanisms of knowledge recall.  Mitchell et al. (2021) presents a hyper-network method that learns to transform the decomposed terms of the gradient in order to efficiently predict a knowledge update. We compare with all these methods in our experiments, and find that our single-layer Rank-One Model Editing (ROME) parameter intervention has comparable capabilities.



RQUGE:3.2064
 Q1:What is a new discovery about the language model?
Q2:What is the main conclusion of the model?
Best ans: The final output y = decode(h(L) T) is read from the last hidden state. Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery.
['A0: This paper presents an autoregressive transformer language model that maps token sequences to a probability distribution y  R|V |. Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery.', 'A1: Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is  a two-layer neural network. So the final answer is (c).', 'A2: Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is  a two-layer neural network.', 'A3: The final output y = decode(h(L) T) is read from the last hidden state. Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery.', 'A4: strong casualities', 'A5: highly clinical', 'A6: Strong causality', 'A7: highly clinically early site” in middle layers']Text: Autoregressive transformer language model G : X → Y over vocabulary V maps a token sequence x = [x1,..., xT ] to a probability distribution y ⊂ R|V | that predicts next-token continuations of x. Within the transformer, the ith token is embedded as a series of hidden state vectors h(l) i, beginning with h(0) i = emb(xi) + pos(i) ∈ RH. The final output y = decode(h(L) T ) is read from the last hidden state.  Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.



RQUGE:3.112
 Q1:How do we measure the generalization–specificity tradeoff of G′?
Q2:What is the harmonic mean of ES, PS, and NS?
Best ans: The harmonic mean of Efficacy Score (ES) Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S) is the harmonic mean (mean) of the following: Paraphrase Score (PS) PS Neighborhood score (NS). The harmonic means of these scores are:
['A0: The harmonic mean of Efficacy Score (ES) Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S) is the harmonic mean (mean) of the following: Paraphrase Score (PS) PS Neighborhood score (NS). The harmonic means of these scores are: Efficacity Score (E) PS.', 'A1: The harmonic mean of Efficacy Score (ES) Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S) is the harmonic mean (mean) of the following: Paraphrase Score (PS) PS Neighborhood score (NS). The harmonic means of these scores are:', 'A2: The harmonic mean of Efficacy Score (ES) Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S) is the harmonic mean (mean) of the following: Paraphrase Score (PS) PS Neighborhood score (NS).', 'A3: The harmonic mean of Efficacy Score (ES) Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S) is the harmonic mean (mean) of the following:', 'A4: the harmonic mean of Efficiency Score Paraphrase Scores (PS)  Neighborhood Score (NS) as Score (S)', 'A5: the harmonic mean of', 'A6: the harmonic mean', 'A7:  Efficacy Score (ES)PS, Neighborhood Score (NS) as Score (S)']Text: Hase et al. (2021) observed that standard model-editing benchmarks underestimate difficulty by testing only proposals that the model previously scored as likely. We compile a set of more difficult false facts (s, r, oc) and report Paraphrase Scores (PS) and (PM) to measure efficacy of significant changes. To test generalization–specificity tradeoff, we report the harmonic mean of Efficacy Score (ES)  PS, Neighborhood Score (NS) as Score (S) We also wish to measure semantic consistency of G′’s generations.  COUNTERFACT is a challenging evaluation dataset for evaluating counterfactual edits in language models. It contains 21,919 records with a diverse set of subjects, relations, and linguistic variations. The goal is to differentiate robust storage of new facts from the superficial regurgitation of target words. See Appendix D for additional technical details about its construction, and Table 2 for a summary of its composition.



RQUGE:2.8266
 Q1:What are the parameters of the experiment?
Q2:What are the internal components of GPT-2 XL?
Best ans: 1.5B parameters = 0, 1, 2, 3, 4, 5, 6, 7, 0.
['A0: 1.5B parameters = 0, 1, 2, 3, 4, 5, 6, 7, 0.', 'A1: 1.5B parameters = 0, 1, 2, 3, 4, 5, 6, 7, 0', 
'A2:  average total effect (AIE (effect) (ATE)= average indirect effect (AIE) (AUE) of the internal components of GPT-2 XL (1.5B parameters) The ATE of this experiment is 18.6%.', 'A3:  average indirect effect (AIE (effect) (AIE)8.7% at layer 15 at the last subject token. The average total effect (ATE) of this experiment is 18.6%.', 'A4: 1,5b', 'A5: 2.5', 'A6: ATE', 'A7: 2.5 B']Text: Figure 2 plots the average indirect effect (AIE (effect) (AIE) of the internal components of GPT-2 XL (1.5B parameters) The average total effect (ATE) of this experiment is 18.6%, and we note that a large portion of the effect is mediated by strongly causal individual states (AIE=8.7% at layer 15) at the last subject token. The presence of strong causal states at a late site immediately before the prediction is unsurprising, but their emergence at an early site is a new discovery. Decomposing the causal effects suggests a decisive role for MLP modules at the early site.  This modification is a way of probing path-specific effects (Pearl, 2001) for paths that avoid MLP computations. Causal Tracing is more informative than gradient-based salience methods such as integrated gradients. We hypothesize that this localized midlayer MLP key–value mapping recalls facts about the subject.



RQUGE:2.8073
 Q1:In which layer of a neural network is attention important for the late site?
Q2:What is the MLP layer?
Best ans: The last layer of a neural network is the MLP layer. Attention is important at the late site. The final answer: (c). The last layers of  a neuronal network.
['A0: The last layer of a neural network is the MLP layer. Attention is important at the late site. The final answer: (c). The last layers of  a neuronal network.', 'A1: In the model G, the last layer has a two-layer MLP. The last layer of the model has b MLP contributions dominate the early site. The final answer: (b).', 'A2: c) Attention is important at the late site. Each Layer’s MLP is a two-layer neural network. The final answer: (c).', 'A3: Last layer is the layer where the MLP contributions dominate. Attention is important at the late site. Each layer’s MLP is a two-layer neural network. The final answer: (c).', 'A4: b', 'A5: MLP', 'A6: last', 'A7: last layers']Text: Autoregressive transformer language model G : X → Y over vocabulary V maps a token sequence x = [x1,..., xT ] to a probability distribution y ⊂ R|V | that predicts next-token continuations of x. Within the transformer, the ith token is embedded as a series of hidden state vectors h(l) i, beginning with h(0) i = emb(xi) + pos(i) ∈ RH. The final output y = decode(h(L) T ) is read from the last hidden state.  Strong causality at a ‘late site’ in the last layers at the last token is unsurprising, but strongly causal states at an ‘early site” in middle layers is a new discovery. (b) MLP contributions dominate the early site. (c) Attention is important at the late site. Each layer’s MLP is a two-layer neural network.



RQUGE:2.5599
 Q1:Which metrics are used to measure the effectiveness of counterfactual edits?
Q2:What do we report to measure efficacy of significant changes?
Best ans:  Paraphrase Scores (PS) and (PM)
['A0: Efficacy score (ES) Paraphrase Scores (PS) neighborhood score (NS) Efficiency score (PS) PS Efficity score (PM) ES', 'A1: Efficacy score (ES) Paraphrase Scores (PS) neighborhood score (NS) Efficiency score (PS) PS Efficity score (PM) Efficacy Score (ES) PS NS', 'A2: Efficacy score (ES) Paraphrase Scores (PS) neighborhood score (NS) Efficiency score (PS) PS Efficity score (PM) Efficacy Score (ES) PS Neighborhood Score (NS) S', 'A3: Efficacy score (ES) Paraphrase Scores (PS) neighborhood score (NS) Efficiency score (PS) PS Efficity score (PM)', 'A4: paraphrasing scores', 'A5:  Paraphrase Scores (PS) and (PM)', 'A6: PS', 'A7: NS']Text: Hase et al. (2021) observed that standard model-editing benchmarks underestimate difficulty by testing only proposals that the model previously scored as likely. We compile a set of more difficult false facts (s, r, oc) and report Paraphrase Scores (PS) and (PM) to measure efficacy of significant changes. To test generalization–specificity tradeoff, we report the harmonic mean of Efficacy Score (ES)  PS, Neighborhood Score (NS) as Score (S) We also wish to measure semantic consistency of G′’s generations.  COUNTERFACT is a challenging evaluation dataset for evaluating counterfactual edits in language models. It contains 21,919 records with a diverse set of subjects, relations, and linguistic variations. The goal is to differentiate robust storage of new facts from the superficial regurgitation of target words. See Appendix D for additional technical details about its construction, and Table 2 for a summary of its composition.



RQUGE:2.4067
 Q1:How do we select the subject?
Q2:How does the optimization process work?
Best ans: In the MLP module, we identify the vector representation of the new property for the subject s. We use the following algorithm:
['A0: In the MLP module, we identify the vector representation of the new property for the subject s. We use the following algorithm:', 'A1: In the MLP module, we identify the vector representation of the new property for the subject s.', 'A2: Using the Moore-Penrose pseudoinverse, we can derive a closed form solution: minimize  WK  V. In a fully-connected layer, we have a solution that minimizes  WK - V.', 'A3: The method is based on a Moore-Penrose pseudoinverse: W = V K+. Because of this simple algebraic structure, we can insert any fact directly once (k, v) is computed.', 'A4: ', 'A5: subject is a', 'A6: we chose the subject at its last token as the lookup key', 'A7: ']Text: A new key–value pair (k∗, v∗) can be inserted optimally into the memory by solving a constrained least-squares problem. In a convolutional network, Bau et al. solve this using an optimization, but in a fully-connected layer, we can derive a closed form solution: minimize ∥ ˆWK − V. The solution is based on the Moore-Penrose pseudoinverse: W = V K+.  Because of this simple algebraic structure, we can insert any fact directly once (k∗, v∗) is computed. Step 1: Choosing k∗ to Select the Subject, we choose inputs that represent the subject at its last token as the lookup key. Step 2: We choose some vector value vâ� that encodes the new relation (r, o∗), as a property of s. Step 3: We sample xj by generating 50 random token sequences of length 2 to 10 using G.  Eqn.4a seeks a vector z that, when substituted as the output of the MLP at the token i at the end of the subject (notated G(m(l∗) i := z), will cause the network to predict the target object o∗ in response to the factual prompt p′ (of the form “{subject} is a”) The optimization does not directly alter model weights; in the MLP modules (ii (it) identifies a vector representation v∗ that when output at the targeted MLP module, represents the new property for the subject s.



RQUGE:2.3164
 Q1:Why does G lose some information about the subject?
Q2:What is the recurrent model used for?
Best ans: We use the recurrent model to model the subject. We use a set of corrupted activations to model a subject. The recursive model is a model of a state. The model is used to model states.
['A0: We use the recurrent model to model the subject. We use a set of corrupted activations to model a subject. The recursive model is a model of a state.', 'A1: We use the recurrent model to model the subject. We use a set of corrupted activations to model a subject. The recursive model is a model of a state. The model is used to model states.', 'A2: We use the recurrent model to model the subject. We use a set of corrupted activations to model a subject. The recursive model is a model of a state. The model is used to model states. The answer: G is allowed to continue normally, giving us a aset of corrupt activations.', 'A3: In the GPT variants we use the following model: G is allowed to continue normally, giving us a set of corrupted activations. We select  to be 3 times larger than the empirical standard deviation of embeddings G is a GPT model that uses the MLP to perform computations on the noisy embeddments.', 'A4: corruption of activations.', 'A5: corrupted activations.', 'A6: corruption of activations', 'A7: corruption']Text: The grid of states (Figure 1) forms a causal graph (Pearl, 2009) describing dependencies between the hidden variables. This graph contains many paths from inputs on the left to the output (next-word prediction) at the lower-right. We wish to understand if there are specific hidden state variables that are more important than others when recalling a fact. As Vig et al. (2020b) have shown, this is a natural case for causal mediation analysis.  G is allowed to continue normally, giving us a set of corrupted activations. Because G loses some information about the subject, in the MLP modules (ii (it) will likely return an incorrect answer. The corrupted-with-restoration run, lets G run computations on the noisy embeddings as in the corrupted baseline. The ability of a few clean states to recover the correct fact, despite many other states being corrupted by the obfuscated subject, will indicate their causal importance in the computation graph. The total effect (AIE (effect) (TE) is the difference between these quantities: TE = P[o] − P∗[o].  The indirect effect (IE) of a specific mediating state h(l) i is defined as the difference between the probability of o under the corrupted version and the probability when that state is set to its clean version, while the subject remains corrupted. Our methods also apply to GPT variants such as Wang & Komatsuzaki (2021) that put attention in parallel to the MLP. We select ν to be 3 times larger than the empirical standard deviation of embeddings.



RQUGE:2.2685
 Q1:What is ROME? How does it compare to hypernetworks and fine-tuning methods?
Q2:What is Rank-One Model Editing (ROME)?
Best ans: A method for editing one-to-one relationships in the context of a sentence. Rank-One Model Editing (ROME) is an approach to editing one model in the same sentence, which is a common approach to the Zero-Shot Re-
['A0: A method for editing one-to-one relationships in the context of a sentence.', 'A1: A method for editing one-to-one relationships in the context of a sentence. Rank-One Model Editing (ROME) is an approach to editing one model in the same sentence, which is a common approach to the Zero-Shot Re-', 'A2: The Rank-One Model Editing (ROME) is a model editing method that is based on the Zero-Shot Re-', 'A3:  Rank-One Model Editing (ROME)is a model editing method that is based on the Zero-Shot Re-', 'A4: A model editing method that is competitive with hypernetworks and fine-tuning methods despite its simplicity', 'A5: The Rank-One Model Editing (ROME) is competitive with hypernetworks and fine-tuning methods despite its simplicity.', 'A6: We evaluate Rank-One Model Editing (ROME) on the Zero-Shot Re-', 'A7:  Rank-One Model Editing (ROME)is competitive with hypernetworks and fine-tuning methods despite its simplicity.']Text: We evaluate Rank-One Model Editing (ROME) on the Zero-Shot Re-  Table 1: zero-shot relation extraction (zsRE) Editing Results on GPT-2 XL. lation Extraction (zsRE) task. Our evaluation slice contains 10,000 records, each containing one factual statement, its paraphrase, and one unrelated fact. “Efficacy” and “Paraphrase” measure post-edit accuracy I o∗ = argmaxoPG′ [o], while “Specificity” measures the edited model’s accuracy on an unrelated fact.  ROME is competitive with hypernetworks and fine-tuning methods despite its simplicity. We find that in the MLP modules (ii (it) is not hard for ROME to insert an association that can be regurgitated by the model. Robustness under paraphrase is also strong, although it comes short of custom-tuned hyperparameter networks Knowledge Editor (KE) zsRE and MEND-ZsRE.



RQUGE:2.1845
 Q1:Which of these is the best way to store factual associations?
Q2:Where does the hypothesis localize factual association along three dimensions?
Best ans: The hypothesis localizes factual association along three dimensions, placing in the MLP modules (ii) in the middle MLP layers (i) and specifically at the processing of the subject’s last token.
['A0: The hypothesis localizes factual association along three dimensions, placing in the MLP modules (ii) in the middle MLP layers (i) and specifically at the processing of the subject’s last token. The final answer: (i).', 'A1: The hypothesis localizes factual association along three dimensions, placing in the MLP modules (ii) in the middle MLP layers (i) and specifically at the processing of the subject’s last token.', 'A2:  ii) at specific middle layers (iii)and specifically at the processing of the subject’s last token.', 'A3: We posit a specific mechanism for storage of factual associations. Each midlayer MLP module accepts inputs that encode a subject, then produces outputs that recall memorized properties about that subject. High layers are used to process the subject’s last token.', 'A4: f)', 'A5: MLP modules (ii)', 'A6: f', 'A7: MLP modules']Text: Based on causal traces, we posit a specific mechanism for storage of factual associations. Each midlayer MLP module accepts inputs that encode a subject, then produces outputs that recall memorized properties about that subject. Middle layer MLP outputs accumulate information, then the summed information is copied to the last token by attention at high layers. This hypothesis localizes factual association along three dimensions, placing in the MLP modules (ii (it) (i) in the MLP modules (iii and specifically at the processing of the subject’s last token.  (e) To write new value vector v∗ into the layer, (f) we calculate a rank-one update to cause ˆ W (l) projk∗ = v, while minimizing interference with other memories stored in the layer. could be equivalently stored in any one of the middle MLP layers.



