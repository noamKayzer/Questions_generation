(0) RQUGE:5.106
Q1:Why did they use LIWC?
Q2:What did previous studies on crowdfunding use LIWC for?
Best ans: To analyze the textual description part of projects.
['A0: They wanted to analyze textual description part of projects', 'A1: To analyze the textual description part of projects.', 'A2: We used Linguistic Inquiry and Word Count (LIWC) to extract features from the text. LIWC analysis measures the appearance of dictionary words in a specific text.', 'A3:  Linguistic Inquiry and Word Count (LIWC)analysis measures the appearance of dictionary words in a specific text.', 'A4: analyzes', 'A5: analyze', 'A6: measure the appearance of dictionary words in', 'A7: To extract features from the text']
Text: We used the Linguistic Inquiry and Word Count (LIWC) software tool to extract features from the text. LIWC analysis measures the appearance of dictionary words in a specific text. The measure is a numeric value in the range [0..1]. It reflects the degree to which the text being analyzed is related to the theme of the dictionary. The output of LIWC is VD = SD/NT, which is the value of the feature that corresponds to D. Previous studies on crowdfunding used LIWC to analyze the textual description part of projects.  The number and diversity of features in our study are much larger than previously published, and our dataset is significantly greater as well. As a result, we arrive at much higher model accuracy.



(4) RQUGE:5.0702
Q1:Which model has the highest accuracy?|What is the dataset used?|
Q2:On what dataset was training performed on?
Best ans: All_D
['A0: Models trained on All_D with 10-fold cross validation.', 'A1: All_D is a dataset used in this study.', 'A2: Using All_D dataset, we trained the Latent Dirichlet allocation (LDA) Model, Metadata-Model and Semantic-Model with the following algorithms:', 'A3:  Latent Dirichlet allocation (LDA)Model is trained on All_D with 10-fold cross-validation. Semantic-Model has the highest accuracy.', 'A4: Semantic-Model', 'A5:  Latent Dirichlet allocation (LDA)Model', 'A6: All_D', 'A7: Model we developed']
Text: The study aims to examine whether the set of features we use for prediction and the dataset on which learning was applied deliver a better model by means of F-score accuracy. We trained the Latent Dirichlet allocation (LDA) Model and the Metadata-Model with the algorithms that were used in the studies above, and with additional algorithms, including SVM, J48, Random forest, LightGBM, SDG, and DNN. This training was performed on All_D with 10-fold cross-validation.  F-score is used for consistency with the earlier studies to which we compare. Figure shows that the model we developed has the highest accuracy. The accuracy of the Semantic-Model is similar to that of the LDA-Model and the Metadata-Model.



(6) RQUGE:5.0184
Q1:Which features are associated with the success of crowdfunding projects?||
Q2:What are two features that are highly correlate with a project's success in fund raising?
Best ans: Buzzwords and LIWC
['A0: An approach to crowdfunding success prediction based on semantic features.', 'A1: We use unique features (for example, the use of buzzwords) and perform extensive research on the semantics of projects’ text.', 'A2: Using a large dataset, we use a combination of a semantic model and a model based on the use of buzzwords to predict funding success of crowdfunding projects.', 'A3: Using a large dataset, we use a combination of a semantic model and a model based on the use of buzzwords to predict funding success of crowdfunding projects. The model is based upon the following: Buzzwords and Linguistic Inquiry and Word Count (LIWC) are among the highly correlate features with the project’s success in fund raising.', 'A4: buzzwords', 'A5: Buzzwords and LIWC', 'A6: A more comprehensive approach to studying and predicting crowdfunding', 'A7: Article summary']
Text: In recent years, crowdfunding has emerged as a popular financing mechanism that allows various types of projects to get funded. Three main parties are involved in crowdfunding: entrepreneurs (and their projects), individuals or groups who support the project, and online platforms, i.e., crowdfunding websites. The average success rate of funded crowdfunding projects in Kickstarter is 37.5% [4] In this paper, we refer to a project as a funding success (FS) if it achieved its funding goal (i.e.  In contrast to prior studies, we take a more comprehensive approach to studying and predicting funding success. We use unique features (for example, the use of buzzwords) and perform extensive research on the semantics of the projects’ text. Our main research objective is to find characteristics, with a focus on semantic characteristics, which affect the success of a project in meeting its funding goal via crowdfunding. This approach leverages known results and improves upon them to provide high-quality funding success prediction.  Achieving these research objectives should provide new insights into the relationship between crowdfunding project’s data and their funding success. This should provide entrepreneurs with additional and desirable ways to improve their chances of reaching their funding goals. The accuracy of the semantic-model (in terms of F-score and correctly classified instances) is comparable to the accuracy of state-of-the-art models which are based on metadata features such as the number of updates, number of images, etc.  The accuracy of the combined-model is higher than the accuracy derived in previous studies that use other models [11–14] Fourth, we show that buzzwords and Linguistic Inquiry and Word Count (LIWC) are among the highly correlate features with the project’s success in fund raising. Fifth, to the best of our knowledge, our research relies on the largest dataset used to date for developing models that predict funding success of crowdfunding projects. In addition to the scientific contributions listed above, we provide a set of recommendations that may increase project funding success chances.  The Methodology section focuses on the research methodology applied, including the acquisition of our dataset, preprocessing, feature extraction and selection. The Results section presents the empirical evaluation of our research model and discusses the results. It further compares our models to models in earlier studies.



(7) RQUGE:4.8242
Q1:Who developed Semantic-Model?
Q2:What did we use to develop the semantic model?
Best ans: To develop the Semantic Model, semantic features were used as input. We utilized several machine learning algorithms.
['A0: A team of researchers developed the Semantic-Model.', 'A1: We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN and more) on All_D.', 'A2: To develop the Semantic Model, semantic features were used as input. We utilized several machine learning algorithms. The Semanic Model was developed by:', 'A3: To develop the Semantic Model, semantic features were used as input. We utilized several machine learning algorithms.', 'A4: we', 'A5: authors', 'A6: team', 'A7: researchers']
Text: For the development of the Semantic-Model, semantic features were used as input. We utilized several machine learning algorithms (including SVM, J48, Random Forest, LightGBM, SDG, DNN, and more) on All_D. Table 2 presents the accuracies metrics of the combined-model: Combined model.  The semantic-model we have developed is comparable in accuracy with the state of the art (metadata) models, exhibiting an accuracy level of 91.2%. The LightGBM algorithm exhibited a high accuracy level for all three datasets. In particular, the accuracy of the prediction model is greater than 94% for all datasets.



(8) RQUGE:4.7051
Q1:Why did they use LDA? What is it used for?
Q2:What is known about LDA?
Best ans: previous experiments used Latent Dirichlet allocation (LDA) to perform topic analysis on the text of project updates. The latter is known to run faster than other implementations and generates better topic segregation.
['A0: Prior research has used Latent Dirichlet allocation (LDA) to perform topic analysis on the text of project updates.', 'A1: previous experiments used Latent Dirichlet allocation (LDA) to perform topic analysis on the text of project updates. The latter is known to run faster than other implementations and generates better topic segregation.', 'A2: The latter is known to run faster than other implementations and generates better topic segregation. Previous studies on crowdfunding used Latent Dirichlet allocation (LDA) to perform topic analysis.', 'A3: Previous studies on crowdfunding used Latent Dirichlet allocation (LDA) to perform topic analysis on the text of project updates.', 'A4: topic analysis', 'A5: perform topic analysis on the text of project updates.', 'A6: to perform topic analysis on the text of project updates.', 'A7: perform topic analysis on the text of project updates']
Text: Latent Dirichlet allocation (LDA) is a widely used topic modeling method. LDA algorithm considers each document as a collection of topics, where each word in the document belongs to one or some of these topics. Previous studies on crowdfunding used LDA to perform topic analysis on the text of project updates. We used the Gensim Python package LDA implementation (from GitHub.com) to execute LDA. The latter is known to run faster than other implementations and generates better topic segregation [16].  The three main inputs to the LDA topic model are the dictionary, the corpus, and the number of topics. Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] To avoid overfitting, we chose the one that derived the highest coherence value and the smallest number of. topics. There were 30 topics that derived. the highest. coherence values for the All_D dataset, 15 for the Tech_D and 15 for Market_D datasets.



(9) RQUGE:4.4884
Q1:Modeling Crowdfunding Projects' Fundraising Success?
Q2:What is the purpose of this paper?
Best ans: The purpose of this paper is to: Modeling Crowdfunding Projects' Fundraising Success.
['A0: The purpose of this paper is to:', "A1: The purpose of this paper is to: Modeling Crowdfunding Projects' Fundraising Success.", "A2: Modeling Crowdfunding Projects' Fundraising Success?", "A3: Modeling Crowdfunding Projects' Fundraising Success", 'A4: An additional Model', 'A5: novel model for crowdfunding projects in meeting their funding goals', 'A6: model for crowdfunding projects in meeting their funding goals', "A7: Modeling Crowdfunding Projects' Fundraising Success"]
Text:Crowdfunding platforms allow entrepreneurs to publish projects and raise funds for realizing them. Hence, the question of what influences projects’ fundraising success is very important. Previous studies examined various factors such as project goals and project duration that may influence the outcomes of fundraising campaigns. We present a novel model for predicting the success of crowdfunding projects in meeting their funding goals. Our model focuses on semantic features only, whose performance is comparable to that of previous models. In an additional model we developed, we examine both project metadata and project semantics, delivering a comprehensive study of factors influencing crowdfunding success. Further, we analyze a large dataset of crowdfunding project data, larger than reported in the art. Finally, we show that when combining semantics and metadata, we arrive at F1 score accuracy of 96.2%. We compare our model’s accuracy to the accuracy of previous research models by applying their methods on our dataset, and demonstrate higher accuracy of our model. In addition to our scientific contribution, we provide practical recommendations that may increase project funding success chances.



(10) RQUGE:4.3635
Q1:Why did this study investigate the relationship between funding and buzzwords?
Q2:What are the results of this study relevant to?
Best ans: Fundraisers using crowdfunding web platforms use buzzwords to attract more funding.
['A0: It is among features highly associated with funding success.', 'A1: They found that buzzwords are highly correlated with crowdfunding.', 'A2: Fundraisers using crowdfunding web platforms use buzzwords to attract more funding.', 'A3: A new model based on semantic features is developed to predict funding success.', 'A4: to fundraise using crowdfunding web platforms.', 'A5: high correlation', 'A6: high correlation with funding success', 'A7: to fundraise using crowdfunding web platforms']
Text: The study is the first that investigates the relationship between funding success and buzzwords. The buzzwords feature is among the features that are highly correlated to funding success compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model’s performance could be achieved via novel feature selection algorithms.



(12) RQUGE:4.2806
Q1:Which topic model is best for crowdfunding text?
Q2:What is a widely used topic modeling method?
Best ans:  Latent Dirichlet allocation (LDA)model
['A0: In this paper, we use the Latent Dirichlet allocation (LDA) method to model crowdfunding text.', 'A1: Gensim Python package Latent Dirichlet allocation (LDA) implementation (from GitHub.com) to execute LDA. The three main inputs to the.', 'A2: Using Latent Dirichlet allocation (LDA)  we used Gensim Python package LDA to execute topic modeling on the text of project updates.', 'A3: To avoid overfitting, we chose the topic model that derived the highest coherence value and smallest number of topics. The final answer: Latent Dirichlet allocation (LDA) ', 'A4: all', 'A5: All_D', 'A6:  Latent Dirichlet allocation (LDA)model', 'A7: LDA']
Text: Latent Dirichlet allocation (LDA) is a widely used topic modeling method. LDA algorithm considers each document as a collection of topics, where each word in the document belongs to one or some of these topics. Previous studies on crowdfunding used LDA to perform topic analysis on the text of project updates. We used the Gensim Python package LDA implementation (from GitHub.com) to execute LDA. The latter is known to run faster than other implementations and generates better topic segregation [16].  The three main inputs to the LDA topic model are the dictionary, the corpus, and the number of topics. Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is [16] To avoid overfitting, we chose the one that derived the highest coherence value and the smallest number of. topics. There were 30 topics that derived. the highest. coherence values for the All_D dataset, 15 for the Tech_D and 15 for Market_D datasets.



(14) RQUGE:4.0421
Q1:Which features are most correlated with funding success?
Q2:What is the novelty of the combined model?
Best ans: A large dataset of Kickstarter and Indiegogo projects was used to train the model to predict funding success. The model was trained on the datasets: All_D, Market_D and Tech_D. The models were trained on a 10-fold cross-validation test. The combined model was developed by combining semantic and meta-data features to predict the funding success of a project.
['A0: To study funding success, we used the following data: Kickstarter and Indiegogo datasets. We used Beautifulsup to obtain additional metadata features. We built three dataset: All_D (all_d), Tech_D and Market_D. We performed a 10-fold cross-validation test to evaluate the model’s performance and developed a combined-model.', 'A1: Datasets were collected from Kickstarter and Indiegogo. We obtained data from Kaggle. We used Beautifulsup to extract data from the Kaggler website. We compared the data with the datasets to find the most significant set of features (MSSF) that has the highest impact on funding success. We performed a 10-fold cross-validation test to evaluate the model’s performance.', 'A2: A large dataset of Kickstarter and Indiegogo projects was used to train the model to predict funding success. The model was trained on the datasets: All_D, Market_D and Tech_D. The models were trained on a 10-fold cross-validation test.', 'A3: A large dataset of Kickstarter and Indiegogo projects was used to train the model to predict funding success. The model was trained on the datasets: All_D, Market_D and Tech_D. The models were trained on a 10-fold cross-validation test. The combined model was developed by combining semantic and meta-data features to predict the funding success of a project.', 'A4: buzz words', 'A5: Buzzwords', 'A6: The combined-model', 'A7: CFS (correlation-based feature selection)']
Text: We used a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects. We obtained these data from the Kaggle website for 2018. We used Beautifulsup (a Python web scraping package) to gain additional metadata features, such as, description content, number of updates, etc. For each record in the dataset, we obtained the values of five metadata features and about 120 semantic features, including buzzwords, Linguistic Inquiry and Word Count (LIWC) outputs, feelings words, explanation words, and Latent Dirichlet allocation (LDA) outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets.  To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the following analysis goals: First, it facilitates improvement in the LDA topic coherence score. Second, it allows us to determine whether a category affects the features that are highly correlated with funding success. Third, to study the correlation between buzzwords and funding success (FS)  it is preferable for datasets to be separated into specific subdomains.  For each dataset, the original features space was reduced into three Principal Components (PCs) The sum of the explained variance ratio of these three PCs is 78% of the total variance. To identify the most significant set of features (MSSF) that has the highest impact on FS, we use the CFS (correlation-based feature selection) algorithm. The Principal Component Analysis (PCA) plots in Fig 1 present the distribution of the All_D, Market_D and Tech_D datasets. Dots in blue represent unsuccessfully funded projects and red represent successfully funded projects.  The models’ design, derivation, and operational tests were conducted using the following Python packages: scikit-learn, scikits-feature and LightGBM. We employed a 10-fold cross-validation test to evaluate the prediction performance. Fig 2 includes a flowchart of the methodology. To validate the results of our study, we compared our model’s accuracy to previous research models by applying their methods on our dataset. To this end, we have developed the combined-model, whose novelty lies in the combination of semantic and meta-data features.



(15) RQUGE:3.9938
Q1:Are LDA Models Better than Metadata Model?
Q2:What does the figure show?
Best ans: Compared to previous studies, we trained Latent Dirichlet allocation (LDA) Models and Metadata Models with additional algorithms. The model we developed has the highest accuracy.
['A0: Models trained with the Latent Dirichlet allocation (LDA) Model and the Metadata-Model are similar in accuracy. The model we developed has the highest accuracy of the LDC Model.', 'A1: Compared to previous studies, we trained Latent Dirichlet allocation (LDA) Models and Metadata Models with additional algorithms. The model we developed has the highest accuracy.', 'A2:  Latent Dirichlet allocation (LDA)Models are trained on a dataset of all_d. Metadata Models were trained on the dataset of only d. The accuracy of the LDA-Model is higher than that of the Metadata-Model.', 'A3: A comparison of the Latent Dirichlet allocation (LDA) Model and the Metadata Model. The LDA model has the highest accuracy. The Metadata model has a lower F-score.', 'A4:  Latent Dirichlet allocation (LDA)Models', 'A5: no', 'A6: yes', 'A7: No']
Text: The study aims to examine whether the set of features we use for prediction and the dataset on which learning was applied deliver a better model by means of F-score accuracy. We trained the Latent Dirichlet allocation (LDA) Model and the Metadata-Model with the algorithms that were used in the studies above, and with additional algorithms, including SVM, J48, Random forest, LightGBM, SDG, and DNN. This training was performed on All_D with 10-fold cross-validation.  F-score is used for consistency with the earlier studies to which we compare. Figure shows that the model we developed has the highest accuracy. The accuracy of the Semantic-Model is similar to that of the LDA-Model and the Metadata-Model.



(16) RQUGE:3.9131
Q1:Which features are highly correlated to funding success?
Q2:What are the buzzwords feature?
Best ans: Project-specific aspects and semantics of project descriptions. The Buzzwords feature is among the features correlated to funding success.
['A0: buzz words', 'A1: buzz words feature', 'A2: Project-specific aspects and semantics of project descriptions.', 'A3: Project-specific aspects and semantics of project descriptions. The Buzzwords feature is among the features correlated to funding success.', 'A4: hyped', 'A5: buzz words', 'A6: hype', 'A7: buzzwords feature']
Text: The study is the first that investigates the relationship between funding success and buzzwords. The buzzwords feature is among the features that are highly correlated to funding success compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model’s performance could be achieved via novel feature selection algorithms.



(17) RQUGE:3.6477
Q1:What features are most influential for funding success? Feature Selection
Q2:What does the CFS algorithm evaluate subsets of features based on?
Best ans: Feature Selection The following is a list describing the features that are most influential for funding success. The following features are evaluated based on the individual predictive ability of each feature along with the degree of redundancy between them.
['A0: Dataset: We used the following datasets: The following dataset is used: The datasets are:', 'A1: Feature Selection The following is a list describing the features that are most influential for funding success.', 'A2: Feature Selection The following is a list describing the features that are most influential for funding success. The following features are evaluated based on the individual predictive ability of each feature along with the degree of redundancy between them.', 'A3: Feature Selection The following is a list describing the features that are most influential for funding success. The following features are evaluated based on the individual predictive ability of each feature along with the degree of redundancy between them. Among the top 10 features, about 70% of the features are the same across data sets', 'A4: Feature Selection (Feature Selection)', 'A5: A feature selection method for predicting funding success.', 'A6: A feature selection method for predicting funding success', 'A7: The following is a list of features that are most influential for funding success.']
Text: In this section, we provide details of the data setup, the usage of the Latent Dirichlet allocation (LDA) algorithm, the feature correlation analysis, and the feature selection process. In what follows we describe the way in which we found the features that are most influential for funding success (FS)  The CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.  The semantic features buzzwords and Linguistic Inquiry and Word Count (LIWC) are among the features that have a higher correlation in all datasets. An important, unique conclusion of our study is that the features correlated to FS are dependent on the project category. Among the top 10 features, about 70% of the features are the same across datasets. For example, the features feelings_num and buzz_num appear in the three top 10 lists. In contrast, the parameter WC is unique in the R_Tech _D top 10 list and the parameter number is distinctive.



(18) RQUGE:3.6092
Q1:How do they predict crowdfunding success?
Q2:What is the prediction model based on?
Best ans: A model is developed based on semantic and project-specific aspects and semantics of the project descriptions to predict crowdfunding success.
['A0: A model is developed based on semantic and project-specific aspects and semantics of the project descriptions to predict crowdfunding success. The model is based mainly on buzzwords.', 'A1: A model is developed based on semantic and project-specific aspects and semantics of the project descriptions to predict crowdfunding success.', 'A2: Using the buzzword feature, they developed a model that is based on semantic features only and achieved similar accuracy level as previous studies. They also developed s a prediction model with an impressive Fscore of 96.2 percent.', 'A3: They develop an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. They also developed a prediction model with an impressive fscore.', 'A4: buzzwords', 'A5: buzzwords feature', 'A6: The buzzwords feature', 'A7: model based on semantic features only']
Text: The study is the first that investigates the relationship between funding success and buzzwords. The buzzwords feature is among the features that are highly correlated to funding success compared to other parameters that we examined and that other researchers examined. We developed a novel model based on semantic features only and achieved similar accuracy level as previous studies. We also developed a prediction model with an impressive Fscore of 96.2%, focusing on both project-specific aspects and semantics of project descriptions. The results of our study are highly relevant to fundraisers using crowdfunding web platforms.  Future research could further improve accuracy by considering the characteristics of images, video content and the semantics of video scripts. Further improvements in the model’s performance could be achieved via novel feature selection algorithms.



(21) RQUGE:3.345
Q1:What datasets were used to study the relationship between buzzwords and funding success?
Q2:What are the three datasets used to study the relationship between features and project category?
Best ans: All_D, Market_D and Tech_D datasets.
['A0: Kickstarter and Indiegogo datasets.', 'A1: Kickstarter and Indiegogo datasets', 'A2: All_D, Market_D and Tech_D datasets.', 'A3: 50,000 Kickstarter and 50,00 Indiegogo projects', 'A4: alld', 'A5: Kaggle', 'A6: Kaggle dataset', 'A7: The combined-model']
Text: We used a dataset of 50,000 Kickstarter and 50,00 Indiegogo projects. We obtained these data from the Kaggle website for 2018. We used Beautifulsup (a Python web scraping package) to gain additional metadata features, such as, description content, number of updates, etc. For each record in the dataset, we obtained the values of five metadata features and about 120 semantic features, including buzzwords, Linguistic Inquiry and Word Count (LIWC) outputs, feelings words, explanation words, and Latent Dirichlet allocation (LDA) outputs. We removed LDA topics that overlapped with LIWC topics by comparing the topic sets.  To study the relationship between features and the project category, we built three datasets: All_D, Tech_D and Market_D. The division aims to address the following analysis goals: First, it facilitates improvement in the LDA topic coherence score. Second, it allows us to determine whether a category affects the features that are highly correlated with funding success. Third, to study the correlation between buzzwords and funding success (FS)  it is preferable for datasets to be separated into specific subdomains.  For each dataset, the original features space was reduced into three Principal Components (PCs) The sum of the explained variance ratio of these three PCs is 78% of the total variance. To identify the most significant set of features (MSSF) that has the highest impact on FS, we use the CFS (correlation-based feature selection) algorithm. The Principal Component Analysis (PCA) plots in Fig 1 present the distribution of the All_D, Market_D and Tech_D datasets. Dots in blue represent unsuccessfully funded projects and red represent successfully funded projects.  The models’ design, derivation, and operational tests were conducted using the following Python packages: scikit-learn, scikits-feature and LightGBM. We employed a 10-fold cross-validation test to evaluate the prediction performance. Fig 2 includes a flowchart of the methodology. To validate the results of our study, we compared our model’s accuracy to previous research models by applying their methods on our dataset. To this end, we have developed the combined-model, whose novelty lies in the combination of semantic and meta-data features.



(29) RQUGE:1.1258
Q1:Why do we use LDA?
Q2:What algorithm was used to find the most influential features?
Best ans: To find features that are most influential for funding success (FS)  we used the Latent Dirichlet allocation (LDA) algorithm.
['A0: A dataset of 3000+ companies was used to evaluate the features that are most influential for funding success.', 'A1: A dataset of 3000+ companies was used to evaluate the features that are most influential for funding success. The data was collected from the following sources:', 'A2: To find features that are most influential for funding success (FS)  we used the Latent Dirichlet allocation (LDA) algorithm.', 'A3: Feature selection process is based on the individual predictive ability of each feature along with the degree of redundancy between them.', 'A4: Feature Selection for Funding Success (FS)', 'A5: the Latent Dirichlet allocation algorithm', 'A6: To find features that are most influential for funding success (FS) ', 'A7: Feature Selection for Funding Success']
Text: In this section, we provide details of the data setup, the usage of the Latent Dirichlet allocation (LDA) algorithm, the feature correlation analysis, and the feature selection process. In what follows we describe the way in which we found the features that are most influential for funding success (FS)  The CFS algorithm evaluates subsets of features based on the individual predictive ability of each feature along with the degree of redundancy between them.  The semantic features buzzwords and Linguistic Inquiry and Word Count (LIWC) are among the features that have a higher correlation in all datasets. An important, unique conclusion of our study is that the features correlated to FS are dependent on the project category. Among the top 10 features, about 70% of the features are the same across datasets. For example, the features feelings_num and buzz_num appear in the three top 10 lists. In contrast, the parameter WC is unique in the R_Tech _D top 10 list and the parameter number is distinctive.



(30) RQUGE:1.1152
Q1:Who used linguistic inquiry and word count to extract features from text?
Q2:Who developed the LIWC software tool?
Best ans: Researchers at MIT.
['A0: Researchers', 'A1: Authors', 'A2: Researchers at MIT.', 'A3: Researchers at MIT. We used the Linguistic Inquiry and Word Count (LIWC) software tool to extract features from the text.', 'A4: team', 'A5: author', 'A6: researchers', 'A7: authors']
Text: We used the Linguistic Inquiry and Word Count (LIWC) software tool to extract features from the text. LIWC analysis measures the appearance of dictionary words in a specific text. The measure is a numeric value in the range [0..1]. It reflects the degree to which the text being analyzed is related to the theme of the dictionary. The output of LIWC is VD = SD/NT, which is the value of the feature that corresponds to D. Previous studies on crowdfunding used LIWC to analyze the textual description part of projects.  The number and diversity of features in our study are much larger than previously published, and our dataset is significantly greater as well. As a result, we arrive at much higher model accuracy.



