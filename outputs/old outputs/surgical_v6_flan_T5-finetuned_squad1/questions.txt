Q1:In this study, we present an supervised DOS model whose accuracy outperforms what?
Text:Accurate estimation of duration of surgery (DOS) can lead to cost-effective utilization of surgical staff and operating rooms and decrease patients’ waiting time. In this study, we present a supervised DOS nonlinear regression prediction model whose accuracy outperforms earlier results. In addition, unlike previous studies, we identify the features that influence DOS prediction. Further, in difference from others, we study the causal relationship between the feature set and DOS. The feature sets used in prior studies included a subset of the features presented in this study. This study aimed to derive influential effectors of duration of surgery via optimized prediction and causality analysis. We implemented an array of machine learning algorithms and trained them on datasets comprising surgery-related data, to derive DOS prediction models. The datasets we acquired contain patient, surgical staff, and surgery features. The datasets comprised 23,293 surgery records of eight surgery types performed over a 10-year period in a public hospital. We have introduced new, unstudied features and combined them with features adopted from previous studies to generate a comprehensive feature set. We utilized feature importance methods to identify the influential features, and causal inference methods to identify the causal features. Our model demonstrates superior performance in comparison to DOS prediction models in the art. The performance of our DOS model in terms of the mean absolute error (MAE) was 14.9 minutes. The algorithm that derived the model with the best performance was the gradient boosted trees (GBT)  We identified the 10 most influential features and the 10 most causal features. In addition, we showed that 40% of the influential features have a significant (p-value = 0.05) causal relationship with DOS. We developed a DOS prediction model whose accuracy is higher than that of prior models. This improvement is achieved via the introduction of a Novel column (novel) feature set on which the model was trained. Utilizing our prediction model, hospitals can improve the efficiency of surgery schedules, and by exploiting the identified causal relationship, can influence the DOS. Further, the feature importance methods we used can help explain the model’s predictions.


Q1:What are ORs?
Text: High cost of surgeries and operating rooms (ORs) have made them key elements for hospital administrators looking to streamline expenses. OR underutilization results in negative consequences such as staff idle time, increased patient waiting times for surgeries, and more. OR overutilization might overload the staff, increase patient waiting time and dissatisfaction, generate disorder, increase the probability of human error. Current practices suggest that physicians who are hospital staff members schedule the surgeries. As shown in the art, however, physicians tend to predict duration of surgery (DOS) inaccurately, thus causing sub-optimal scheduling.  machine learning (ML) techniques are widely used in health informatics studies. With the increase in surgery documentation in electronic health records, ML has become very relevant for DOS prediction. Explaining predictions produced by ML models is a necessary element of ML research in healthcare [12] Explaining the importance of each feature to the model sheds light on the model’s behavior. Such understanding allows domain experts, i.e., physicians and surgeons, to validate the model's predictions and gives them a tool for optimizing surgery management.  Causal inference addresses the problem of identifying cause and effect relationships in data [17] and has a central role in healthcare [19] Unlike previous studies, our focus is on the importance of features and the effect of that importance on the model and the predicted DOS. Our models provide a prediction for both the elective and the emergency surgery classes. We study a broad range of patient features (age, gender, BMI, etc. ) and surgical staff features. In addition, we use explanatory algorithms to analyze our model’s predictions and causal inference algorithms.  Using our prediction model, OR management teams can improve the performance of surgery scheduling in terms of patient waiting time and surgery team idle time. This study has several OR management implications. Using the identified causal relationships, OR teams can control and adjust DOS values. The paper proceeds as follows. The Introduction section presents the state-of-the-art, the motivation for this study, and its objectives.


Q1:Who did this study work with to obtain data from the Tel Aviv Sourasky Medical Center's (TASM)?
Text: The data was obtained from the Tel Aviv Sourasky Medical Center’s (TASM) (a public hospital) surgery department. The data included 23,293 retrospective surgical records, focusing on the eight most common surgeries in this department between 2010 and 2020. The full list of features is shown in Table 1. The table shows feature names, indication of whether a feature is Novel column (novel) (by a V in the Novel column), the value range of each feature, and values’ statistics. For handling missing data of other features, we used the Sequence of Regression Models (SRM) technique.  The missing values of features were computed using the values of other features.


Q1:The average treatment effect (ATE) of a feature is what?
Text: The average treatment effect (ATE) of a feature (whose value range is binary) measures the difference in the mean of the outcomes between data records with different values assigned to the feature. Since our study is observational, the ATE values could not be computed accurately, as a feature in a surgery record only has an observed value and cannot be assigned other values [29] We use Eq (1) and its extensions to calculate ATE. Two main machine learning (ML) model types, propensity and heterogeneity models, are used for estimating causal effects.  The propensity score is the probability of a record to have a particular feature value given a set of observed other features. Propensity scores are used to reduce confounding variables’ effects and the implied bias. The latter models are used for estimating the heterogeneity of the treatment effect [31] To develop the heterogeneity model, we used forest-based algorithms.


Q1:Which RF, gradient boosted trees are capable of accurately predicting high-variance continuous variables in the healthcare domain?
Text: Recent studies have shown that RF, gradient boosted trees (GBT)  and deep neural networks (DNNs) are capable of accurately predicting both binary and high-variance continuous variables in the healthcare domain. For training and testing our model, we split the surgery dataset (SD)  70% for training and 30% for testing. We measured the performance metrics for the whole training set and for each of its sub-sets, partitioned by surgery type.


Q1:How are the regression metrics calculated?
Text: To evaluate our model’s performance, we used the regression metrics Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) The metrics are computed as follow: yi is the predicted duration of surgery (DOS) value of record i, ti is the true value of DOS, and n is the number of records. To evaluate the grid search output, We used K-fold cross-validation, a commonly used method to fully and effectively utilize data.


Q1:Where were the Causal analysis Models used?
Text: Causal analysis models we used were trained on the surgery dataset (SD)  The inputs to these models are a vector of the counterfactual features X and a vector for the model’s target feature Y. The hyperparameter values we used to optimize the heterogeneity treatment effect (HTE) and propensity models are listed in Table 3. Table 4 presents the 10 features whose absolute average treatment effect (ATE) values were the highest, in decreasing order. Half of the top 10 causal features are among the Novel column (novel) features shown in Table 1. The LassoCV algorithm is an iterative algorithm that finds the optimal parameters for a Lasso model using cross-validation.


Q1:Which model is the best?
Text: We trained the duration of surgery (DOS) models on the dataset using several machine learning (ML) algorithms. The algorithms that generated the top performing models–GBT being the best–are presented in Table 6. The mean absolute error (MAE) values in the table suggest that the performance is similar across the three algorithms, with gradient boosted trees (GBT) performing a bit better. We have calculated the model’s uncertainty as follows: For each record in the test set, we used the DOSM to predict a list of probabilities from each tree in the GBT. The derived uncertainty of the model was 4.1 minutes.


Q1:When was this model created?
Text: Barket-FM-DOSM is a duration of surgery (DOS) model using the features and the methods used in Barket et al. (2019) but trained on our surgery dataset (SD)  The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. This comparison led to the conclusion that neither the machine learning (ML) algorithms nor the dataset are the source of differences in the models performance. The major effector of such differences is the set of features.


Q1:The Shapley Additive exPlanations algorithm computed what?
Text: Feature importance was computed using the Shapley Additive exPlanations (SHAP) algorithm. Half of the 10 most influential features are among the Novel column (novel) features presented in Table 1 in Section 2. The 8 features with the highest absolute Pearson correlation values vis-à-vis duration of surgery (DOS) are presented in decreasing order of correlation values. We observe that 3 out of 8 (37.5%) of the features selected are the same for both methods, SHAP and Pearson correlation. The higher the vertical location of a dot indicates its feature’s value effect on DOS, i.e.e., the impact on the model's output.


Q1:Who used ML techniques to develop supervised ML models that predict the duration of surgery?
Text: We used machine learning (ML) techniques to develop supervised ML models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries. For training the models, we built a dataset of 23,293 records, collected and processed in collaboration with one of the biggest public hospitals in Israel. The performance of our DOS model in terms of mean absolute error (MAE) was 14.9 minutes. The average treatment effect (ATE) value of the 10 most influential features by Shapley Additive exPlanations (SHAP) that derived the model with the best performance was the gradient boosted trees (GBT)  The model outperformed earlier models.  Using the DOS value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using the identified causal relationship, OR management teams can apply measures to affect DOS. Future research could study additional surgery types at different hospitals to broaden applicability of our results. Further research is needed to quantify potential cost-saving and OR utilization when using the DOSM.

