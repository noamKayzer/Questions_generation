(0) RQUGE:5.0914
Q1:Which method was used to train multilayer networks?Stochastic gradient descent
Q2:What is the name of the simple method that can be used to train multilayer networks?
Best ans: stochastic gradient descent
['A0: stochastic gradient descent', 'A1: stochastic gradient descent is a method used to train multilayer networks', 'A2: Stochastic gradient descent', 'A3: Simple stochastic gradient descent', 'A4: random', 'A5: backpropagation procedure', 'A6: random distribution', 'A7: backpropagation']
Text: Multilayer networks can be trained by simple stochastic gradient descent. As long as the modules are relatively smooth functions of their inputs and of their internal weights, one can compute gradients using the backpropagation procedure. The idea that this could be done, and that it worked, was discovered independently by several different groups during the 1970s and 1980s. Many applications of deep learning use feedforward neural network architecture (Fig. 1), which learn to maps (map) a fixed-size input (for example, an image) to a fixed size output.  In the late 1990s, neural nets and backpropagation were largely forsaken by the machine-learning community and ignored by the computer-vision and speech-recognition communities. Recent theoretical and empirical results strongly suggest that local minima are not a serious issue in general in general. The hidden layers can be seen as distorting the input in a non-linear way so that categories become linearly separable by the last layer (Fig. 1), such as hidden layers.  Interest in deep feedforward networks was revived around 2006 (refs 31–34) by a group of researchers brought together by the Canadian Institute for Advanced Research (CIFAR) The analysis seems to show that saddle points with only a few downward curving directions are present in very large numbers. Almost all of these saddle points have very similar values of the objective function. Hence, it does not much matter which of the saddle points the algorithm gets stuck at. Information flows bottom up with lower-level features acting as oriented edge detectors, and a score is computed for each image class in output.  In 2009, the approach was used to map short temporal windows of coefficients extracted from a sound wave to a set of probabilities for the various fragments of speech that might be represented by the frame in the centre of the window. It achieved record-breaking results on a standard speech recognition benchmark that used a small vocabulary. By 2012, versions of the deep net from 2009 were being developed by many of the major speech groups and were already being deployed in Android phones. For smaller data sets, unsupervised pre-training helps to prevent overfitting40, leading to significantly better generalization.  Convolutional neural network (ConvNet) achieved many successes during the period when neural networks were out of favour. It has recently been widely adopted by the computervision community.



(1) RQUGE:5.0135
Q1:How does deep learning differ from conventional machine learning?
Q2:What is the key aspect of deep learning?
Best ans: These layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure.
['A0: These layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure.', 'A1: It has turned out to be very good at discovering intricate structures in high dimensional data and is therefore applicable to many domains of science, business and government', 'A2: This is a list of applications of deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years.', 'A3: The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure.', 'A4: they are learned from data using a general-purpose learning procedure.', 'A5: requires very little engineering by hand', 'A6: layers of features are not designed by human engineers', 'A7: they are learned from data using a general-purpose learning procedure']
Text: Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition. system required careful engineering and considerable domain expertise to design a feature extractor.  Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data.  New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.



(2) RQUGE:5.0128
Q1:LSTM and memory networks are used for what tasks?
Q2:Memory networks have yielded excellent performance on what standard benchmarks?
Best ans: question answering benchmarks
['A0: question answering benchmarks', 'A1: Question-answering', 'A2: speech recognition', 'A3: speech recognition machine translation', 'A4: speech recognition systems', 'A5: question-answering benchmarks', 'A6: machine translation', 'A7: question-answering']
Text: For tasks that involve sequential inputs, such as speech and language, it is often better to use recurrent neural networks (RNNs)  Backpropagation was first introduced to train RNNs But training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78. When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns.  This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art. This raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules. It is more compatible with the view that everyday reasoning involves many simultaneous analogies of word representations learned for modelling language, non-linearly projected to 2D for visualization using the t-SNE algorithm103. Instead of translating meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image.  The encoder is a deep ConvNet that converts pixels into an activity vector in its last hidden layer. The decoder is an recurrent neural network (RNN) similar to the ones used for machine translation and neural language modelling. long short-term memory (LSTM) networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step87, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription.  LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the RNN can choose to read from or write to88, and memory networks. Memory networks have yielded excellent performance on standard question-answering benchmarks.



(3) RQUGE:5.0127
Q1:Which of these is a type of neural network?
Q2:What does RNN stand for?
Best ans: Recurrent neural networks
['A0: ConvNets', 'A1: RNNs', 'A2: Reinforcement learning', 'A3: Recurrent neural networks', 'A4: reinforcement', 'A5: ConvNets', 'A6: deep learning', 'A7: Reinforcement learning']
Text: Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object. We expect much of the future progress in vision to come from systems that are trained end-toend and combine ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. Natural language understanding is another area in which deep learning is poised to make a large impact over the next few years. Ultimately, major progress in artificial intelligence will come about through systems that combine representation learning with complex reasoning.  A recurrent neural network can maps (map) an input sequence into an output sequence with elements ot, with each ot depending on all the previous xtʹ (for tʹ ≤ t) The same parameters (matrices U,V,W ) are used at each time step. The backpropagation algorithm (Fig. 1) can be directly applied to the computational graph of the unfolded network.



(5) RQUGE:4.9823
Q1:What is the main idea of this passage? ___
Q2:What is poised to make a large impact in artificial intelligence?
Best ans: Deep learning is poised to make a large impact in artificial intelligence.
['A0: In the past, deep learning has been used to train systems for a variety of tasks.', 'A1: Learning to recognize and understand the structure of the world is a fundamental part of the human condition.', 'A2: Recurrent neural networks are a powerful tool for understanding the structure of the world.', 'A3: Deep learning is poised to make a large impact in artificial intelligence.', 'A4: Learning to Unfold', 'A5: deep neural networks', 'A6: A recurrent neural network', 'A7: Artificial intelligence']
Text: Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object. We expect much of the future progress in vision to come from systems that are trained end-toend and combine ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. Natural language understanding is another area in which deep learning is poised to make a large impact over the next few years. Ultimately, major progress in artificial intelligence will come about through systems that combine representation learning with complex reasoning.  A recurrent neural network can maps (map) an input sequence into an output sequence with elements ot, with each ot depending on all the previous xtʹ (for tʹ ≤ t) The same parameters (matrices U,V,W ) are used at each time step. The backpropagation algorithm (Fig. 1) can be directly applied to the computational graph of the unfolded network.



(7) RQUGE:4.8814
Q1:Deep learning is a type of what? ________.
Q2:What are used to identify objects in images?
Best ans: machine learning techniques
['A0: AI', 'A1: artificial intelligence', 'A2: artificial intelligence system', 'A3: machine learning techniques', 'A4: algorithms', 'A5: algorithm', 'A6: computer science', 'A7: neural networks']
Text: Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition. system required careful engineering and considerable domain expertise to design a feature extractor.  Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data.  New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.



(8) RQUGE:4.8669
Q1:How many layers of ReLUs are in a ConvNet architecture? 67.
Q2:How many layers of ReLUs are in a ConvNet architecture?
Best ans: 10 to 20 layers of ReLUs are in a ConvNet architectures.
['A0: The number of rectified linear unit (ReLU) layers in a ConvNet architecture is 10 to 20 layers.', 'A1: 10 to 20 layers of ReLUs are in a ConvNet architectures.', 'A2: Recently, ConvNet architectures have 10 to 20 layers of ReLUs.', 'A3: ConvNet architectures have 10 to 20 layers of ReLUs.', 'A4: Recently', 'A5: recent', 'A6: 67', 'A7: 20']
Text: ConvNets have been applied with great success to the detection, segmentation and recognition of objects and regions in images since the early 2000s. A major recent practical success of face recognition is face recognition. Importantly, images can be labelled at the pixel level, which will have applications in technology, including autonomous mobile robots and self-driving cars. Companies such as Mobileye and NVIDIA are using ConvNet-based methods in their upcoming vision-   tems for cars. Other applications gaining importance involve natural language understanding14 and speech recognition7.  Recent ConvNet architectures have 10 to 20 layers of ReLUs, hundreds of millions of weights, and billions of connections between units. ConvNets are easily amenable to efficient hardware implementations in chips or field-programmable gate arrays66,67. A number of companies such as NVIDIA, Mobileye, Intel, Qualcomm and Samsung are developing ConvNet chips to enable real-time vision applications in smartphones, cameras, robots and self-driving cars.



(9) RQUGE:4.8303
Q1:Which of these networks is used for tasks that involve sequential inputs?
Q2:What is the decoder?
Best ans: Recurrent neural network (RNN)
['A0: RNNs', 'A1: Recurrent neural network (RNN)', 'A2: Long short-term memory (LSTM) networks', 'A3:  long short-term memory (LSTM)networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76.', 'A4: ConvNet', 'A5: decoder', 'A6: RNNs', 'A7: long short-term memory']
Text: For tasks that involve sequential inputs, such as speech and language, it is often better to use recurrent neural networks (RNNs)  Backpropagation was first introduced to train RNNs But training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78. When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns.  This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art. This raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules. It is more compatible with the view that everyday reasoning involves many simultaneous analogies of word representations learned for modelling language, non-linearly projected to 2D for visualization using the t-SNE algorithm103. Instead of translating meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image.  The encoder is a deep ConvNet that converts pixels into an activity vector in its last hidden layer. The decoder is an recurrent neural network (RNN) similar to the ones used for machine translation and neural language modelling. long short-term memory (LSTM) networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step87, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription.  LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the RNN can choose to read from or write to88, and memory networks. Memory networks have yielded excellent performance on standard question-answering benchmarks.



(11) RQUGE:4.7824
Q1:When was ConvNets first used to detect, segmentation and recognition of objects in images?
Q2:Since when have ConvNets been used?
Best ans: since 2000s ConvNets have been applied with great success to the detection of objects and regions in images. So, the final answer is the early 2000s.
['A0: since 2000s ConvNets have been applied with great success to the detection of objects and regions in images.', 'A1: since 2000s ConvNets have been applied with great success to the detection of objects and regions in images. So, the final answer is the early 2000s.', "A2: ConvNets have been applied with great success to the detection, segmentation and recognition of objects and regions in images since the early 2000s. So, the final answer is the early '00s..", "A3: ConvNets have been applied with great success to the detection, segmentation and recognition of objects and regions in images since the early 2000s. So, the final answer is the early '00s.", 'A4: 2000s.', 'A5: in', 'A6: 2002', 'A7: 2000s']
Text: ConvNets have been applied with great success to the detection, segmentation and recognition of objects and regions in images since the early 2000s. A major recent practical success of face recognition is face recognition. Importantly, images can be labelled at the pixel level, which will have applications in technology, including autonomous mobile robots and self-driving cars. Companies such as Mobileye and NVIDIA are using ConvNet-based methods in their upcoming vision-   tems for cars. Other applications gaining importance involve natural language understanding14 and speech recognition7.  Recent ConvNet architectures have 10 to 20 layers of ReLUs, hundreds of millions of weights, and billions of connections between units. ConvNets are easily amenable to efficient hardware implementations in chips or field-programmable gate arrays66,67. A number of companies such as NVIDIA, Mobileye, Intel, Qualcomm and Samsung are developing ConvNet chips to enable real-time vision applications in smartphones, cameras, robots and self-driving cars.



(12) RQUGE:4.73
Q1:What are the advantages of deep learning over classic learning algorithms? What are they?
Q2:What are the word vectors in a language model composed of?
Best ans: These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network
['A0: Learning to represent the networks input word vector in a way makes it easy to predict the target outputs.', 'A1: These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network71.', 'A2: These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network', 'A3: In a language model, the other layers of the network learn to convert the input word vectors into an output word vector for the predicted next word. These word vector are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network.', 'A4: both', 'A5: use distributed representations21', 'A6: distributed representations21', 'A7: power of composition']
Text: Deep-learning theory shows that deep nets have two different exponential advantages over classic learning algorithms that do not use distributed representations21. Both of these advantages arise from the power of composition and depend on the underlying data-generating distribution having an appropriate componential structure40. The hidden layers of a multilayer neural network learn to represent the network’s inputs in a way that makes it easy to predict the target outputs. Figure 3 | From image to text. Captions generated by a recurrent neural network taking, as extra input, the representation extracted by a deep convolution neural network from a test image.  Each word in the context is presented to the network as a one-of-N vector, that is, one component has a value of 1 and the rest are 0. The network learns word vectors that contain many active components each of which can be interpreted as a separate feature of the word. In a language model, the other layers of the network learn to convert the input word vectors into an output word vector for the predicted next word. These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network.  In the logic-inspired paradigm, an instance of a symbol is something for which the only property is that it is either identical or non-identical to other symbols. By contrast, neural networks just use big activity vectors, big weight matrices and scalar non-linearities to perform the type of fast ‘intuitive’ inference that underpins effortless commonsense reasoning. Before the introduction of neural language models71, the standard approach to statistical modelling of language did not exploit distributed representations.



(13) RQUGE:4.5118
Q1:Which of these is used to adjust the weight vector of a deep learning system?
Q2:What is a gradient vector?
Best ans: A gradient vector is used to adjust the weight vector of a deep-learning system. The learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.
['A0: A gradient vector is used to adjust the weight vector of a deep-learning system.', 'A1: To properly adjust the weight vector of a deep learning system, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A2: A gradient vector is used to adjust the weight vector of a deep-learning system. The learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A3: Learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A4: average gradient', 'A5: an error derivative', 'A6: stochastic gradient descent', 'A7: gradient vector']
Text: Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.  Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. In practice, most practitioners use a procedure called stochastic gradient descent (SGD) This consists of showing the input vector for a few examples, computing the outputs and the errors, and computing the average gradient for those examples, and adjusting the weights accordingly. The negative gradient vector indicates the direction of steepest descent in this landscape, taking it closer to a minimum, where the output error is low on average.  Since the 1960s we have known that linear classifiers can only carve their input space into very simple regions, namely half-spaces separated by a hyperplane19. Problems such as image and speech recognition require the input–output function to be insensitive to irrelevant variations of the input, such as variations in position, orientation or illumination of an object, or variations in the pitch or accent of speech. At the pixel level, images of two Samoyeds in different poses and in different environments may be very different from each other, whereas two images of a Samoyed and a wolf in the same position and on similar backgrounds may be similar to each other.  The chain rule of derivatives tells us how two small effects (that of a small change of x on y on y, and that of y on z) are composed. Substituting one equation into the other gives the chain rule. It also works when x, y and z are vectors (and the derivatives are Jacobian matrices) For simplicity, we have omitted bias terms. At each layer, we first compute the total input z to each unit, which is a weighted sum of the output of the units in the layer below. Then a non-linear function f(.) is applied to z to get the output.  Non-linear functions used in neural networks include the rectified linear unit (ReLU) f(z) = max(0,z), commonly used in recent years. At each hidden layer we compute the error derivative with respect to the output of each unit. The error-derivative for the weight wjk on the connection from unit j in the layer below is just yj ∂E/∂zk. raw pixels could not possibly distinguish the latter two.  Deep-learning architecture is a multilayer stack of simple modules, all (or most) of which are subject to learning. Each module (module) in the stack transforms its input to increase both the selectivity and the invariance of the representation. With multiple non-linear layers, say a depth of 5 to 20, a system can implement extremely intricate functions of its inputs that are simultaneously sensitive to minute details — distinguishing Samoyeds from white wolves — and insensitive to large irrelevant variations.



(14) RQUGE:4.3938
Q1:What is the chain rule of derivatives? What is it used for? What are the examples of this rule?
Q2:How many adjustable weights are there in a deep learning system?
Best ans: To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights
['A0: A deep learning system uses a weighted sum of the output of the units in the layer below to compute the error derivative. Substituting one equation into the other gives the chain rule. It also works when x,y and z are vectors (and the derivatives are Jacobianmatrices)', 'A1: In a typical deep-learning system, there may be hundreds of millions of these adjustable weights. To properly adjust the weight vector, the learning algorithm computes the average gradient for those examples, computing the outputs and the errors, and computing the average deviation for those samples, and adjusting the weights accordingly.', 'A2: To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights', 'A3: To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A4: distinguishing Samoyeds from white wolves', 'A5: distinguishing Samoyeds from white wolves and insensitive to large irrelevant variations', 'A6: subtitling one equation into the other gives the chain rule. It also works when', 'A7: subtitling one equation into the other gives the chain rule']
Text: Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.  Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. In practice, most practitioners use a procedure called stochastic gradient descent (SGD) This consists of showing the input vector for a few examples, computing the outputs and the errors, and computing the average gradient for those examples, and adjusting the weights accordingly. The negative gradient vector indicates the direction of steepest descent in this landscape, taking it closer to a minimum, where the output error is low on average.  Since the 1960s we have known that linear classifiers can only carve their input space into very simple regions, namely half-spaces separated by a hyperplane19. Problems such as image and speech recognition require the input–output function to be insensitive to irrelevant variations of the input, such as variations in position, orientation or illumination of an object, or variations in the pitch or accent of speech. At the pixel level, images of two Samoyeds in different poses and in different environments may be very different from each other, whereas two images of a Samoyed and a wolf in the same position and on similar backgrounds may be similar to each other.  The chain rule of derivatives tells us how two small effects (that of a small change of x on y on y, and that of y on z) are composed. Substituting one equation into the other gives the chain rule. It also works when x, y and z are vectors (and the derivatives are Jacobian matrices) For simplicity, we have omitted bias terms. At each layer, we first compute the total input z to each unit, which is a weighted sum of the output of the units in the layer below. Then a non-linear function f(.) is applied to z to get the output.  Non-linear functions used in neural networks include the rectified linear unit (ReLU) f(z) = max(0,z), commonly used in recent years. At each hidden layer we compute the error derivative with respect to the output of each unit. The error-derivative for the weight wjk on the connection from unit j in the layer below is just yj ∂E/∂zk. raw pixels could not possibly distinguish the latter two.  Deep-learning architecture is a multilayer stack of simple modules, all (or most) of which are subject to learning. Each module (module) in the stack transforms its input to increase both the selectivity and the invariance of the representation. With multiple non-linear layers, say a depth of 5 to 20, a system can implement extremely intricate functions of its inputs that are simultaneously sensitive to minute details — distinguishing Samoyeds from white wolves — and insensitive to large irrelevant variations.



(15) RQUGE:4.3343
Q1:Why is backpropagation problematic? What is the solution?
Q2:Why has training RNNs been problematic?
Best ans: backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78
['A0:  long short-term memory (LSTM)networks have subsequently proved to be more effective than conventional recurrent neural networks (RNNs) especially when they have several layers for each time step87 enabling an entire speech recognition system that goes all of from acoustics', 'A1:  long short-term memory (LSTM)networks have subsequently proved to be more effective than conventional RNNs', 'A2:  long short-term memory (LSTM)networks have subsequently proved to be more effective than conventional recurrent neural networks (RNNs) especially when they have several layers for each time step87', 'A3: When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train recurrent neural networks (RNNs) ', 'A4: over many time steps they typically explode or vanish77,78', 'A5: backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78', 'A6: backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish', 'A7: over many time steps they typically explode or vanish']
Text: For tasks that involve sequential inputs, such as speech and language, it is often better to use recurrent neural networks (RNNs)  Backpropagation was first introduced to train RNNs But training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78. When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns.  This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art. This raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules. It is more compatible with the view that everyday reasoning involves many simultaneous analogies of word representations learned for modelling language, non-linearly projected to 2D for visualization using the t-SNE algorithm103. Instead of translating meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image.  The encoder is a deep ConvNet that converts pixels into an activity vector in its last hidden layer. The decoder is an recurrent neural network (RNN) similar to the ones used for machine translation and neural language modelling. long short-term memory (LSTM) networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step87, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription.  LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the RNN can choose to read from or write to88, and memory networks. Memory networks have yielded excellent performance on standard question-answering benchmarks.



(16) RQUGE:4.1413
Q1:Why are recurrent neural networks used in learning to recognize objects in images?
Q2:What can be applied to the computational graph of the unfolded network?
Best ans: The same parameters (matrices U,V,W) are used at each time step. The same parameter sets are used for each time point. The backpropagation algorithm can be directly applied.
['A0: The same parameters (matrices U,V,W) are used at each time step. The same parameter sets are used for each time point.', 'A1: The same parameters (matrices U,V,W) are used at each time step. The same parameter sets are used for each time point. The backpropagation algorithm can be directly applied.', 'A2: The same parameters (matrices U,V,W) are used at each time step. The same parameter sets are used for each time point. The backpropagation algorithm can be directly applied. The final answer: the computational graph of the unfolded network.', 'A3: The same parameters (matrices U,V,W) are used at each time step.', 'A4: to decide where to look', 'A5: the same parameters', 'A6: use reinforcement learning to decide where to look.', 'A7: human and animal learning is largely unsupervised']
Text: Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object. We expect much of the future progress in vision to come from systems that are trained end-toend and combine ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. Natural language understanding is another area in which deep learning is poised to make a large impact over the next few years. Ultimately, major progress in artificial intelligence will come about through systems that combine representation learning with complex reasoning.  A recurrent neural network can maps (map) an input sequence into an output sequence with elements ot, with each ot depending on all the previous xtʹ (for tʹ ≤ t) The same parameters (matrices U,V,W ) are used at each time step. The backpropagation algorithm (Fig. 1) can be directly applied to the computational graph of the unfolded network.



(23) RQUGE:3.4072
Q1:A machine learning system is an artificial intelligence system that can do what?
Q2:What are some of the applications of machine learning?
Best ans: Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items with users’ interests, and select relevant results of search. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years.
['A0: Use deep neural networks to learn from data. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years.', 'A1: To identify things, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years.', 'A2: Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items with users’ interests, and select relevant results of search. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years.', 'A3: The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure.', 'A4: detect patterns', 'A5: recognize intricate structures', 'A6: find relevant results of search', 'A7: transcribe speech into text']
Text: Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users’ interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition. system required careful engineering and considerable domain expertise to design a feature extractor.  Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data.  New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.



(24) RQUGE:3.1207
Q1:How do we learn the weights of a deep learning system?
Q2:What does SGD do?
Best ans: Stochastic gradient descent (SGD) is a method for learning the weights of a deep learning system. To properly adjust a weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.
['A0: Stochastic gradient descent (SGD) is a method for learning the weights of a deep learning system. To properly adjust a weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A1: The learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A2: A deep learning system uses multiple layers of data to learn representations that are composed of multiple levels of abstraction. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A3: In a typical deep-learning system, there may be hundreds of millions of these adjustable weights. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.', 'A4: algorithm computes', 'A5: SGD', 'A6: to adjust the weight vector', 'A7: SGD']
Text: Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. In a typical deep-learning system, there may be hundreds of millions of these adjustable weights. To properly adjust the weight vector, the learning algorithm computes a gradient vector that, for each weight, indicates by what amount the error would increase or decrease if the weight were increased by a tiny amount.  Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. In practice, most practitioners use a procedure called stochastic gradient descent (SGD) This consists of showing the input vector for a few examples, computing the outputs and the errors, and computing the average gradient for those examples, and adjusting the weights accordingly. The negative gradient vector indicates the direction of steepest descent in this landscape, taking it closer to a minimum, where the output error is low on average.  Since the 1960s we have known that linear classifiers can only carve their input space into very simple regions, namely half-spaces separated by a hyperplane19. Problems such as image and speech recognition require the input–output function to be insensitive to irrelevant variations of the input, such as variations in position, orientation or illumination of an object, or variations in the pitch or accent of speech. At the pixel level, images of two Samoyeds in different poses and in different environments may be very different from each other, whereas two images of a Samoyed and a wolf in the same position and on similar backgrounds may be similar to each other.  The chain rule of derivatives tells us how two small effects (that of a small change of x on y on y, and that of y on z) are composed. Substituting one equation into the other gives the chain rule. It also works when x, y and z are vectors (and the derivatives are Jacobian matrices) For simplicity, we have omitted bias terms. At each layer, we first compute the total input z to each unit, which is a weighted sum of the output of the units in the layer below. Then a non-linear function f(.) is applied to z to get the output.  Non-linear functions used in neural networks include the rectified linear unit (ReLU) f(z) = max(0,z), commonly used in recent years. At each hidden layer we compute the error derivative with respect to the output of each unit. The error-derivative for the weight wjk on the connection from unit j in the layer below is just yj ∂E/∂zk. raw pixels could not possibly distinguish the latter two.  Deep-learning architecture is a multilayer stack of simple modules, all (or most) of which are subject to learning. Each module (module) in the stack transforms its input to increase both the selectivity and the invariance of the representation. With multiple non-linear layers, say a depth of 5 to 20, a system can implement extremely intricate functions of its inputs that are simultaneously sensitive to minute details — distinguishing Samoyeds from white wolves — and insensitive to large irrelevant variations.



(26) RQUGE:2.1613
Q1:Do neural networks have two different exponential advantages? What are these advantages?
Q2:What do neural networks use that underpins effortless commonsense reasoning?
Best ans: No. Neural networks do not use distributed representations. Neighboring data-generating distributions do not have an appropriate componential structure. Neons just use big activity vectors, big weight matrices and scalar non-linearities to perform the type of fast ‘intuitive’
['A0: No. Neural networks do not use distributed representations.', 'A1: No. Neural networks do not use distributed representations. Neighboring data-generating distributions do not have an appropriate componential structure.', 'A2: No. Neural networks do not use distributed representations. Neighboring data-generating distributions do not have an appropriate componential structure. Neons just use big activity vectors, big weight matrices and scalar non-linearities to perform the type of fast ‘intuitive’', 'A3: Neural networks have two different exponential advantages over classic learning algorithms that do not use distributed representation21. Both of these advantages arise from the power of composition and depend on underlying data-generating distribution having an appropriate componential structure40.', 'A4: power', 'A5: Both', 'A6: Yes', 'A7: yes']
Text: Deep-learning theory shows that deep nets have two different exponential advantages over classic learning algorithms that do not use distributed representations21. Both of these advantages arise from the power of composition and depend on the underlying data-generating distribution having an appropriate componential structure40. The hidden layers of a multilayer neural network learn to represent the network’s inputs in a way that makes it easy to predict the target outputs. Figure 3 | From image to text. Captions generated by a recurrent neural network taking, as extra input, the representation extracted by a deep convolution neural network from a test image.  Each word in the context is presented to the network as a one-of-N vector, that is, one component has a value of 1 and the rest are 0. The network learns word vectors that contain many active components each of which can be interpreted as a separate feature of the word. In a language model, the other layers of the network learn to convert the input word vectors into an output word vector for the predicted next word. These word vectors are composed of learned features that were not determined ahead of time by experts, but automatically discovered by the neural network.  In the logic-inspired paradigm, an instance of a symbol is something for which the only property is that it is either identical or non-identical to other symbols. By contrast, neural networks just use big activity vectors, big weight matrices and scalar non-linearities to perform the type of fast ‘intuitive’ inference that underpins effortless commonsense reasoning. Before the introduction of neural language models71, the standard approach to statistical modelling of language did not exploit distributed representations.



(29) RQUGE:1.6785
Q1:How do we learn the structure of the world by observing it?
Q2:What does Reinforcement Learning combine?
Best ans: Reinforcement Learning combines ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. The same parameters (matrices U,V,W) are used at each time step.
['A0: Reinforcement Learning combines ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look.', 'A1: The same parameters (matrices U,V,W) are used at each time step. The same algorithms (backpropagation algorithm) are applied to the computational graph of the unfolded network.', 'A2: Reinforcement Learning combines ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. The same parameters (matrices U,V,W) are used at each time step.', 'A3: Recurrent neural networks (RNNs) are a type of machine learning system that use reinforcement learning to decide where to look. Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object.', 'A4: backpropagation algorithm', 'A5: Reinforcement learning', 'A6: reinforcement learning', 'A7: reinforcement learning to decide where to look']
Text: Human and animal learning is largely unsupervised: we discover the structure of the world by observing it, not by being told the name of every object. We expect much of the future progress in vision to come from systems that are trained end-toend and combine ConvNets with recurrent neural networks (RNNs) that use reinforcement learning to decide where to look. Natural language understanding is another area in which deep learning is poised to make a large impact over the next few years. Ultimately, major progress in artificial intelligence will come about through systems that combine representation learning with complex reasoning.  A recurrent neural network can maps (map) an input sequence into an output sequence with elements ot, with each ot depending on all the previous xtʹ (for tʹ ≤ t) The same parameters (matrices U,V,W ) are used at each time step. The backpropagation algorithm (Fig. 1) can be directly applied to the computational graph of the unfolded network.



(31) RQUGE:1.49
Q1:How can we train recurrent neural networks?
Q2:What are some proposals for LSTM networks?
Best ans:  long short-term memory (LSTM)networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the recurrent neural network (RNN) can choose to read from or write to88, and memory networks
['A0: Assuming that the output of the hidden units at different discrete time steps is output of various neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train RNNs', 'A1:  long short-term memory (LSTM)networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the recurrent neural network (RNN) can choose to read from or write to88, and memory networks.', 'A2:  long short-term memory (LSTM)networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the recurrent neural network (RNN) can choose to read from or write to88, and memory networks', 'A3: When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns long short-term memory (LSTM) networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,7276', 'A4: using t-SNE algorithm103', 'A5:  long short-term memory (LSTM)networks', 'A6: backPropagation', 'A7: deep multilayer network']
Text: For tasks that involve sequential inputs, such as speech and language, it is often better to use recurrent neural networks (RNNs)  Backpropagation was first introduced to train RNNs But training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78. When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns.  This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art. This raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules. It is more compatible with the view that everyday reasoning involves many simultaneous analogies of word representations learned for modelling language, non-linearly projected to 2D for visualization using the t-SNE algorithm103. Instead of translating meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image.  The encoder is a deep ConvNet that converts pixels into an activity vector in its last hidden layer. The decoder is an recurrent neural network (RNN) similar to the ones used for machine translation and neural language modelling. long short-term memory (LSTM) networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step87, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription.  LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the RNN can choose to read from or write to88, and memory networks. Memory networks have yielded excellent performance on standard question-answering benchmarks.



(32) RQUGE:1.3045
Q1:Who first introduced backpropagation to train neural networks for machine translation?
Q2:Who is the main focus of this study?
Best ans: researchers
['A0: Recurrent neural networks (RNNs) were first introduced to train recurrent neural networks (RNNs)  Backpropagation was first introduced for machine translation tasks.', 'A1: Recurrent neural networks (RNNs) were first introduced to train recurrent neural networks (RNNs) ', 'A2:  long short-term memory (LSTM)Networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76', 'A3: Backpropagation was first introduced to train recurrent neural networks (RNNs) ', 'A4: S', 'A5: ConvNet', 'A6: researchers', 'A7: RNNs']
Text: For tasks that involve sequential inputs, such as speech and language, it is often better to use recurrent neural networks (RNNs)  Backpropagation was first introduced to train RNNs But training them has proved to be problematic because the backpropagated gradients either grow or shrink at each time step, so over many time steps they typically explode or vanish77,78. When we consider the output of the hidden units at different discrete time steps as if they were the outputs of different neurons in a deep multilayer network, it becomes clear how we can apply backPropagation to train Rnns.  This rather naive way of performing machine translation has quickly become competitive with the state-of-the-art. This raises serious doubts about whether understanding a sentence requires anything like the internal symbolic expressions that are manipulated by using inference rules. It is more compatible with the view that everyday reasoning involves many simultaneous analogies of word representations learned for modelling language, non-linearly projected to 2D for visualization using the t-SNE algorithm103. Instead of translating meaning of a French sentence into an English sentence, one can learn to ‘translate’ the meaning of an image.  The encoder is a deep ConvNet that converts pixels into an activity vector in its last hidden layer. The decoder is an recurrent neural network (RNN) similar to the ones used for machine translation and neural language modelling. long short-term memory (LSTM) networks have subsequently proved to be more effective than conventional RNNs, especially when they have several layers for each time step87, enabling an entire speech recognition system that goes all the way from acoustics to the sequence of characters in the transcription.  LSTM networks or related forms of gated units are also currently used for the encoder and decoder networks that perform so well at machine translation17,72,76. Proposals include the Neural Turing Machine in which the network is augmented by a ‘tape-like’ memory that the RNN can choose to read from or write to88, and memory networks. Memory networks have yielded excellent performance on standard question-answering benchmarks.



