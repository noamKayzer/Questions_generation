RQUGE:5.0593
 Q1:The dataset used for the experiments is what one?
Q2:What dataset were the causal analysis models trained on?
Best ans: surgery data set
['A0: surgery data', 'A1: surgery data set dataset', 'A2: the Surgery Dataset', 'A3: surgery data set', 'A4: surgical', 'A5: Surgery', 'A6: Surgery data', 'A7: SD']Text: Causal analysis models we used were trained on the surgery dataset (SD)  The inputs to these models are a vector of the counterfactual features X and a vector for the model’s target feature Y. The hyperparameter values we used to optimize the heterogeneity treatment effect (HTE) and propensity models are listed in Table 3. Table 4 presents the 10 features whose absolute average treatment effect (ATE) values were the highest, in decreasing order. Half of the top 10 causal features are among the Novel column (novel) features shown in Table 1. The LassoCV algorithm is an iterative algorithm that finds the optimal parameters for a Lasso model using cross-validation.



RQUGE:4.8398
 Q1:In which column are novel features presented?
Q2:Half of the 10 most influential features are among what type of features?
Best ans:  Novel column (novel)
['A0: New Column', 'A1: New Column Novel column', 'A2: In Table 1, Novel column (novel) features are presented.', 'A3: Table 1 in Section 2 presents the Novel column (novel) features.', 'A4:  Novel column (novel)', 'A5: Notebook', 'A6: novel', 'A7: Table 1']Text: Feature importance was computed using the Shapley Additive exPlanations (SHAP) algorithm. Half of the 10 most influential features are among the Novel column (novel) features presented in Table 1 in Section 2. The 8 features with the highest absolute Pearson correlation values vis-à-vis duration of surgery (DOS) are presented in decreasing order of correlation values. We observe that 3 out of 8 (37.5%) of the features selected are the same for both methods, SHAP and Pearson correlation. The higher the vertical location of a dot indicates its feature’s value effect on DOS, i.e.e., the impact on the model's output.



RQUGE:4.5304
 Q1:Does Barket-FM-DOSM have better performance than Barket?
Q2:is the dataset the source of differences in the models performance
Best ans: A duration of surgery model is trained on the surgery dataset (SD) dataset. The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. The major effector of such differences is the set of features. So, the final answer is yes...
['A0: A duration of surgery model is trained on the surgery dataset (SD) dataset. The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. The major effector of such differences is the set of features. So, the final answer is yes...', 'A1: A duration of surgery model is trained on the surgery dataset (SD) dataset. The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. The major effector of such differences is the set of features. So, the final answer is yes..', 'A2: In 2019, Barket et al. (2019) trained a duration of surgery model on their surgery dataset (SD)  The mean absolute error (MAE) value of their model is lower than the MAE values derived for Barket. The major effector of such differences is the set of features in their model.', 'A3: A duration of surgery model is trained on the surgery dataset (SD) dataset. The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. The major effector of such differences is the set of features.', 'A4: yes.', 'A5: No', 'A6: no', 'A7: yes']Text: Barket-FM-DOSM is a duration of surgery (DOS) model using the features and the methods used in Barket et al. (2019) but trained on our surgery dataset (SD)  The mean absolute error (MAE) value of our model–DOSM–is lower than the MAE values derived for Barket. This comparison led to the conclusion that neither the machine learning (ML) algorithms nor the dataset are the source of differences in the models performance. The major effector of such differences is the set of features.



RQUGE:4.4688
 Q1:Do they use propensity and heterogeneity models to estimate treatment effect?
Q2:is the average treatment effect of a feature a measure of the difference in the mean of
Best ans: The propensity score is the probability of a record to have a particular feature value given a set of observed other features. The latter models are used for estimating the heterogeneity of the treatment effect. So, the final answer is yes.....
['A0: Both the propensity and heterogeneity models are used for the estimation of causal effects.', 'A1: The propensity score is the probability of a record to have a particular feature value given a set of observed other features. The latter models are used for estimating the heterogeneity of the treatment effect. So, the final answer is yes.....', 'A2: The propensity score is the probability of a record to have a particular feature value given a set of observed other features. The latter models are used for estimating the heterogeneity of the treatment effect. So, the final answer is yes...', 'A3: The propensity score is the probability of a record to have a particular feature value given a set of observed other features. The latter models are used for estimating the heterogeneity of the treatment effect. So, the final answer is yes..', 'A4: yes.', 'A5: No', 'A6: no', 'A7: Yes']Text: The average treatment effect (ATE) of a feature (whose value range is binary) measures the difference in the mean of the outcomes between data records with different values assigned to the feature. Since our study is observational, the ATE values could not be computed accurately, as a feature in a surgery record only has an observed value and cannot be assigned other values [29] We use Eq (1) and its extensions to calculate ATE. Two main machine learning (ML) model types, propensity and heterogeneity models, are used for estimating causal effects.  The propensity score is the probability of a record to have a particular feature value given a set of observed other features. Propensity scores are used to reduce confounding variables’ effects and the implied bias. The latter models are used for estimating the heterogeneity of the treatment effect [31] To develop the heterogeneity model, we used forest-based algorithms.



RQUGE:4.2367
 Q1:What is the full list of features?
Q2:What is the full list of features?
Best ans: A complete set is shown in Table 1. The full list of features is shown below.
['A0: A complete set is shown in Table 1. The full list of features is shown below.', 'A1: A complete set is shown in Table 1. The full list of features is shown below. The data was obtained from the Tel Aviv Sourasky Medical Center’s (TASM) (a public hospital) surgery department. The full set of features are:', 'A2: Surgical records were obtained from the Tel Aviv Sourasky Medical Center’s (TASM) (a public hospital) surgery department. The full list of features is shown below:', 'A3: Data was obtained from the Tel Aviv Sourasky Medical Center’s surgery department. The data included 23,293 retrospective surgical records, focusing on the eight most common surgeries in this department between 2010 and 2020. The full list of feature names is shown in Table 1.', 'A4: Table 1 the full list of features', 'A5: Table 1 the full list of features is shown in Table 1', 'A6: the following features are shown in Table 1:', 'A7: The full list of features is shown in Table 1']Text: The data was obtained from the Tel Aviv Sourasky Medical Center’s (TASM) (a public hospital) surgery department. The data included 23,293 retrospective surgical records, focusing on the eight most common surgeries in this department between 2010 and 2020. The full list of features is shown in Table 1. The table shows feature names, indication of whether a feature is Novel column (novel) (by a V in the Novel column), the value range of each feature, and values’ statistics. For handling missing data of other features, we used the Sequence of Regression Models (SRM) technique.  The missing values of features were computed using the values of other features.



RQUGE:4.1793
 Q1:How are the metrics used to evaluate the grid search?
Q2:How are the regression metrics calculated?
Best ans: yi is the predicted duration of surgery (DOS) value of record, ti is true value of DOS and number of records. We used K-fold cross-validation to evaluate the grid search output. The metrics are computed as follows:
['A0: We used K-fold cross-validation to evaluate the grid search. The metrics are computed as follows: y, t, n = (y + t)/(n + y)/x. Then, we used the K-Fold method to evaluate our model’s performance.', 'A1: yi is the predicted duration of surgery (DOS) value of record, ti is true value of DOS and number of records. We used K-fold cross-validation to evaluate the grid search output. The metrics are computed as follows:', 'A2: yi is the predicted duration of surgery (DOS) value of record, ti is true value of DOS and number of records. We used K-fold cross-validation to evaluate the grid search output.', 'A3: To evaluate the grid search, We used K-fold cross-validation, a commonly used method to fully and effectively utilize data. The metrics are computed as follows: yi is the predicted duration of surgery (DOS) value of record i, ti is true value of DOS, and n is the number of records.', 'A4: K-fold cross-validation, a commonly used method to fully and effectively utilize data.', 'A5: The metrics are computed as follow:', 'A6: K-fold cross-validation', 'A7: K-fold cross-validation, a commonly used method to fully and effectively utilize data']Text: To evaluate our model’s performance, we used the regression metrics Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) The metrics are computed as follow: yi is the predicted duration of surgery (DOS) value of record i, ti is the true value of DOS, and n is the number of records. To evaluate the grid search output, We used K-fold cross-validation, a commonly used method to fully and effectively utilize data.



RQUGE:4.1703
 Q1:What is the purpose of this paper?
Q2:What did we use machine learning to do?
Best ans: Predicting the duration of surgery in a hospital
['A0: Predicting the duration of surgery', 'A1: Predicting the duration of surgery in a hospital', 'A2: Models to predict the duration of surgery in hospitals', 'A3: A model that can predict the duration of surgery', 'A4: Modeling the Duration of Surgery in Hospitals', 'A5: Modeling the Duration of Surgery', 'A6: A model to predict the duration of surgery', 'A7: to predict duration of surgery']Text: We used machine learning (ML) techniques to develop supervised ML models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries. For training the models, we built a dataset of 23,293 records, collected and processed in collaboration with one of the biggest public hospitals in Israel. The performance of our DOS model in terms of mean absolute error (MAE) was 14.9 minutes. The average treatment effect (ATE) value of the 10 most influential features by Shapley Additive exPlanations (SHAP) that derived the model with the best performance was the gradient boosted trees (GBT)  The model outperformed earlier models.  Using the DOS value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using the identified causal relationship, OR management teams can apply measures to affect DOS. Future research could study additional surgery types at different hospitals to broaden applicability of our results. Further research is needed to quantify potential cost-saving and OR utilization when using the DOSM.



RQUGE:4.1132
 Q1:Why did we split the surgery dataset (SD) 70% and 30% for training and testing?
Q2:How did we split the dataset?
Best ans: To train and test our model, we split the surgery dataset (SD) 70% for training, and 30% for testing.
['A0: This dataset is used for training and testing our model.', 'A1: This dataset is used for training and testing our model. The training set is split into 70 training sets and 30 training sets.', 'A2: For testing our model, we split the surgery dataset (SD) 70% for training and 30% for testing. The surgery dataset is a healthcare dataset.', 'A3: To train and test our model, we split the surgery dataset (SD) 70% for training, and 30% for testing.', 'A4: the surgery dataset (SD) 70% for training and 30% for testing', 'A5: for training and testing our model, we split the surgery dataset (SD) 70% for training', 'A6: to measure the performance metrics for the whole training set and each of its sub-sets', 'A7: training and testing our model']Text: Recent studies have shown that RF, gradient boosted trees (GBT)  and deep neural networks (DNNs) are capable of accurately predicting both binary and high-variance continuous variables in the healthcare domain. For training and testing our model, we split the surgery dataset (SD)  70% for training and 30% for testing. We measured the performance metrics for the whole training set and for each of its sub-sets, partitioned by surgery type.



RQUGE:4.0683
 Q1:How can we reduce waiting time and optimize surgical staff idle time?
Q2:What is the benefit of using the model for surgery scheduling?
Best ans: Using the duration of surgery (DOS) value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using this model for scheduling can reduce waiting time for patients and optimize surgical staff time.
['A0: Using the duration of surgery (DOS) value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using this model for scheduling can reduce waiting time for patients and optimize surgical staff time.', 'A1: Models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries.', 'A2: Using the duration of surgery (DOS) value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using this model for scheduling can reduce waiting time for patients and optimize surgical staff time. Further research is needed to quantify potential cost-saving and OR utilization when using the DOSM.', 'A3: The model predicts the duration of surgery (DOS) from features related to patients, physicians, and surgeries. Using the DOS value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time.', 'A4: Applying measures to affect duration of surgery (DOS) ', 'A5: Applying measures to affect DOS', 'A6: The model outperformed earlier models', 'A7: Use duration of surgery (DOS) value predicted by our model for surgery scheduling']Text: We used machine learning (ML) techniques to develop supervised ML models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries. For training the models, we built a dataset of 23,293 records, collected and processed in collaboration with one of the biggest public hospitals in Israel. The performance of our DOS model in terms of mean absolute error (MAE) was 14.9 minutes. The average treatment effect (ATE) value of the 10 most influential features by Shapley Additive exPlanations (SHAP) that derived the model with the best performance was the gradient boosted trees (GBT)  The model outperformed earlier models.  Using the DOS value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using the identified causal relationship, OR management teams can apply measures to affect DOS. Future research could study additional surgery types at different hospitals to broaden applicability of our results. Further research is needed to quantify potential cost-saving and OR utilization when using the DOSM.



RQUGE:3.7296
 Q1:What is the purpose and significance of this paper?
Q2:What does this paper present?
Best ans: This paper presents an accurate prediction of duration of surgery (DOS) using a Novel column (novel) feature set.
['A0: Identifying Influential and Causal Features Influencing Duration of Surgery.', 'A1: Identifying Influential and Causal Features Influencing Duration of Surgery', 'A2: This paper presents an accurate prediction of duration of surgery (DOS) using a Novel column (novel) feature set.', 'A3: To develop a supervised model for the duration of surgery.', 'A4: Predicting the duration of surgery using Novel column (novel) features and causality analysis', 'A5: A Novel column (novel) feature set and a novel model for estimating duration of surgery', 'A6: We present an accurate prediction model for duration of surgery.', 'A7: To develop a supervised model for the duration of surgery.']Text:Accurate estimation of duration of surgery (DOS) can lead to cost-effective utilization of surgical staff and operating rooms and decrease patients’ waiting time. In this study, we present a supervised DOS nonlinear regression prediction model whose accuracy outperforms earlier results. In addition, unlike previous studies, we identify the features that influence DOS prediction. Further, in difference from others, we study the causal relationship between the feature set and DOS. The feature sets used in prior studies included a subset of the features presented in this study. This study aimed to derive influential effectors of duration of surgery via optimized prediction and causality analysis. We implemented an array of machine learning algorithms and trained them on datasets comprising surgery-related data, to derive DOS prediction models. The datasets we acquired contain patient, surgical staff, and surgery features. The datasets comprised 23,293 surgery records of eight surgery types performed over a 10-year period in a public hospital. We have introduced new, unstudied features and combined them with features adopted from previous studies to generate a comprehensive feature set. We utilized feature importance methods to identify the influential features, and causal inference methods to identify the causal features. Our model demonstrates superior performance in comparison to DOS prediction models in the art. The performance of our DOS model in terms of the mean absolute error (MAE) was 14.9 minutes. The algorithm that derived the model with the best performance was the gradient boosted trees (GBT)  We identified the 10 most influential features and the 10 most causal features. In addition, we showed that 40% of the influential features have a significant (p-value = 0.05) causal relationship with DOS. We developed a DOS prediction model whose accuracy is higher than that of prior models. This improvement is achieved via the introduction of a Novel column (novel) feature set on which the model was trained. Utilizing our prediction model, hospitals can improve the efficiency of surgery schedules, and by exploiting the identified causal relationship, can influence the DOS. Further, the feature importance methods we used can help explain the model’s predictions.



RQUGE:3.6343
 Q1:Why did they use only causal features?
Q2:does the dosm-f model have a positive causal effect
Best ans: Training using only causal values allowed the causal features to have a bigger impact on the prediction value of the model. So, the final answer is yes.
['A0: They wanted to compare features that had high correlation with the causal features so that the comparison would not be based on highly correlated features', 'A1: The CF values were used to have a bigger impact on the prediction value of the model. So, the final answer is yes.', 'A2: Training using only causal values allowed the causal features to have a bigger impact on the prediction value of the model. So, the final answer is yes.', 'A3: Training using only causal values allowed the causal features to have a bigger impact on the prediction value of the model.', 'A4: allow the CF values to have', 'A5: to calculate feature importance, we developed', 'A6: so that the comparison would not be', 'A7: so that the comparison would not be founded on highly correlated features']Text: We filtered out features that had high correlation with the causal features so that the comparison would not be based on highly correlated features. To calculate feature importance, we developed a duration of surgery (DOS) prediction model using the features in CF and filtered non-causal feature set (FNCF)  We aimed to identify features that influence DOS prediction and also have a causal relationship with DOS. In addition, we examined whether a feature that has a positive causal effect on DOS also had a positive effect on the DOS predicted value. We call this model DOSM-F, as it is similar to DOSM, but with filtered features.  DOSM-F model was used to estimate the potential change in the DOS as a result of variations in causal feature values. Training using only CF values allowed the CF values to have a bigger impact on the prediction value of the model.



RQUGE:3.5708
 Q1:Do supervised models predict the duration of surgery?
Q2:How was the model developed?
Best ans: The model outperformed earlier models. The model was developed using supervised machine learning (ML) techniques.
['A0: The model outperformed earlier models.', 'A1: The model outperformed earlier models. The model was developed using supervised machine learning (ML) techniques.', 'A2: Models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries.', 'A3: Machine learning models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries.', 'A4: yes.', 'A5: outperformed earlier models', 'A6: The model outperformed earlier models', 'A7: Yes']Text: We used machine learning (ML) techniques to develop supervised ML models that predict duration of surgery (DOS) from features related to patients, physicians, and surgeries. For training the models, we built a dataset of 23,293 records, collected and processed in collaboration with one of the biggest public hospitals in Israel. The performance of our DOS model in terms of mean absolute error (MAE) was 14.9 minutes. The average treatment effect (ATE) value of the 10 most influential features by Shapley Additive exPlanations (SHAP) that derived the model with the best performance was the gradient boosted trees (GBT)  The model outperformed earlier models.  Using the DOS value predicted by our model for surgery scheduling can decrease patient waiting time and minimize surgical staff idle time. Using the identified causal relationship, OR management teams can apply measures to affect DOS. Future research could study additional surgery types at different hospitals to broaden applicability of our results. Further research is needed to quantify potential cost-saving and OR utilization when using the DOSM.



RQUGE:3.3574
 Q1:How is the uncertainty of the model calculated?
Q2:How much uncertainty did the GBT model have?
Best ans: Using a DOSM to predict a list of probabilities from each tree in the gradient boosted trees (GBT)  we calculated 4.1 minutes of uncertainty. The final answer: 4.1. minutes.
['A0: Using a DOSM to predict a list of probabilities from each tree in the gradient boosted trees (GBT)  we calculated 4.1 minutes of uncertainty. The final answer: 4.1. minutes..', 'A1: Using a DOSM to predict a list of probabilities from each tree in the gradient boosted trees (GBT)  we calculated 4.1 minutes of uncertainty. The final answer: 4.1. minutes.', 'A2: Using a DOSM to predict a list of probabilities from each tree in the gradient boosted trees (GBT)  we calculated 4.1 minutes of uncertainty. The final answer: 4.1.', 'A3: Using a DOSM to predict a list of probabilities from each tree in the gradient boosted trees (GBT)  we calculated 4.1 minutes of uncertainty.', 'A4: for every record in the test set', 'A5: for every record', 'A6: derived uncertainty of model was 4.1 minutes.', 'A7: derived uncertainty of model was 4.1 minutes']Text: We trained the duration of surgery (DOS) models on the dataset using several machine learning (ML) algorithms. The algorithms that generated the top performing models–GBT being the best–are presented in Table 6. The mean absolute error (MAE) values in the table suggest that the performance is similar across the three algorithms, with gradient boosted trees (GBT) performing a bit better. We have calculated the model’s uncertainty as follows: For each record in the test set, we used the DOSM to predict a list of probabilities from each tree in the GBT. The derived uncertainty of the model was 4.1 minutes.



RQUGE:3.1323
 Q1:Why did we train GBT over GOT?
Q2:What is the difference between the GOT and the GBT models?
Best ans: The gradient boosted trees (GBT) model is a bit better than the GOT model because it uses a more general model.
['A0: The gradient boosted trees (GBT) model is a bit better than the GOT model because it uses a more general model.', 'A1: We used gradient boosted trees (GBT) over GOT because it is a more general approach to training models.', 'A2:  gradient boosted trees (GBT)is a better model than GOT because it has more trees.', 'A3: Compared to GOT, gradient boosted trees (GBT) has a higher degree of accuracy and a lower degree of uncertainty than GOT.', 'A4: performs a bit better.', 'A5:  gradient boosted trees (GBT)performs better', 'A6:  gradient boosted trees (GBT)performs better than GOT', 'A7: performs a bit better']Text: We trained the duration of surgery (DOS) models on the dataset using several machine learning (ML) algorithms. The algorithms that generated the top performing models–GBT being the best–are presented in Table 6. The mean absolute error (MAE) values in the table suggest that the performance is similar across the three algorithms, with gradient boosted trees (GBT) performing a bit better. We have calculated the model’s uncertainty as follows: For each record in the test set, we used the DOSM to predict a list of probabilities from each tree in the GBT. The derived uncertainty of the model was 4.1 minutes.



RQUGE:2.9569
 Q1:What is Mean Absolute Error?
Q2:How is MAE calculated?
Best ans:  mean absolute error (MAE)is the absolute error of the model. MAE can be calculated by multiplying the predicted duration of surgery (DOS) value by the number of records.
['A0: To evaluate our model’s performance, we used the regression metrics Mean Absolute Error (MAE), Mean Absolutity Percentage Erron (MAPE) and Root Mean Square Err on data.', 'A1: To evaluate our model’s performance, we used the regression metrics Mean Absolute Error (MAE), Mean Absolutity Percentage Erron (MAPE) and Root Mean Square Err', 'A2: The mean absolute error (MAE) is the difference between the predicted duration of surgery (DOS) value and the actual duration of the surgery. MAE is the absolute error of the model.', 'A3:  mean absolute error (MAE)is the absolute error of the model. MAE can be calculated by multiplying the predicted duration of surgery (DOS) value by the number of records.', 'A4: (MAE)', 'A5:  mean absolute error (MAE)is the absolute error', 'A6: MAE', 'A7: mean absolute error']Text: To evaluate our model’s performance, we used the regression metrics Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Root Mean Square Error (RMSE) The metrics are computed as follow: yi is the predicted duration of surgery (DOS) value of record i, ti is the true value of DOS, and n is the number of records. To evaluate the grid search output, We used K-fold cross-validation, a commonly used method to fully and effectively utilize data.



